{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook trains a model with additional loss for Stability on Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "import torch\n",
    "dataset = Planetoid(root='/tmp/Citeseer/', name='Citeseer')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import k_hop_subgraph, to_undirected\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.data import Data\n",
    "from graphxai.explainers._base import _BaseExplainer\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "\n",
    "class _BaseExplainer:\n",
    "    \"\"\"\n",
    "    Base Class for Explainers\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            model: nn.Module,\n",
    "            emb_layer_name: Optional[str] = None,\n",
    "            is_subgraphx: Optional[bool] = False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "                The output of the model should be unnormalized class score.\n",
    "                For example, last layer = GCNConv or Linear.\n",
    "            emb_layer_name (str, optional): name of the embedding layer\n",
    "                If not specified, use the last but one layer by default.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.L = len([module for module in self.model.modules()\n",
    "                      if isinstance(module, MessagePassing)])\n",
    "        self.explain_graph = False  # Assume node-level explanation by default\n",
    "        self.subgraphx_flag = is_subgraphx\n",
    "        self.__set_embedding_layer(emb_layer_name)\n",
    "\n",
    "    def __set_embedding_layer(self, emb_layer_name: str = None):\n",
    "        \"\"\"\n",
    "        Set the embedding layer (by default is the last but one layer).\n",
    "        \"\"\"\n",
    "        if emb_layer_name:\n",
    "            try:\n",
    "                self.emb_layer = getattr(self.model, emb_layer_name)\n",
    "            except AttributeError:\n",
    "                raise ValueError(f'{emb_layer_name} does not exist in the model')\n",
    "        else:\n",
    "            self.emb_layer = list(self.model.modules())[-2]\n",
    "\n",
    "    def _get_embedding(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                       forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the embedding.\n",
    "        \"\"\"\n",
    "        emb = self._get_activation(self.emb_layer, x, edge_index, forward_kwargs)\n",
    "        return emb\n",
    "\n",
    "    def _set_masks(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                   edge_mask: torch.Tensor = None, explain_feature: bool = False,\n",
    "                   device = None):\n",
    "        \"\"\"\n",
    "        Initialize the edge (and feature) masks.\n",
    "        \"\"\"\n",
    "        (n, d), m = x.shape, edge_index.shape[1]\n",
    "\n",
    "        # Initialize edge_mask and feature_mask for learning\n",
    "        std = torch.nn.init.calculate_gain('relu') * np.sqrt(2.0 / (2 * n))\n",
    "        if edge_mask is None:\n",
    "            edge_mask = (torch.randn(m) * std).to(device)\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        else:\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        if explain_feature:\n",
    "            feature_mask = (torch.randn(d) * 0.1).to(device)\n",
    "            self.feature_mask = torch.nn.Parameter(feature_mask)\n",
    "\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # Tell pytorch geometric to apply edge masks\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def _clear_masks(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.edge_mask = None\n",
    "        self.feature_mask = None\n",
    "\n",
    "    def _flow(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def _predict(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                 return_type: str = 'label', forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the model's prediction.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            return_type (str): one of ['label', 'prob', 'log_prob']\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            pred (torch.Tensor, [n x ...]): model prediction\n",
    "        \"\"\"\n",
    "        # Compute unnormalized class score\n",
    "        with torch.no_grad():\n",
    "            out = self.model.to(device)(x, edge_index, **forward_kwargs)\n",
    "            if return_type == 'label':\n",
    "                out = out.argmax(dim=-1)\n",
    "            elif return_type == 'prob':\n",
    "                out = F.softmax(out, dim=-1)\n",
    "            elif return_type == 'log_prob':\n",
    "                out = F.log_softmax(out, dim=-1)\n",
    "            else:\n",
    "                raise ValueError(\"return_type must be 'label', 'prob', or 'log_prob'\")\n",
    "\n",
    "            if self.explain_graph:\n",
    "                out = out.squeeze()\n",
    "\n",
    "            return out\n",
    "\n",
    "    def _prob_score_func_graph(self, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probability that the input graphs\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            target_class (int): the targeted class of the graph\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        def get_prob_score(x: torch.Tensor,\n",
    "                           edge_index: torch.Tensor,\n",
    "                           forward_kwargs: dict = {}):\n",
    "            prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                 forward_kwargs=forward_kwargs)\n",
    "            score = prob[:, target_class]\n",
    "            return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _prob_score_func_node(self, node_idx: torch.Tensor, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probabilities that k specified nodes\n",
    "        in `torch_geometric.data.Batch` (disconnected union of the input graphs)\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            node_idx (torch.Tensor, [k]): the indices of the k nodes interested\n",
    "            target_class (torch.Tensor, [k]): the targeted classes of the k nodes\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        if self.subgraphx_flag:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[node_idx, target_class]\n",
    "                return score\n",
    "        else:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[:, node_idx, target_class]\n",
    "                return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _get_activation(self, layer: nn.Module, x: torch.Tensor,\n",
    "                        edge_index: torch.Tensor, forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the activation of the layer.\n",
    "        \"\"\"\n",
    "        activation = {}\n",
    "        def get_activation():\n",
    "            def hook(model, inp, out):\n",
    "                activation['layer'] = out.detach()\n",
    "            return hook\n",
    "\n",
    "        layer.register_forward_hook(get_activation())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return activation['layer']\n",
    "\n",
    "    def _get_k_hop_subgraph(self, node_idx: int, x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor, num_hops: int = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Extract the subgraph of target node\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): the node index\n",
    "            x (torch.Tensor, [n x d]): node feature matrix with shape\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index\n",
    "            kwargs (dict): additional parameters of the graph\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # TODO: use NamedTuple\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        return khop_info\n",
    "\n",
    "    def get_explanation_node(self, node_idx: int,\n",
    "                             x: torch.Tensor,\n",
    "                             edge_index: torch.Tensor,\n",
    "                             label: torch.Tensor = None,\n",
    "                             num_hops: int = None,\n",
    "                             forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): index of the node to be explained\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            label (torch.Tensor, optional, [n x ...]): labels to explain\n",
    "                If not provided, we use the output of the model.\n",
    "            num_hops (int, optional): number of hops to consider\n",
    "                If not provided, we use the number of graph layers of the GNN.\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "            khop_info (4-tuple of torch.Tensor):\n",
    "                0. the nodes involved in the subgraph\n",
    "                1. the filtered `edge_index`\n",
    "                2. the mapping from node indices in `node_idx` to their new location\n",
    "                3. the `edge_index` mask indicating which edges were preserved\n",
    "        \"\"\"\n",
    "        # If labels are needed\n",
    "        label = self._predict(x, edge_index, return_type='label') if label is None else label\n",
    "        # If probabilities / log probabilities are needed\n",
    "        prob = self._predict(x, edge_index, return_type='prob')\n",
    "        log_prob = self._predict(x, edge_index, return_type='log_prob')\n",
    "\n",
    "        num_hops = self.L if num_hops is None else num_hops\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return exp, khop_info\n",
    "\n",
    "    def get_explanation_graph(self, edge_index: torch.Tensor,\n",
    "                              x: torch.Tensor, label: torch.Tensor,\n",
    "                              forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a whole-graph prediction.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            label (torch.Tensor, [n x ...]): labels to explain\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "        \"\"\"\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_explanation_link(self):\n",
    "        \"\"\"\n",
    "        Explain a link prediction.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph as subgraph\n",
    "\n",
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class _BaseDecomposition(_BaseExplainer):\n",
    "    '''\n",
    "    Code adapted from Dive into Graphs (DIG)\n",
    "    Code: https://github.com/divelab/DIG\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__(model=model) # Will set self.model = model\n",
    "        # Other properties: self.L (number of layers)\n",
    "\n",
    "    @property\n",
    "    def __num_hops__(self):\n",
    "        if self.explain_graph:\n",
    "            return -1\n",
    "        else:\n",
    "            return self.L\n",
    "    \n",
    "    def set_graph_attr(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.num_edges = edge_index.shape[1]\n",
    "        self.num_nodes = x.shape[0]\n",
    "        self.device = x.device\n",
    "\n",
    "    def extract_step(self, x: Tensor, edge_index: Tensor, detach: bool = True, split_fc: bool = False, forward_kwargs: dict = None):\n",
    "        '''Gets information about every layer in the graph\n",
    "        Args:\n",
    "\n",
    "            forward_kwargs (tuple, optional): Additional arguments to model forward call (other than x and edge_index)\n",
    "                (default: :obj:`None`)\n",
    "        '''\n",
    "\n",
    "        layer_extractor = []\n",
    "        hooks = []\n",
    "\n",
    "        def register_hook(module: nn.Module):\n",
    "            if not list(module.children()) or isinstance(module, MessagePassing):\n",
    "                hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "        def forward_hook(module: nn.Module, input: Tuple[Tensor], output: Tensor):\n",
    "            # input contains x and edge_index\n",
    "            if detach:\n",
    "                layer_extractor.append((module, input[0].clone().detach(), output.clone().detach()))\n",
    "            else:\n",
    "                layer_extractor.append((module, input[0], output))\n",
    "\n",
    "        # --- register hooks ---\n",
    "        self.model.apply(register_hook)\n",
    "\n",
    "        # ADDED: OWEN QUEEN --------------\n",
    "        if forward_kwargs is None:\n",
    "            _ = self.model(x, edge_index)\n",
    "        else:\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "        # --------------------------------\n",
    "        # Remove hooks:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        # --- divide layer sets ---\n",
    "\n",
    "        # print('Layer extractor', [layer_extractor[i][0] for i in range(len(layer_extractor))])\n",
    "\n",
    "        walk_steps = []\n",
    "        fc_steps = []\n",
    "        pool_flag = False\n",
    "        step = {'input': None, 'module': [], 'output': None}\n",
    "        for layer in layer_extractor:\n",
    "            if isinstance(layer[0], MessagePassing):\n",
    "                if step['module']: # Append step that had previously been building\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], GNNPool):\n",
    "                pool_flag = True\n",
    "                if step['module']:\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                # Putting in GNNPool\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], nn.Linear):\n",
    "                if step['module']:\n",
    "                    if isinstance(step['module'][0], MessagePassing):\n",
    "                        walk_steps.append(step) # Append MessagePassing layer to walk_steps\n",
    "                    else: # Always append Linear layers to fc_steps\n",
    "                        fc_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            # Also appends non-trainable layers to step (not modifying input):\n",
    "            step['module'].append(layer[0])\n",
    "            step['output'] = layer[2]\n",
    "\n",
    "        if step['module']:\n",
    "            if isinstance(step['module'][0], MessagePassing):\n",
    "                walk_steps.append(step)\n",
    "            else: # Append anything to FC that is not MessagePassing at its origin\n",
    "                # Still supports sequential layers\n",
    "                fc_steps.append(step)\n",
    "            # print('layer', layer[0])\n",
    "            # if isinstance(layer[0], MessagePassing) or isinstance(layer[0], GNNPool):\n",
    "            #     if isinstance(layer[0], GNNPool):\n",
    "            #         pool_flag = True\n",
    "            #     if step['module'] and step['input'] is not None:\n",
    "            #         walk_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # if pool_flag and split_fc and isinstance(layer[0], nn.Linear):\n",
    "            #     if step['module']:\n",
    "            #         fc_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # step['module'].append(layer[0])\n",
    "            # step['output'] = layer[2]\n",
    "\n",
    "        for walk_step in walk_steps:\n",
    "            if hasattr(walk_step['module'][0], 'nn') and walk_step['module'][0].nn is not None:\n",
    "                # We don't allow any outside nn during message flow process in GINs\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "            elif hasattr(walk_step['module'][0], 'lin') and walk_step['module'][0].lin is not None:\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "\n",
    "        # print('Walk steps', [walk_steps[i]['module'] for i in range(len(walk_steps))])\n",
    "        # print('fc steps', [fc_steps[i]['module'] for i in range(len(fc_steps))])\n",
    "\n",
    "        return walk_steps, fc_steps\n",
    "\n",
    "    def walks_pick(self,\n",
    "                   edge_index: Tensor,\n",
    "                   pick_edge_indices: List,\n",
    "                   walk_indices: List=[],\n",
    "                   num_layers=0\n",
    "                   ):\n",
    "        walk_indices_list = []\n",
    "        for edge_idx in pick_edge_indices:\n",
    "\n",
    "            # Adding one edge\n",
    "            walk_indices.append(edge_idx)\n",
    "            _, new_src = src, tgt = edge_index[:, edge_idx]\n",
    "            next_edge_indices = np.array((edge_index[0, :] == new_src).nonzero().view(-1))\n",
    "\n",
    "            # Finding next edge\n",
    "            if len(walk_indices) >= num_layers:\n",
    "                # return one walk\n",
    "                walk_indices_list.append(walk_indices.copy())\n",
    "            else:\n",
    "                walk_indices_list += self.walks_pick(edge_index, next_edge_indices, walk_indices, num_layers)\n",
    "\n",
    "            # remove the last edge\n",
    "            walk_indices.pop(-1)\n",
    "\n",
    "        return walk_indices_list\n",
    "\n",
    "class CAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, activation = None):\n",
    "        '''\n",
    "        .. note::\n",
    "            From Pope et al., CAM requires that the layer immediately before the softmax layer be\n",
    "            a global average pooling layer, or in the case of node classification, a graph convolutional\n",
    "            layer. Therefore, for this algorithm to theoretically work, there can be no fully-connected\n",
    "            layers after global pooling. There is no restriction in the code for this, but be warned. \n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            activation (method, optional): activation funciton for final layer in network. If `activation = None`,\n",
    "                explainer assumes linear activation. Use `activation = None` if the activation is applied\n",
    "                within the `forward` method of `model`, only set this parameter if another activation is\n",
    "                applied in the training procedure outside of model. (:default: :obj:`None`)\n",
    "        '''\n",
    "        super().__init__(model=model)\n",
    "        self.model = model\n",
    "\n",
    "        # Set activation function\n",
    "        self.activation = lambda x: x  if activation is None else activation\n",
    "        # i.e. linear activation if none provided\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                node_idx: int, \n",
    "                edge_index: torch.Tensor, \n",
    "                label: int = None,  \n",
    "                y = None,\n",
    "                forward_kwargs: dict = {},\n",
    "                directed: bool = False\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Explain one node prediction by the model\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.tensor): edge_index of entire graph\n",
    "            label (int, optional): Label on which to compute the explanation for\n",
    "                this node. If `None`, the predicted label from the model will be\n",
    "                used. (default: :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "            directed (bool, optional): If True, graph is directed.\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        if not directed:\n",
    "            edge_index = to_undirected(edge_index)\n",
    "\n",
    "        if label is None:\n",
    "            if y is None:\n",
    "                label = int(self.__forward_pass(x, edge_index, forward_kwargs).argmax(dim=1).item())\n",
    "            else:\n",
    "                label = y[node_idx]\n",
    "\n",
    "        # Perform walk:\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=False, split_fc=False, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        # Get subgraph:\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        #cam = torch.zeros(N) # Compute CAM only over the subgraph (all others are zero)\n",
    "        cam = torch.zeros(subgraph_N)\n",
    "        for i in range(subgraph_N):\n",
    "            n = subgraph_nodes[i]\n",
    "            cam[i] += self.__exp_node(n, walk_steps, label)\n",
    "\n",
    "        # Set Explanation class:\n",
    "        exp = Explanation(\n",
    "            node_imp = cam,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs = {}):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, predicted_c):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after last convolutiuonal layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        last_conv_layer = walk_steps[-1]\n",
    "\n",
    "        if isinstance(last_conv_layer['module'][0], GINConv):\n",
    "            weight_vec = last_conv_layer['module'][0].nn.weight[predicted_c, :].detach()  # last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], GCNConv):\n",
    "            weight_vec = last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], torch.nn.Linear):\n",
    "            weight_vec = last_conv_layer['module'][0].weight[predicted_c, :].detach()\n",
    "\n",
    "        F_l_n = F.relu(last_conv_layer['input'][node_idx,:]).detach()\n",
    "\n",
    "        L_cam_n = F.relu(torch.matmul(weight_vec, F_l_n))\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "\n",
    "class GradCAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Gradient Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.Tensor, criterion = F.cross_entropy):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "            x: torch.Tensor, \n",
    "            y: torch.Tensor, \n",
    "            node_idx: int, \n",
    "            edge_index: torch.Tensor, \n",
    "            label: int = None, \n",
    "            forward_kwargs: dict = {}, \n",
    "            average_variant: bool = True, \n",
    "            layer: int = 0\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a node in the given graph\n",
    "        Args:\n",
    "            x (torch.Tensor, (n,)): Tensor of node features from the entire graph, with n nodes.\n",
    "            y (torch.Tensor, (n,)): Ground-truth labels for all n nodes in the graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.Tensor): Edge_index of entire graph.\n",
    "            label (int, optional): Label for which to compute Grad-CAM against. If None, computes\n",
    "                the Grad-CAM with respect to the model's predicted class for this node.\n",
    "                (default :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. (default: :obj:`None`)\n",
    "            average_variant (bool, optional): If True, computes the average Grad-CAM across all convolutional\n",
    "                layers in the model. If False, computes Grad-CAM for `layer`. (default: :obj:`True`)\n",
    "            layer (int, optional): Layer by which to compute the Grad-CAM. Argument only has an effect if \n",
    "                `average_variant == True`. Must be less-than the total number of convolutional layers\n",
    "                in the model. (default: :obj:`0`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        x = x.detach().clone()\n",
    "        y = y.detach().clone()\n",
    "\n",
    "        x.requires_grad = True\n",
    "\n",
    "        if label is None:\n",
    "            pred = self.__forward_pass(x, y, edge_index, forward_kwargs)[0][node_idx, :].reshape(1, -1)\n",
    "            y[node_idx] = pred.argmax(dim=1).item()\n",
    "        else: # Transform node_idx's label if provided by user\n",
    "            pred, loss = self.__forward_pass(x, y, edge_index, forward_kwargs)\n",
    "            y[node_idx] = label\n",
    "\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=True, split_fc=True, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx, self.L, edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        if average_variant:\n",
    "            # Size of all nodes in the subgraph:\n",
    "            avg_gcam = torch.zeros(subgraph_N)\n",
    "\n",
    "            for l in range(self.L):\n",
    "                # Compute gradients for this layer ahead of time:\n",
    "                gradients = self.__grad_by_layer(l)\n",
    "\n",
    "                for i in range(subgraph_N): # Over all subgraph nodes\n",
    "                    n = subgraph_nodes[i]\n",
    "                    avg_gcam[i] += self.__get_gCAM_layer(walk_steps, l, n, gradients)\n",
    "\n",
    "            avg_gcam /= self.L # Apply average\n",
    "\n",
    "            exp.node_imp = avg_gcam\n",
    "\n",
    "        else:\n",
    "            assert layer < len(walk_steps), \"Layer must be an index of convolutional layers\"\n",
    "\n",
    "            gcam = torch.zeros(subgraph_N)\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "            for i in range(subgraph_N):\n",
    "                n = subgraph_nodes[i]\n",
    "                gcam[i] += self.__get_gCAM_layer(walk_steps, layer, n, gradients)#[0]\n",
    "\n",
    "            exp.node_imp = gcam\n",
    "\n",
    "        return exp\n",
    "        \n",
    "    def __forward_pass(self, x, label, edge_index, forward_kwargs):\n",
    "        x.requires_grad = True # Enforce that x needs gradient\n",
    "\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        loss = self.criterion(pred, label)\n",
    "        loss.backward() # Propagate loss backward through network\n",
    "\n",
    "        return pred, loss\n",
    "\n",
    "    def __grad_by_layer(self, layer):\n",
    "        # Index 0 of parameters to avoid calculating gradients for biases\n",
    "        module_at_layer = list(self.model.children())[layer]\n",
    "\n",
    "        if isinstance(module_at_layer, GCNConv):\n",
    "            grad = module_at_layer.lin.weight.grad\n",
    "        elif isinstance(module_at_layer, GINConv):\n",
    "            grad = module_at_layer.nn.weight.grad\n",
    "        else:\n",
    "            grad = module_at_layer.weight.grad\n",
    "\n",
    "        return grad.mean(dim=1)\n",
    "\n",
    "    def __get_gCAM_layer(self, walk_steps, layer, node_idx = None, gradients = None):\n",
    "        # Gets Grad CAM for one layer\n",
    "        if gradients is None:\n",
    "            # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "            # ''        '' shape: [k,] - k= # output features from layer l\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "\n",
    "        if node_idx is None: # Need to compute for entire graph:\n",
    "            node_explanations = []\n",
    "            for n in range(self.N):\n",
    "                node_explanations.append(self.__exp_node(n, walk_steps, layer, gradients))\n",
    "\n",
    "            return node_explanations\n",
    "\n",
    "        # Return for only one node:\n",
    "        return self.__exp_node(node_idx, walk_steps, layer, gradients)\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, layer, gradients):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after each convolutional layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "        # ''        '' shape: [k,] - k= # input features to layer l\n",
    "\n",
    "        # Activations for node n\n",
    "        F_l_n = F.relu(walk_steps[layer]['output'][node_idx,:]).detach()\n",
    "        L_cam_n = F.relu(torch.matmul(gradients, F_l_n)) # Combine gradients and activations\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "# from ._decomp_base_old import _BaseDecomposition\n",
    "\n",
    "def clip_hook(grad):\n",
    "    # Apply ReLU activation to gradient\n",
    "    return torch.clamp(grad, min=0)\n",
    "import gc\n",
    "\n",
    "class GuidedBP(_BaseDecomposition):\n",
    "\n",
    "    def __init__(self, model, criterion = F.cross_entropy, enforce_requires_grad = True):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.L = len([module for module in self.model.modules() if isinstance(module, MessagePassing)])\n",
    "\n",
    "        self.registered_hooks = []\n",
    "\n",
    "        self.enforce_requires_grad = enforce_requires_grad\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor,\n",
    "                edge_index: torch.Tensor,  \n",
    "                node_idx: int, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Get Guided Backpropagation explanation for one node in the graph\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            y (torch.Tensor): Ground truth labels correspond to each node's \n",
    "                classification. This argument is input to the `criterion` \n",
    "                function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the enclosing \n",
    "                subgraph. Must support `dim` argument.\n",
    "                (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        if self.enforce_requires_grad:\n",
    "            try:\n",
    "                x = x.detach().clone()\n",
    "                x.requires_grad = True\n",
    "            except:\n",
    "                pass\n",
    "        # assert x.requires_grad, 'x must have requires_grad == True'\n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        graph_exp = x.grad\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        node_imp = aggregate_node_imp(torch.stack([graph_exp[i,:] for i in subgraph_nodes]).detach(), dim=1)\n",
    "\n",
    "        # Get only those explanations for nodes in the subgraph:\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        \n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        return exp\n",
    "\n",
    "    def get_explanation_graph(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor, \n",
    "                edge_index: torch.Tensor, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a whole-graph prediction with Guided Backpropagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor of node features from the entire graph.\n",
    "            y (torch.tensor): Ground truth label of given input. This argument is \n",
    "                input to the `criterion` function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the graph. \n",
    "                Must support `dim` argument. (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)   \n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method. \n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [num_nodes, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `graph`: :obj:`torch_geometric.data.Data`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        try:\n",
    "            x.requires_grad = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        assert x.requires_grad, 'x must have requires_grad == True' \n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        node_imp = aggregate_node_imp(x.grad, dim=1)\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp\n",
    "        )\n",
    "    \n",
    "        exp.set_whole_graph(Data(x, edge_index))\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __apply_hooks(self):\n",
    "        self.registered_hooks = []\n",
    "        for p in self.model.parameters():\n",
    "            h = p.register_hook(clip_hook)\n",
    "            self.registered_hooks.append(h)\n",
    "\n",
    "    def __rm_hooks(self):\n",
    "        for h in self.registered_hooks:\n",
    "            h.remove()\n",
    "        self.registered_hooks = []\n",
    "    \n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        self.__apply_hooks()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "from graphxai.utils import Explanation\n",
    "class IG():\n",
    "    def __init__(self, model, hops: Optional[int] = 1, criterion = None):\n",
    "        self.model = model\n",
    "        self.num_hops = hops\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def node_explanations(self, node_idx: int, \n",
    "            x: torch.Tensor,\n",
    "            edge_index: torch.Tensor, \n",
    "            y: Optional[torch.Tensor] = None,):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): Index of the node to be explained.\n",
    "            edge_index (torch.Tensor, [2 x m]): Edge index of the graph.\n",
    "            x (torch.Tensor, [n x d]): Node features.\n",
    "            label (torch.Tensor, [n x ...]): Labels to explain.\n",
    "            y (torch.Tensor): Same as `label`, provided for general \n",
    "                compatibility in the arguments. (:default: :obj:`None`)\n",
    "            num_hops (int, optional): Number of hops in the enclosing \n",
    "                subgraph. If `None`, set to the number of layers in \n",
    "                the GNN. (:default: :obj:`None`)\n",
    "            steps (int, optional): Number of steps for the Riemannian \n",
    "                integration. (:default: :obj:`40`)\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`torch.Tensor, [x.shape[1],]`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :class:`graphxai.utils.EnclosingSubgraph`\n",
    "        \"\"\"\n",
    "\n",
    "        if (y is None):\n",
    "            raise ValueError('Either label or y should be provided for Integrated Gradients')\n",
    "\n",
    "        label = y[node_idx]\n",
    "        if len(label.shape) == 0:\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, self.num_hops, edge_index,\n",
    "                            relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "        steps = 40\n",
    "        self.model.eval()\n",
    "        grads = torch.zeros(steps+1, x.shape[1]).to(device)\n",
    "\n",
    "        # Perform Riemannian integration\n",
    "        for i in range(steps+1):\n",
    "            with torch.no_grad():\n",
    "                baseline = torch.zeros_like(sub_x).to(device)  # TODO: baseline all 0s, all 1s, ...?\n",
    "                temp_x = baseline + (float(i)/steps) * (sub_x.clone()-baseline)\n",
    "            temp_x.requires_grad = True\n",
    "            output = self.model(temp_x, sub_edge_index)\n",
    "            loss = self.criterion(output[mapping], label)\n",
    "            loss.backward()\n",
    "            grad = temp_x.grad[torch.where(subset==node_idx)[0].item()]\n",
    "            grads[i] = grad\n",
    "\n",
    "        grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "        avg_grads = torch.mean(grads, axis=0)\n",
    "\n",
    "        # Integrated gradients for only node_idx:\n",
    "        # baseline[0] just gets a single-value 0-tensor\n",
    "        integrated_gradients = ((x[torch.where(subset == node_idx)[0].item()]\n",
    "                                    - baseline[0]) * avg_grads)\n",
    "\n",
    "        # Integrated gradients across the enclosing subgraph:\n",
    "        all_node_ig = ((x[subset] - baseline) * avg_grads)\n",
    "        node_importances = torch.sum(all_node_ig, dim=1)\n",
    "        exp = Explanation(\n",
    "            feature_imp = integrated_gradients,\n",
    "            node_imp = node_importances,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        gc.collect()\n",
    "        return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import random\n",
    "from copy import deepcopy\n",
    "random.seed(12345)\n",
    "def perturbed_edge_list(data: torch_geometric.data.Data, n_to_add: int = 2)->torch_geometric.data.Data:\n",
    "    \"\"\"Adding two random nodes to each node\"\"\"\n",
    "    # Do not want seed here\n",
    "    edge_list = data.edge_index\n",
    "    # torch.cat((edge_list, torch.LongTensor((1,2)).to(device).reshape(1,-1)), dim=-1)\n",
    "    # print(edge_list)\n",
    "    data = deepcopy(data)\n",
    "    for node in range(data.x.shape[0]):\n",
    "        # generating two random nodes to add to its adjacency list\n",
    "        for i in range(n_to_add):\n",
    "            n1 = randint(0, data.x.shape[0]-1)\n",
    "            new1 = torch.cat((edge_list[0], torch.LongTensor([node]).to(device)), axis=-1)\n",
    "            new2 = torch.cat((edge_list[1], torch.LongTensor([n1]).to(device)), axis=-1)\n",
    "            edge_list = torch.cat([new1.reshape(1,-1), new2.reshape(1,-1)])\n",
    "    data.edge_index = edge_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def explanation_list_to_matrix(l: list, data)->torch.Tensor:\n",
    "    len_l = len(l)\n",
    "    matrix = torch.zeros((len_l, data.x.shape[0]))\n",
    "    with tqdm(total=len_l) as pbar:\n",
    "        for i, exp in enumerate(l):\n",
    "            pbar.update(1)\n",
    "            subgraph = exp.enc_subgraph.nodes\n",
    "            for j, n in enumerate(subgraph):\n",
    "                n = n.item()\n",
    "                matrix[i][n] = exp.node_imp[j].item()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def stability(generated_exp_unperturbed, generated_exp_perturbed ) -> float:\n",
    "    \"\"\"takes in two matrices the first is unperturbed explanations and the second are perturbed via the addition of a random node\n",
    "        - We assume here that the explanations are in their padded form that is: that the explanation vectors in the list have nodes at equal positions \"\"\"\n",
    "    stability = float() \n",
    "    # Accessing the enclosing subgraph. Will be the same for both explanation.:\n",
    "    stability = abs( np.linalg.norm(np.matrix(generated_exp_unperturbed.numpy())) - np.linalg.norm(np.matrix(generated_exp_perturbed.numpy())) )\n",
    "    return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the random nodes\n",
    "from random import sample\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "# I now want all nodes for each given class (there are 7), and I will randomly select 50 of each class\n",
    "class_0 = [idx for idx, val in enumerate(data.y) if val == 0]\n",
    "class_1 = [idx for idx, val in enumerate(data.y) if val == 1]\n",
    "class_2 = [idx for idx, val in enumerate(data.y) if val == 2]\n",
    "class_3 = [idx for idx, val in enumerate(data.y) if val == 3]\n",
    "class_4 = [idx for idx, val in enumerate(data.y) if val == 4]\n",
    "class_5 = [idx for idx, val in enumerate(data.y) if val == 5]\n",
    "\n",
    "random_class_0 = sample(class_0, k=50)\n",
    "random_class_1 = sample(class_1, k=50)\n",
    "random_class_2 = sample(class_2, k=50)\n",
    "random_class_3 = sample(class_3, k=50)\n",
    "random_class_4 = sample(class_4, k=50)\n",
    "random_class_5 = sample(class_5, k=50)\n",
    "\n",
    "\n",
    "random_nodes = random_class_0\n",
    "random_nodes.extend(random_class_1)\n",
    "random_nodes.extend(random_class_2)\n",
    "random_nodes.extend(random_class_3)\n",
    "random_nodes.extend(random_class_4)\n",
    "random_nodes.extend(random_class_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbp_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    bp_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = GuidedBP(model=model)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            bp_exps.append(exp)\n",
    "    return bp_exps\n",
    "\n",
    "def cam_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    cam_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = CAM(model=model)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x = data_object.x, edge_index = data_object.edge_index,  y = data_object.y)\n",
    "            cam_exps.append(exp)\n",
    "    return cam_exps\n",
    "\n",
    "def ig_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    ig_exps = list()\n",
    "    model.eval()\n",
    "    ig = IG(model=model, criterion=torch.nn.CrossEntropyLoss(), hops=1)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = ig.node_explanations(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            ig_exps.append(exp)\n",
    "    return ig_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_data = perturbed_edge_list(data=data).to(device) # this is our perturbed data to check against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 300/300 [00:09<00:00, 32.52it/s]\n",
      "100%|| 300/300 [00:18<00:00, 16.14it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1122.03it/s]\n",
      "100%|| 300/300 [00:00<00:00, 542.93it/s]\n",
      "100%|| 300/300 [00:32<00:00,  9.19it/s]\n",
      "100%|| 300/300 [00:44<00:00,  6.80it/s]\n",
      "100%|| 300/300 [00:00<00:00, 978.67it/s]\n",
      "100%|| 300/300 [00:00<00:00, 367.60it/s]\n",
      "100%|| 300/300 [00:54<00:00,  5.49it/s]\n",
      "100%|| 300/300 [00:59<00:00,  5.02it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1088.79it/s]\n",
      "100%|| 300/300 [00:00<00:00, 457.27it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [01:28<00:00,  3.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 944.75it/s]\n",
      "100%|| 300/300 [00:00<00:00, 432.53it/s]\n",
      "100%|| 300/300 [01:36<00:00,  3.11it/s]]\n",
      "100%|| 300/300 [01:47<00:00,  2.79it/s]\n",
      "100%|| 300/300 [00:00<00:00, 990.10it/s]\n",
      "100%|| 300/300 [00:00<00:00, 385.01it/s]\n",
      "100%|| 300/300 [02:01<00:00,  2.47it/s]]\n",
      "100%|| 300/300 [02:16<00:00,  2.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 998.78it/s]\n",
      "100%|| 300/300 [00:00<00:00, 403.77it/s]\n",
      "100%|| 300/300 [02:20<00:00,  2.14it/s]]\n",
      "100%|| 300/300 [02:33<00:00,  1.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 931.68it/s]\n",
      "100%|| 300/300 [00:00<00:00, 470.22it/s]\n",
      "100%|| 300/300 [02:41<00:00,  1.86it/s]]\n",
      "100%|| 300/300 [02:46<00:00,  1.80it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1060.08it/s]\n",
      "100%|| 300/300 [00:00<00:00, 421.94it/s]\n",
      "100%|| 300/300 [02:58<00:00,  1.68it/s]]\n",
      "100%|| 300/300 [03:23<00:00,  1.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1094.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 364.08it/s]\n",
      "100%|| 300/300 [03:27<00:00,  1.45it/s]t]\n",
      "100%|| 300/300 [03:38<00:00,  1.38it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1034.49it/s]\n",
      "100%|| 300/300 [00:00<00:00, 456.47it/s]\n",
      "100%|| 300/300 [03:45<00:00,  1.33it/s]t]\n",
      "100%|| 300/300 [04:02<00:00,  1.24it/s]\n",
      "100%|| 300/300 [00:00<00:00, 884.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 373.08it/s]\n",
      "100%|| 300/300 [04:14<00:00,  1.18it/s]t]\n",
      "100%|| 300/300 [04:21<00:00,  1.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1074.39it/s]\n",
      "100%|| 300/300 [00:00<00:00, 434.78it/s]\n",
      "100%|| 300/300 [04:24<00:00,  1.13it/s]it]\n",
      "100%|| 300/300 [04:36<00:00,  1.09it/s]\n",
      "100%|| 300/300 [00:00<00:00, 983.61it/s]\n",
      "100%|| 300/300 [00:00<00:00, 430.27it/s]\n",
      "100%|| 300/300 [04:44<00:00,  1.05it/s]s/it]\n",
      "100%|| 300/300 [05:01<00:00,  1.01s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1000.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 444.29it/s]\n",
      "100%|| 300/300 [05:05<00:00,  1.02s/it]s/it]\n",
      "100%|| 300/300 [05:08<00:00,  1.03s/it]\n",
      "100%|| 300/300 [00:00<00:00, 931.69it/s]\n",
      "100%|| 300/300 [00:00<00:00, 324.96it/s]\n",
      "100%|| 300/300 [05:31<00:00,  1.10s/it]s/it]\n",
      "100%|| 300/300 [05:33<00:00,  1.11s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1048.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 476.95it/s]\n",
      "100%|| 300/300 [05:47<00:00,  1.16s/it]s/it]\n",
      "100%|| 300/300 [05:54<00:00,  1.18s/it]\n",
      "100%|| 300/300 [00:00<00:00, 909.10it/s]\n",
      "100%|| 300/300 [00:00<00:00, 466.46it/s]\n",
      "100%|| 300/300 [06:00<00:00,  1.20s/it]s/it]\n",
      "100%|| 300/300 [06:08<00:00,  1.23s/it]\n",
      "100%|| 300/300 [00:00<00:00, 989.07it/s]\n",
      "100%|| 300/300 [00:00<00:00, 379.75it/s]\n",
      "100%|| 300/300 [05:58<00:00,  1.19s/it]s/it]\n",
      "100%|| 300/300 [06:21<00:00,  1.27s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1135.38it/s]\n",
      "100%|| 300/300 [00:00<00:00, 468.75it/s]\n",
      "100%|| 300/300 [06:42<00:00,  1.34s/it]s/it]\n",
      "100%|| 300/300 [06:45<00:00,  1.35s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1102.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 498.34it/s]\n",
      "100%|| 300/300 [06:58<00:00,  1.39s/it]s/it]\n",
      "100%|| 300/300 [07:07<00:00,  1.42s/it]\n",
      "100%|| 300/300 [00:00<00:00, 892.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 448.90it/s]\n",
      "100%|| 300/300 [07:32<00:00,  1.51s/it]s/it]\n",
      "100%|| 300/300 [07:22<00:00,  1.47s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1063.00it/s]\n",
      "100%|| 300/300 [00:00<00:00, 490.20it/s]\n",
      "100%|| 300/300 [07:29<00:00,  1.50s/it]s/it]\n",
      "100%|| 300/300 [07:48<00:00,  1.56s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1060.08it/s]\n",
      "100%|| 300/300 [00:00<00:00, 463.53it/s]\n",
      "100%|| 300/300 [08:05<00:00,  1.62s/it]s/it]\n",
      "100%|| 300/300 [07:59<00:00,  1.60s/it]\n",
      "100%|| 300/300 [00:00<00:00, 922.45it/s]\n",
      "100%|| 300/300 [00:00<00:00, 368.00it/s]\n",
      "100%|| 300/300 [07:54<00:00,  1.58s/it]s/it]\n",
      "100%|| 300/300 [08:22<00:00,  1.67s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1006.02it/s]\n",
      "100%|| 300/300 [00:00<00:00, 412.09it/s]\n",
      "100%|| 300/300 [08:42<00:00,  1.74s/it]s/it]\n",
      "100%|| 300/300 [08:40<00:00,  1.74s/it]\n",
      "100%|| 300/300 [00:00<00:00, 939.67it/s]\n",
      "100%|| 300/300 [00:00<00:00, 459.22it/s]\n",
      "100%|| 300/300 [08:55<00:00,  1.79s/it]s/it]\n",
      "100%|| 300/300 [08:52<00:00,  1.77s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1086.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 460.71it/s]\n",
      "100%|| 300/300 [08:40<00:00,  1.73s/it]s/it]\n",
      "100%|| 300/300 [08:00<00:00,  1.60s/it]\n",
      "100%|| 300/300 [00:00<00:00, 903.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 442.32it/s]\n",
      "100%|| 300/300 [08:03<00:00,  1.61s/it]s/it]\n",
      "100%|| 300/300 [08:20<00:00,  1.67s/it]\n",
      "100%|| 300/300 [00:00<00:00, 961.54it/s]\n",
      "100%|| 300/300 [00:00<00:00, 402.94it/s]\n",
      "100%|| 300/300 [08:23<00:00,  1.68s/it]s/it]\n",
      "100%|| 300/300 [08:32<00:00,  1.71s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1075.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 411.36it/s]\n",
      "100%|| 300/300 [08:37<00:00,  1.73s/it]s/it]\n",
      "100%|| 300/300 [08:55<00:00,  1.79s/it]\n",
      "100%|| 300/300 [00:00<00:00, 983.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 452.15it/s]\n",
      "100%|| 300/300 [08:41<00:00,  1.74s/it]8s/it]\n",
      "100%|| 300/300 [09:33<00:00,  1.91s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1013.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 324.94it/s]\n",
      "100%|| 300/300 [10:12<00:00,  2.04s/it]7s/it]\n",
      "100%|| 300/300 [10:43<00:00,  2.14s/it]\n",
      "100%|| 300/300 [00:00<00:00, 945.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 481.54it/s]\n",
      "100%|| 300/300 [11:02<00:00,  2.21s/it]6s/it]\n",
      "100%|| 300/300 [11:01<00:00,  2.20s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1123.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 480.00it/s]\n",
      "100%|| 300/300 [11:15<00:00,  2.25s/it]1s/it]\n",
      "100%|| 300/300 [11:11<00:00,  2.24s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1079.14it/s]\n",
      "100%|| 300/300 [00:00<00:00, 383.63it/s]\n",
      "100%|| 300/300 [11:21<00:00,  2.27s/it]2s/it]\n",
      "100%|| 300/300 [11:56<00:00,  2.39s/it]\n",
      "100%|| 300/300 [00:00<00:00, 857.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 346.30it/s]\n",
      "100%|| 300/300 [11:54<00:00,  2.38s/it]7s/it]\n",
      "100%|| 300/300 [11:41<00:00,  2.34s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1106.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 482.95it/s]\n",
      "100%|| 300/300 [11:47<00:00,  2.36s/it]1s/it]\n",
      "100%|| 300/300 [12:23<00:00,  2.48s/it]\n",
      "100%|| 300/300 [00:00<00:00, 900.06it/s]\n",
      "100%|| 300/300 [00:00<00:00, 438.60it/s]\n",
      "100%|| 300/300 [12:09<00:00,  2.43s/it]1s/it]\n",
      "100%|| 300/300 [12:33<00:00,  2.51s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1041.67it/s]\n",
      "100%|| 300/300 [00:00<00:00, 361.01it/s]\n",
      "100%|| 300/300 [12:24<00:00,  2.48s/it]2s/it]\n",
      "100%|| 300/300 [13:18<00:00,  2.66s/it]\n",
      "100%|| 300/300 [00:00<00:00, 983.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 464.20it/s]\n",
      "100%|| 300/300 [13:01<00:00,  2.60s/it]2s/it]\n",
      "100%|| 300/300 [12:51<00:00,  2.57s/it]\n",
      "100%|| 300/300 [00:00<00:00, 940.44it/s]\n",
      "100%|| 300/300 [00:00<00:00, 375.37it/s]\n",
      "100%|| 300/300 [12:54<00:00,  2.58s/it]8s/it]\n",
      "100%|| 300/300 [13:01<00:00,  2.60s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1075.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 429.80it/s]\n",
      "100%|| 300/300 [12:42<00:00,  2.54s/it]9s/it]\n",
      "100%|| 300/300 [13:07<00:00,  2.62s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1071.44it/s]\n",
      "100%|| 300/300 [00:00<00:00, 429.80it/s]\n",
      "100%|| 300/300 [13:31<00:00,  2.70s/it]54s/it]\n",
      "100%|| 300/300 [14:14<00:00,  2.85s/it]\n",
      "100%|| 300/300 [00:00<00:00, 908.60it/s]\n",
      "100%|| 300/300 [00:00<00:00, 371.04it/s]\n",
      "100%|| 300/300 [14:08<00:00,  2.83s/it]10s/it]\n",
      "100%|| 300/300 [14:19<00:00,  2.86s/it]\n",
      "100%|| 300/300 [00:00<00:00, 970.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 400.24it/s]\n",
      "100%|| 300/300 [14:25<00:00,  2.89s/it]99s/it]\n",
      "100%|| 300/300 [14:48<00:00,  2.96s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1027.41it/s]\n",
      "100%|| 300/300 [00:00<00:00, 457.32it/s]\n",
      "100%|| 300/300 [14:56<00:00,  2.99s/it]31s/it]\n",
      "100%|| 300/300 [15:07<00:00,  3.03s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1030.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 418.99it/s]\n",
      "100%|| 300/300 [15:26<00:00,  3.09s/it]02s/it]\n",
      "100%|| 300/300 [15:26<00:00,  3.09s/it]\n",
      "100%|| 300/300 [00:00<00:00, 993.38it/s] \n",
      "100%|| 300/300 [00:00<00:00, 474.68it/s]\n",
      "100%|| 300/300 [15:31<00:00,  3.11s/it]31s/it]\n",
      "100%|| 300/300 [15:12<00:00,  3.04s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1027.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 522.65it/s]\n",
      "100%|| 300/300 [10:29<00:00,  2.10s/it]42s/it]\n",
      "100%|| 300/300 [09:11<00:00,  1.84s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1203.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 560.75it/s]\n",
      "100%|| 300/300 [08:56<00:00,  1.79s/it]18s/it]\n",
      "100%|| 300/300 [09:18<00:00,  1.86s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1137.17it/s]\n",
      "100%|| 300/300 [00:00<00:00, 510.90it/s]\n",
      "100%|| 300/300 [14:00<00:00,  2.80s/it]68s/it]\n",
      "100%|| 300/300 [15:40<00:00,  3.14s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1115.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 478.22it/s]\n",
      "100%|| 300/300 [15:52<00:00,  3.18s/it]67s/it]\n",
      "100%|| 300/300 [16:12<00:00,  3.24s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1044.49it/s]\n",
      "100%|| 300/300 [00:00<00:00, 439.77it/s]\n",
      "100%|| 300/300 [16:29<00:00,  3.30s/it]59s/it]\n",
      "100%|| 300/300 [16:58<00:00,  3.40s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1093.36it/s]\n",
      "100%|| 300/300 [00:00<00:00, 489.95it/s]\n",
      "100%|| 300/300 [17:02<00:00,  3.41s/it]30s/it]\n",
      "100%|| 300/300 [16:54<00:00,  3.38s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1008.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 467.83it/s]\n",
      "100%|| 300/300 [16:25<00:00,  3.29s/it]06s/it]\n",
      "100%|| 300/300 [17:22<00:00,  3.47s/it]\n",
      "100%|| 300/300 [00:00<00:00, 993.38it/s]\n",
      "100%|| 300/300 [00:00<00:00, 361.88it/s]\n",
      "100%|| 300/300 [17:45<00:00,  3.55s/it]64s/it]\n",
      "100%|| 300/300 [17:07<00:00,  3.42s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1209.68it/s]\n",
      "100%|| 300/300 [00:00<00:00, 545.17it/s]\n",
      "100%|| 300/300 [17:32<00:00,  3.51s/it]27s/it]\n",
      "100%|| 300/300 [18:09<00:00,  3.63s/it]\n",
      "100%|| 300/300 [00:00<00:00, 936.79it/s] \n",
      "100%|| 300/300 [00:00<00:00, 411.52it/s]\n",
      "100%|| 300/300 [18:06<00:00,  3.62s/it]52s/it]\n",
      "100%|| 300/300 [18:22<00:00,  3.67s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1010.11it/s]\n",
      "100%|| 300/300 [00:00<00:00, 455.73it/s]\n",
      "100%|| 300/300 [18:50<00:00,  3.77s/it]40s/it]\n",
      "100%|| 300/300 [18:56<00:00,  3.79s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1060.07it/s]\n",
      "100%|| 300/300 [00:00<00:00, 488.40it/s]\n",
      "100%|| 300/300 [18:39<00:00,  3.73s/it]73s/it]\n",
      "100%|| 300/300 [19:05<00:00,  3.82s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1071.43it/s]\n",
      "100%|| 300/300 [00:00<00:00, 504.90it/s]\n",
      "100%|| 300/300 [18:18<00:00,  3.66s/it]65s/it]\n",
      "100%|| 300/300 [19:28<00:00,  3.89s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1185.03it/s]\n",
      "100%|| 300/300 [00:00<00:00, 537.05it/s]\n",
      "100%|| 300/300 [19:39<00:00,  3.93s/it]17s/it]\n",
      "100%|| 300/300 [19:20<00:00,  3.87s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1000.00it/s]\n",
      "100%|| 300/300 [00:00<00:00, 446.23it/s]\n",
      "100%|| 300/300 [19:56<00:00,  3.99s/it]85s/it]\n",
      "100%|| 300/300 [20:11<00:00,  4.04s/it]\n",
      "100%|| 300/300 [00:00<00:00, 821.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 379.68it/s]\n",
      "100%|| 300/300 [19:56<00:00,  3.99s/it]68s/it]\n",
      "100%|| 300/300 [20:15<00:00,  4.05s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1118.37it/s]\n",
      "100%|| 300/300 [00:00<00:00, 491.66it/s]\n",
      "100%|| 300/300 [20:38<00:00,  4.13s/it]65s/it]\n",
      "100%|| 300/300 [20:29<00:00,  4.10s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1148.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 495.05it/s]\n",
      "100%|| 300/300 [20:45<00:00,  4.15s/it]66s/it]\n",
      "100%|| 300/300 [20:17<00:00,  4.06s/it]\n",
      "100%|| 300/300 [00:00<00:00, 922.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 508.48it/s]\n",
      "100%|| 300/300 [21:05<00:00,  4.22s/it]71s/it]\n",
      "100%|| 300/300 [18:55<00:00,  3.79s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1074.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 480.00it/s]\n",
      "100%|| 300/300 [18:42<00:00,  3.74s/it]70s/it]\n",
      "100%|| 300/300 [18:05<00:00,  3.62s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1136.37it/s]\n",
      "100%|| 300/300 [00:00<00:00, 440.92it/s]\n",
      "100%|| 300/300 [18:20<00:00,  3.67s/it]10s/it]\n",
      "100%|| 300/300 [18:27<00:00,  3.69s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1131.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 524.94it/s]\n",
      "100%|| 300/300 [19:01<00:00,  3.81s/it]07s/it]\n",
      "100%|| 300/300 [18:30<00:00,  3.70s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1105.85it/s]\n",
      "100%|| 300/300 [00:00<00:00, 463.68it/s]\n",
      "100%|| 300/300 [21:45<00:00,  4.35s/it]32s/it]\n",
      "100%|| 300/300 [21:36<00:00,  4.32s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1209.69it/s]\n",
      "100%|| 300/300 [00:00<00:00, 414.94it/s]\n",
      "100%|| 300/300 [22:50<00:00,  4.57s/it]90s/it]\n",
      "100%|| 300/300 [22:13<00:00,  4.44s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1075.27it/s]\n",
      "100%|| 300/300 [00:00<00:00, 498.34it/s]\n",
      "100%|| 300/300 [22:04<00:00,  4.42s/it]44s/it]\n",
      "100%|| 300/300 [22:13<00:00,  4.45s/it]\n",
      "100%|| 300/300 [00:00<00:00, 961.00it/s]\n",
      "100%|| 300/300 [00:00<00:00, 386.60it/s]\n",
      "100%|| 300/300 [22:58<00:00,  4.60s/it]96s/it]\n",
      "100%|| 300/300 [22:54<00:00,  4.58s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1037.45it/s]\n",
      "100%|| 300/300 [00:00<00:00, 522.65it/s]\n",
      "100%|| 300/300 [22:22<00:00,  4.48s/it]64s/it]\n",
      "100%|| 300/300 [23:06<00:00,  4.62s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1185.78it/s]\n",
      "100%|| 300/300 [00:00<00:00, 451.13it/s]\n",
      "100%|| 300/300 [23:22<00:00,  4.67s/it]65s/it]\n",
      "100%|| 300/300 [23:35<00:00,  4.72s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1000.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 414.94it/s]\n",
      "100%|| 300/300 [23:39<00:00,  4.73s/it]07s/it]\n",
      "100%|| 300/300 [23:49<00:00,  4.76s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1115.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 505.05it/s]\n",
      "100%|| 300/300 [24:11<00:00,  4.84s/it]03s/it]\n",
      "100%|| 300/300 [23:38<00:00,  4.73s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1153.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 500.84it/s]\n",
      "100%|| 300/300 [24:25<00:00,  4.89s/it]85s/it]\n",
      "100%|| 300/300 [23:34<00:00,  4.71s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1149.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 530.04it/s]\n",
      "100%|| 300/300 [24:02<00:00,  4.81s/it]54s/it]\n",
      "100%|| 300/300 [20:47<00:00,  4.16s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1153.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 468.02it/s]\n",
      "100%|| 300/300 [21:09<00:00,  4.23s/it]55s/it]\n",
      "100%|| 300/300 [21:19<00:00,  4.27s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1107.02it/s]\n",
      "100%|| 300/300 [00:00<00:00, 505.90it/s]\n",
      "100%|| 300/300 [21:22<00:00,  4.27s/it]35s/it]\n",
      "100%|| 300/300 [21:09<00:00,  4.23s/it]\n",
      "100%|| 300/300 [00:00<00:00, 945.23it/s]\n",
      "100%|| 300/300 [00:00<00:00, 507.49it/s]\n",
      "100%|| 300/300 [21:25<00:00,  4.28s/it]79s/it]\n",
      "100%|| 300/300 [21:25<00:00,  4.28s/it]\n",
      "100%|| 300/300 [00:00<00:00, 999.25it/s] \n",
      "100%|| 300/300 [00:00<00:00, 544.47it/s]\n",
      "100%|| 300/300 [21:11<00:00,  4.24s/it]80s/it]\n",
      "100%|| 300/300 [21:25<00:00,  4.28s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1094.23it/s]\n",
      "100%|| 300/300 [00:00<00:00, 506.76it/s]\n",
      "100%|| 300/300 [21:36<00:00,  4.32s/it]64s/it]\n",
      "100%|| 300/300 [22:03<00:00,  4.41s/it]\n",
      "100%|| 300/300 [00:00<00:00, 963.84it/s] \n",
      "100%|| 300/300 [00:00<00:00, 493.21it/s]\n",
      "100%|| 300/300 [22:11<00:00,  4.44s/it]5s/it] \n",
      "100%|| 300/300 [24:01<00:00,  4.80s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1167.31it/s]\n",
      "100%|| 300/300 [00:00<00:00, 538.34it/s]\n",
      "100%|| 300/300 [25:17<00:00,  5.06s/it]9s/it]\n",
      "100%|| 300/300 [26:03<00:00,  5.21s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1127.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 453.67it/s]\n",
      "100%|| 300/300 [26:06<00:00,  5.22s/it]9s/it]\n",
      "100%|| 300/300 [25:01<00:00,  5.01s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1127.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 560.51it/s]\n",
      "100%|| 300/300 [25:54<00:00,  5.18s/it]9s/it]\n",
      "100%|| 300/300 [26:10<00:00,  5.23s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1107.02it/s]\n",
      "100%|| 300/300 [00:00<00:00, 533.65it/s]\n",
      "100%|| 300/300 [26:53<00:00,  5.38s/it]1s/it]\n",
      "100%|| 300/300 [26:38<00:00,  5.33s/it]\n",
      "100%|| 300/300 [00:00<00:00, 980.39it/s]\n",
      "100%|| 300/300 [00:00<00:00, 383.14it/s]\n",
      "100%|| 300/300 [27:23<00:00,  5.48s/it]3s/it]\n",
      "100%|| 300/300 [27:32<00:00,  5.51s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1094.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 482.92it/s]\n",
      "100%|| 300/300 [26:58<00:00,  5.40s/it]3s/it]\n",
      "100%|| 300/300 [27:31<00:00,  5.51s/it]\n",
      "100%|| 300/300 [00:00<00:00, 964.64it/s] \n",
      "100%|| 300/300 [00:00<00:00, 463.59it/s]\n",
      "100%|| 300/300 [26:57<00:00,  5.39s/it]7s/it]\n",
      "100%|| 300/300 [28:05<00:00,  5.62s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1203.70it/s]\n",
      "100%|| 300/300 [00:00<00:00, 525.39it/s]\n",
      "100%|| 300/300 [27:46<00:00,  5.56s/it]6s/it]\n",
      "100%|| 300/300 [27:36<00:00,  5.52s/it]\n",
      "100%|| 300/300 [00:00<00:00, 996.68it/s]\n",
      "100%|| 300/300 [00:00<00:00, 468.75it/s]\n",
      "100%|| 300/300 [27:26<00:00,  5.49s/it]8s/it]\n",
      "100%|| 300/300 [27:39<00:00,  5.53s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1140.69it/s]\n",
      "100%|| 300/300 [00:00<00:00, 534.16it/s]\n",
      "100%|| 300/300 [27:40<00:00,  5.53s/it]0s/it]\n",
      "100%|| 300/300 [27:33<00:00,  5.51s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1234.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 538.60it/s]\n",
      "100%|| 300/300 [27:54<00:00,  5.58s/it]1s/it]\n",
      "100%|| 300/300 [27:22<00:00,  5.48s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1127.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 341.61it/s]\n",
      "100%|| 300/300 [27:53<00:00,  5.58s/it]/it]  \n",
      "100%|| 300/300 [27:37<00:00,  5.53s/it]\n",
      "100%|| 300/300 [00:00<00:00, 958.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 443.52it/s]\n",
      "100%|| 300/300 [27:24<00:00,  5.48s/it]s/it]\n",
      "100%|| 300/300 [28:01<00:00,  5.60s/it]\n",
      "100%|| 300/300 [00:00<00:00, 1219.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 551.47it/s]\n",
      "100%|| 100/100 [49:48:06<00:00, 1792.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "gbp_stability_list = list()\n",
    "loss_list = list()\n",
    "f1_accuracy_list = list()\n",
    "\n",
    "with tqdm(total=100) as pbar:\n",
    "    for epoch in range(100):\n",
    "        pbar.update(1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "        # measuring the stability\n",
    "        gbp_explanations_unperturbed = gbp_exps(model, graph, data, random_nodes=random_nodes) # unperturbed\n",
    "        gbp_explanations_perturbed =gbp_exps(model, graph, perturbed_data, random_nodes=random_nodes) # unperturbed\n",
    "\n",
    "        gbp_matrix_unperturbed = explanation_list_to_matrix(gbp_explanations_unperturbed, data) \n",
    "        gbp_matrix_perturbed = explanation_list_to_matrix(gbp_explanations_perturbed, data) \n",
    "\n",
    "        # getting the stability\n",
    "        gbp_stab = stability(gbp_matrix_unperturbed, gbp_matrix_perturbed)\n",
    "        loss = loss.add(torch.tensor([gbp_stab], requires_grad=True).to(device) )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_list.append(loss)\n",
    "        gbp_stability_list.append(gbp_stab)\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = multiclass_f1_score(pred, data.y, num_classes=dataset.num_classes)\n",
    "        f1_accuracy_list.append(f1)\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving values to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Stability_100_citeseer_GBP.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2037aac3e20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i.item() for i in loss_list], label=\"Loss\")\n",
    "plt.plot([i for i in gbp_stability_list], label=\"Stability\")\n",
    "plt.plot([i.item() for i in f1_accuracy_list], label=\"Macro F1\")\n",
    "plt.title(\"Loss, Stability & Accuracy vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(loss_list[i].item(), gbp_stability_list[i], f1_accuracy_list[i].item()) for i in range(len(loss_list))], columns=[\"Loss\", \"GBP Stability\", \"F1 Accuracy\"])\n",
    "df.to_csv(\"Training_for_GBP_Stability_Citeseer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [16:38<00:00,  2.71it/s]\n",
      "100%|| 2708/2708 [26:29<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2708 [00:00<07:28,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6574, -0.7225, -0.6013, -0.5233], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2708 [00:00<08:56,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5203, -0.3700, -0.7551, -0.9783], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2708 [00:00<09:50,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8562, -0.5766, -0.4730, -1.1368, -0.3823,  0.0726], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2708 [00:01<10:19,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1077, -0.7583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2708 [00:01<11:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5199, -0.6340, -0.2173, -0.2145, -0.0319, -0.6756], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2708 [00:01<11:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4461, -0.9948, -0.4571, -0.6390], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2708 [00:01<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4153, -0.4828, -0.5654, -0.5037, -0.5363], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2708 [00:02<11:29,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7944, -0.2029], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2708 [00:02<11:34,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6189, -0.9601, -0.6968, -0.6772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2708 [00:02<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1621, -0.9223, -0.8898], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/2708 [00:02<11:29,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8606, -0.7249, -0.6413], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/2708 [00:03<11:26,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3526, -0.1813, -0.2870], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4200, -0.2410, -0.5283, -0.3195, -0.4002], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2708 [00:03<11:19,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0116, -0.7319, -0.6148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8901, -0.2864,  0.0708, -0.5744, -0.2016, -0.7190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2708 [00:04<11:21,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4788, -0.2618, -0.4735, -0.5339, -0.3104], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2708 [00:04<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9772, -0.3799, -0.5573, -0.5985, -0.6028], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4950, -0.8515, -0.5688, -0.4359, -0.5582, -0.3338], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3018, -1.0444, -0.6570, -0.8701, -0.1670, -0.8772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2708 [00:05<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0686, -0.9931], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2708 [00:05<11:26,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3826,  0.0631, -0.8968, -0.9487, -0.6614, -0.3889], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2708 [00:05<11:23,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6130,  0.0976, -0.6573], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2708 [00:05<11:31,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3956, -0.7277, -0.6689, -0.2478, -0.2256, -0.1082], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4049, -1.6713], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2708 [00:06<11:32,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3425, -0.5798, -0.1702, -0.2315, -0.4489, -0.2593, -0.5921, -0.3989],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7113, -0.5180, -0.6471, -0.6454, -0.7941], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2708 [00:07<11:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5213, -0.5076, -0.3410, -0.5158, -0.4208, -0.0247], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/2708 [00:07<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7930, -0.5129, -0.4541, -0.4210, -0.4524], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/2708 [00:07<11:46,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2461, -0.7360], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/2708 [00:07<11:57,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2923, -1.5444, -0.3596], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/2708 [00:08<12:08,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9600, -0.5965, -0.4892, -0.4216,  0.2531, -0.5733, -0.7309],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/2708 [00:08<11:52,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1677, -0.9148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 34/2708 [00:08<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0727, -0.4356, -0.0719, -0.8802, -0.3891], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 35/2708 [00:08<11:56,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6708, -0.2133, -0.4639, -0.0452, -0.1081, -0.2871, -0.5587, -0.3957,\n",
      "        -0.1813, -0.5420], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 36/2708 [00:09<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9400, -1.0512], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 37/2708 [00:09<11:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4529, -0.4503, -0.3648, -0.6088], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 38/2708 [00:09<11:38,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5024, -0.2346, -0.5609, -0.3737, -0.3356, -0.3844, -0.2932, -0.3747,\n",
      "        -0.2052], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 39/2708 [00:09<11:43,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3181, -0.1349, -0.4077, -0.1352], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 40/2708 [00:10<11:49,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9254, -0.6111, -0.1048, -0.3196, -0.2110], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 41/2708 [00:10<11:39,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4832, -0.8994, -0.2025, -0.5024, -0.3493, -0.3469, -0.3100, -0.1292],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 42/2708 [00:10<11:35,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9360, -0.1485, -0.8748, -0.8013], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 43/2708 [00:10<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5408, -0.5323, -0.5018, -0.2520, -0.5001], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 44/2708 [00:11<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9175, -0.6259, -0.8920], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 45/2708 [00:11<11:29,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5529, -0.4633, -0.6824, -0.1575, -0.6823, -0.4527, -0.1097],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 46/2708 [00:11<11:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7863, -0.6055, -0.3041, -0.7659], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 47/2708 [00:12<11:24,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6369, -0.1579,  0.0096, -0.2302, -0.7066, -0.8424, -0.8205],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 48/2708 [00:12<11:23,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5954, -0.7689, -1.0760], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/2708 [00:12<11:25,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6883, -0.7915, -0.8190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 50/2708 [00:12<11:31,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7514, -0.5609, -0.5929, -0.4977, -0.6895, -0.1147, -0.3839, -0.4977,\n",
      "        -0.3521, -0.1876], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 51/2708 [00:13<11:27,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9633, -0.3087, -0.7496], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 52/2708 [00:13<11:32,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0716, -0.7867], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8026, -0.6366, -0.5278, -0.3520, -0.0046, -0.2991, -0.3643],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 54/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2594, -0.6112, -0.5430, -0.0218, -0.8436, -0.6938], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 55/2708 [00:14<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6441, -0.4541, -0.7002, -0.3384], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 56/2708 [00:14<11:24,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5803, -0.7055, -1.0509], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 57/2708 [00:14<11:28,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9221,  0.3088, -0.4489, -0.3684, -0.2524, -0.0571, -0.5076, -0.1804,\n",
      "        -0.2160, -0.0491, -0.4002, -0.8905,  0.1593], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 58/2708 [00:14<11:34,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4749, -0.3756, -0.3725, -0.5048, -0.4532], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 59/2708 [00:15<11:46,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2448, -0.8058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 60/2708 [00:15<11:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3131, -1.6650], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 61/2708 [00:15<11:45,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4681, -0.5944, -0.3451, -0.4504, -0.3806, -0.3288, -0.3684, -0.7651,\n",
      "        -0.3525, -0.0654, -0.5855], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 62/2708 [00:15<11:42,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1158,  0.6875, -1.3673, -0.8284], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 63/2708 [00:16<11:49,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6049, -0.1793, -0.9846, -0.9551, -0.0148, -0.7559], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 64/2708 [00:16<11:47,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4189, -1.4566], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 65/2708 [00:16<11:40,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1445, -0.6135], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 66/2708 [00:17<11:26,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6229, -0.6396, -0.7113, -0.1714], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ig_spar \u001b[38;5;241m=\u001b[39m \u001b[43mig_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIG Spar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mig_spar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mig_sparsity\u001b[1;34m(model, graph, data_object)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[0;32m     33\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mIG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     total_sparse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_nonzeros(exp\u001b[38;5;241m.\u001b[39mnode_imp)\u001b[38;5;241m/\u001b[39mexp\u001b[38;5;241m.\u001b[39menc_subgraph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(exp\u001b[38;5;241m.\u001b[39mnode_imp)\n",
      "Cell \u001b[1;32mIn[3], line 1020\u001b[0m, in \u001b[0;36mIG\u001b[1;34m(node_idx, x, edge_index, y, num_hops, steps, model, criterion)\u001b[0m\n\u001b[0;32m   1018\u001b[0m output \u001b[38;5;241m=\u001b[39m model(temp_x, sub_edge_index)\n\u001b[0;32m   1019\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output[mapping], label)\n\u001b[1;32m-> 1020\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m grad \u001b[38;5;241m=\u001b[39m temp_x\u001b[38;5;241m.\u001b[39mgrad[torch\u001b[38;5;241m.\u001b[39mwhere(subset\u001b[38;5;241m==\u001b[39mnode_idx)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m   1022\u001b[0m grads[i] \u001b[38;5;241m=\u001b[39m grad\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [04:38<00:00,  9.73it/s]\n",
      "100%|| 2708/2708 [12:55<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [11:26<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [12:32:29<00:00, 16.67s/it]        \n",
      "100%|| 2708/2708 [17:32<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [10:33<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
