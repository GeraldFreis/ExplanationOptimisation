{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook trains a model with additional loss for Stability on CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "import torch\n",
    "dataset = Planetoid(root='/tmp/Cora/', name='Cora')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import k_hop_subgraph, to_undirected\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.data import Data\n",
    "from graphxai.explainers._base import _BaseExplainer\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "\n",
    "class _BaseExplainer:\n",
    "    \"\"\"\n",
    "    Base Class for Explainers\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            model: nn.Module,\n",
    "            emb_layer_name: Optional[str] = None,\n",
    "            is_subgraphx: Optional[bool] = False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "                The output of the model should be unnormalized class score.\n",
    "                For example, last layer = GCNConv or Linear.\n",
    "            emb_layer_name (str, optional): name of the embedding layer\n",
    "                If not specified, use the last but one layer by default.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.L = len([module for module in self.model.modules()\n",
    "                      if isinstance(module, MessagePassing)])\n",
    "        self.explain_graph = False  # Assume node-level explanation by default\n",
    "        self.subgraphx_flag = is_subgraphx\n",
    "        self.__set_embedding_layer(emb_layer_name)\n",
    "\n",
    "    def __set_embedding_layer(self, emb_layer_name: str = None):\n",
    "        \"\"\"\n",
    "        Set the embedding layer (by default is the last but one layer).\n",
    "        \"\"\"\n",
    "        if emb_layer_name:\n",
    "            try:\n",
    "                self.emb_layer = getattr(self.model, emb_layer_name)\n",
    "            except AttributeError:\n",
    "                raise ValueError(f'{emb_layer_name} does not exist in the model')\n",
    "        else:\n",
    "            self.emb_layer = list(self.model.modules())[-2]\n",
    "\n",
    "    def _get_embedding(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                       forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the embedding.\n",
    "        \"\"\"\n",
    "        emb = self._get_activation(self.emb_layer, x, edge_index, forward_kwargs)\n",
    "        return emb\n",
    "\n",
    "    def _set_masks(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                   edge_mask: torch.Tensor = None, explain_feature: bool = False,\n",
    "                   device = None):\n",
    "        \"\"\"\n",
    "        Initialize the edge (and feature) masks.\n",
    "        \"\"\"\n",
    "        (n, d), m = x.shape, edge_index.shape[1]\n",
    "\n",
    "        # Initialize edge_mask and feature_mask for learning\n",
    "        std = torch.nn.init.calculate_gain('relu') * np.sqrt(2.0 / (2 * n))\n",
    "        if edge_mask is None:\n",
    "            edge_mask = (torch.randn(m) * std).to(device)\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        else:\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        if explain_feature:\n",
    "            feature_mask = (torch.randn(d) * 0.1).to(device)\n",
    "            self.feature_mask = torch.nn.Parameter(feature_mask)\n",
    "\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # Tell pytorch geometric to apply edge masks\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def _clear_masks(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.edge_mask = None\n",
    "        self.feature_mask = None\n",
    "\n",
    "    def _flow(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def _predict(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                 return_type: str = 'label', forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the model's prediction.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            return_type (str): one of ['label', 'prob', 'log_prob']\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            pred (torch.Tensor, [n x ...]): model prediction\n",
    "        \"\"\"\n",
    "        # Compute unnormalized class score\n",
    "        with torch.no_grad():\n",
    "            out = self.model.to(device)(x, edge_index, **forward_kwargs)\n",
    "            if return_type == 'label':\n",
    "                out = out.argmax(dim=-1)\n",
    "            elif return_type == 'prob':\n",
    "                out = F.softmax(out, dim=-1)\n",
    "            elif return_type == 'log_prob':\n",
    "                out = F.log_softmax(out, dim=-1)\n",
    "            else:\n",
    "                raise ValueError(\"return_type must be 'label', 'prob', or 'log_prob'\")\n",
    "\n",
    "            if self.explain_graph:\n",
    "                out = out.squeeze()\n",
    "\n",
    "            return out\n",
    "\n",
    "    def _prob_score_func_graph(self, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probability that the input graphs\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            target_class (int): the targeted class of the graph\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        def get_prob_score(x: torch.Tensor,\n",
    "                           edge_index: torch.Tensor,\n",
    "                           forward_kwargs: dict = {}):\n",
    "            prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                 forward_kwargs=forward_kwargs)\n",
    "            score = prob[:, target_class]\n",
    "            return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _prob_score_func_node(self, node_idx: torch.Tensor, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probabilities that k specified nodes\n",
    "        in `torch_geometric.data.Batch` (disconnected union of the input graphs)\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            node_idx (torch.Tensor, [k]): the indices of the k nodes interested\n",
    "            target_class (torch.Tensor, [k]): the targeted classes of the k nodes\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        if self.subgraphx_flag:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[node_idx, target_class]\n",
    "                return score\n",
    "        else:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[:, node_idx, target_class]\n",
    "                return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _get_activation(self, layer: nn.Module, x: torch.Tensor,\n",
    "                        edge_index: torch.Tensor, forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the activation of the layer.\n",
    "        \"\"\"\n",
    "        activation = {}\n",
    "        def get_activation():\n",
    "            def hook(model, inp, out):\n",
    "                activation['layer'] = out.detach()\n",
    "            return hook\n",
    "\n",
    "        layer.register_forward_hook(get_activation())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return activation['layer']\n",
    "\n",
    "    def _get_k_hop_subgraph(self, node_idx: int, x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor, num_hops: int = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Extract the subgraph of target node\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): the node index\n",
    "            x (torch.Tensor, [n x d]): node feature matrix with shape\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index\n",
    "            kwargs (dict): additional parameters of the graph\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # TODO: use NamedTuple\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        return khop_info\n",
    "\n",
    "    def get_explanation_node(self, node_idx: int,\n",
    "                             x: torch.Tensor,\n",
    "                             edge_index: torch.Tensor,\n",
    "                             label: torch.Tensor = None,\n",
    "                             num_hops: int = None,\n",
    "                             forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): index of the node to be explained\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            label (torch.Tensor, optional, [n x ...]): labels to explain\n",
    "                If not provided, we use the output of the model.\n",
    "            num_hops (int, optional): number of hops to consider\n",
    "                If not provided, we use the number of graph layers of the GNN.\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "            khop_info (4-tuple of torch.Tensor):\n",
    "                0. the nodes involved in the subgraph\n",
    "                1. the filtered `edge_index`\n",
    "                2. the mapping from node indices in `node_idx` to their new location\n",
    "                3. the `edge_index` mask indicating which edges were preserved\n",
    "        \"\"\"\n",
    "        # If labels are needed\n",
    "        label = self._predict(x, edge_index, return_type='label') if label is None else label\n",
    "        # If probabilities / log probabilities are needed\n",
    "        prob = self._predict(x, edge_index, return_type='prob')\n",
    "        log_prob = self._predict(x, edge_index, return_type='log_prob')\n",
    "\n",
    "        num_hops = self.L if num_hops is None else num_hops\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return exp, khop_info\n",
    "\n",
    "    def get_explanation_graph(self, edge_index: torch.Tensor,\n",
    "                              x: torch.Tensor, label: torch.Tensor,\n",
    "                              forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a whole-graph prediction.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            label (torch.Tensor, [n x ...]): labels to explain\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "        \"\"\"\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_explanation_link(self):\n",
    "        \"\"\"\n",
    "        Explain a link prediction.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph as subgraph\n",
    "\n",
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class _BaseDecomposition(_BaseExplainer):\n",
    "    '''\n",
    "    Code adapted from Dive into Graphs (DIG)\n",
    "    Code: https://github.com/divelab/DIG\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__(model=model) # Will set self.model = model\n",
    "        # Other properties: self.L (number of layers)\n",
    "\n",
    "    @property\n",
    "    def __num_hops__(self):\n",
    "        if self.explain_graph:\n",
    "            return -1\n",
    "        else:\n",
    "            return self.L\n",
    "    \n",
    "    def set_graph_attr(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.num_edges = edge_index.shape[1]\n",
    "        self.num_nodes = x.shape[0]\n",
    "        self.device = x.device\n",
    "\n",
    "    def extract_step(self, x: Tensor, edge_index: Tensor, detach: bool = True, split_fc: bool = False, forward_kwargs: dict = None):\n",
    "        '''Gets information about every layer in the graph\n",
    "        Args:\n",
    "\n",
    "            forward_kwargs (tuple, optional): Additional arguments to model forward call (other than x and edge_index)\n",
    "                (default: :obj:`None`)\n",
    "        '''\n",
    "\n",
    "        layer_extractor = []\n",
    "        hooks = []\n",
    "\n",
    "        def register_hook(module: nn.Module):\n",
    "            if not list(module.children()) or isinstance(module, MessagePassing):\n",
    "                hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "        def forward_hook(module: nn.Module, input: Tuple[Tensor], output: Tensor):\n",
    "            # input contains x and edge_index\n",
    "            if detach:\n",
    "                layer_extractor.append((module, input[0].clone().detach(), output.clone().detach()))\n",
    "            else:\n",
    "                layer_extractor.append((module, input[0], output))\n",
    "\n",
    "        # --- register hooks ---\n",
    "        self.model.apply(register_hook)\n",
    "\n",
    "        # ADDED: OWEN QUEEN --------------\n",
    "        if forward_kwargs is None:\n",
    "            _ = self.model(x, edge_index)\n",
    "        else:\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "        # --------------------------------\n",
    "        # Remove hooks:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        # --- divide layer sets ---\n",
    "\n",
    "        # print('Layer extractor', [layer_extractor[i][0] for i in range(len(layer_extractor))])\n",
    "\n",
    "        walk_steps = []\n",
    "        fc_steps = []\n",
    "        pool_flag = False\n",
    "        step = {'input': None, 'module': [], 'output': None}\n",
    "        for layer in layer_extractor:\n",
    "            if isinstance(layer[0], MessagePassing):\n",
    "                if step['module']: # Append step that had previously been building\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], GNNPool):\n",
    "                pool_flag = True\n",
    "                if step['module']:\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                # Putting in GNNPool\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], nn.Linear):\n",
    "                if step['module']:\n",
    "                    if isinstance(step['module'][0], MessagePassing):\n",
    "                        walk_steps.append(step) # Append MessagePassing layer to walk_steps\n",
    "                    else: # Always append Linear layers to fc_steps\n",
    "                        fc_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            # Also appends non-trainable layers to step (not modifying input):\n",
    "            step['module'].append(layer[0])\n",
    "            step['output'] = layer[2]\n",
    "\n",
    "        if step['module']:\n",
    "            if isinstance(step['module'][0], MessagePassing):\n",
    "                walk_steps.append(step)\n",
    "            else: # Append anything to FC that is not MessagePassing at its origin\n",
    "                # Still supports sequential layers\n",
    "                fc_steps.append(step)\n",
    "            # print('layer', layer[0])\n",
    "            # if isinstance(layer[0], MessagePassing) or isinstance(layer[0], GNNPool):\n",
    "            #     if isinstance(layer[0], GNNPool):\n",
    "            #         pool_flag = True\n",
    "            #     if step['module'] and step['input'] is not None:\n",
    "            #         walk_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # if pool_flag and split_fc and isinstance(layer[0], nn.Linear):\n",
    "            #     if step['module']:\n",
    "            #         fc_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # step['module'].append(layer[0])\n",
    "            # step['output'] = layer[2]\n",
    "\n",
    "        for walk_step in walk_steps:\n",
    "            if hasattr(walk_step['module'][0], 'nn') and walk_step['module'][0].nn is not None:\n",
    "                # We don't allow any outside nn during message flow process in GINs\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "            elif hasattr(walk_step['module'][0], 'lin') and walk_step['module'][0].lin is not None:\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "\n",
    "        # print('Walk steps', [walk_steps[i]['module'] for i in range(len(walk_steps))])\n",
    "        # print('fc steps', [fc_steps[i]['module'] for i in range(len(fc_steps))])\n",
    "\n",
    "        return walk_steps, fc_steps\n",
    "\n",
    "    def walks_pick(self,\n",
    "                   edge_index: Tensor,\n",
    "                   pick_edge_indices: List,\n",
    "                   walk_indices: List=[],\n",
    "                   num_layers=0\n",
    "                   ):\n",
    "        walk_indices_list = []\n",
    "        for edge_idx in pick_edge_indices:\n",
    "\n",
    "            # Adding one edge\n",
    "            walk_indices.append(edge_idx)\n",
    "            _, new_src = src, tgt = edge_index[:, edge_idx]\n",
    "            next_edge_indices = np.array((edge_index[0, :] == new_src).nonzero().view(-1))\n",
    "\n",
    "            # Finding next edge\n",
    "            if len(walk_indices) >= num_layers:\n",
    "                # return one walk\n",
    "                walk_indices_list.append(walk_indices.copy())\n",
    "            else:\n",
    "                walk_indices_list += self.walks_pick(edge_index, next_edge_indices, walk_indices, num_layers)\n",
    "\n",
    "            # remove the last edge\n",
    "            walk_indices.pop(-1)\n",
    "\n",
    "        return walk_indices_list\n",
    "\n",
    "class CAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, activation = None):\n",
    "        '''\n",
    "        .. note::\n",
    "            From Pope et al., CAM requires that the layer immediately before the softmax layer be\n",
    "            a global average pooling layer, or in the case of node classification, a graph convolutional\n",
    "            layer. Therefore, for this algorithm to theoretically work, there can be no fully-connected\n",
    "            layers after global pooling. There is no restriction in the code for this, but be warned. \n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            activation (method, optional): activation funciton for final layer in network. If `activation = None`,\n",
    "                explainer assumes linear activation. Use `activation = None` if the activation is applied\n",
    "                within the `forward` method of `model`, only set this parameter if another activation is\n",
    "                applied in the training procedure outside of model. (:default: :obj:`None`)\n",
    "        '''\n",
    "        super().__init__(model=model)\n",
    "        self.model = model\n",
    "\n",
    "        # Set activation function\n",
    "        self.activation = lambda x: x  if activation is None else activation\n",
    "        # i.e. linear activation if none provided\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                node_idx: int, \n",
    "                edge_index: torch.Tensor, \n",
    "                label: int = None,  \n",
    "                y = None,\n",
    "                forward_kwargs: dict = {},\n",
    "                directed: bool = False\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Explain one node prediction by the model\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.tensor): edge_index of entire graph\n",
    "            label (int, optional): Label on which to compute the explanation for\n",
    "                this node. If `None`, the predicted label from the model will be\n",
    "                used. (default: :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "            directed (bool, optional): If True, graph is directed.\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        if not directed:\n",
    "            edge_index = to_undirected(edge_index)\n",
    "\n",
    "        if label is None:\n",
    "            if y is None:\n",
    "                label = int(self.__forward_pass(x, edge_index, forward_kwargs).argmax(dim=1).item())\n",
    "            else:\n",
    "                label = y[node_idx]\n",
    "\n",
    "        # Perform walk:\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=False, split_fc=False, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        # Get subgraph:\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        #cam = torch.zeros(N) # Compute CAM only over the subgraph (all others are zero)\n",
    "        cam = torch.zeros(subgraph_N)\n",
    "        for i in range(subgraph_N):\n",
    "            n = subgraph_nodes[i]\n",
    "            cam[i] += self.__exp_node(n, walk_steps, label)\n",
    "\n",
    "        # Set Explanation class:\n",
    "        exp = Explanation(\n",
    "            node_imp = cam,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs = {}):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, predicted_c):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after last convolutiuonal layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        last_conv_layer = walk_steps[-1]\n",
    "\n",
    "        if isinstance(last_conv_layer['module'][0], GINConv):\n",
    "            weight_vec = last_conv_layer['module'][0].nn.weight[predicted_c, :].detach()  # last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], GCNConv):\n",
    "            weight_vec = last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], torch.nn.Linear):\n",
    "            weight_vec = last_conv_layer['module'][0].weight[predicted_c, :].detach()\n",
    "\n",
    "        F_l_n = F.relu(last_conv_layer['input'][node_idx,:]).detach()\n",
    "\n",
    "        L_cam_n = F.relu(torch.matmul(weight_vec, F_l_n))\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "\n",
    "class GradCAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Gradient Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.Tensor, criterion = F.cross_entropy):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "            x: torch.Tensor, \n",
    "            y: torch.Tensor, \n",
    "            node_idx: int, \n",
    "            edge_index: torch.Tensor, \n",
    "            label: int = None, \n",
    "            forward_kwargs: dict = {}, \n",
    "            average_variant: bool = True, \n",
    "            layer: int = 0\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a node in the given graph\n",
    "        Args:\n",
    "            x (torch.Tensor, (n,)): Tensor of node features from the entire graph, with n nodes.\n",
    "            y (torch.Tensor, (n,)): Ground-truth labels for all n nodes in the graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.Tensor): Edge_index of entire graph.\n",
    "            label (int, optional): Label for which to compute Grad-CAM against. If None, computes\n",
    "                the Grad-CAM with respect to the model's predicted class for this node.\n",
    "                (default :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. (default: :obj:`None`)\n",
    "            average_variant (bool, optional): If True, computes the average Grad-CAM across all convolutional\n",
    "                layers in the model. If False, computes Grad-CAM for `layer`. (default: :obj:`True`)\n",
    "            layer (int, optional): Layer by which to compute the Grad-CAM. Argument only has an effect if \n",
    "                `average_variant == True`. Must be less-than the total number of convolutional layers\n",
    "                in the model. (default: :obj:`0`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        x = x.detach().clone()\n",
    "        y = y.detach().clone()\n",
    "\n",
    "        x.requires_grad = True\n",
    "\n",
    "        if label is None:\n",
    "            pred = self.__forward_pass(x, y, edge_index, forward_kwargs)[0][node_idx, :].reshape(1, -1)\n",
    "            y[node_idx] = pred.argmax(dim=1).item()\n",
    "        else: # Transform node_idx's label if provided by user\n",
    "            pred, loss = self.__forward_pass(x, y, edge_index, forward_kwargs)\n",
    "            y[node_idx] = label\n",
    "\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=True, split_fc=True, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx, self.L, edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        if average_variant:\n",
    "            # Size of all nodes in the subgraph:\n",
    "            avg_gcam = torch.zeros(subgraph_N)\n",
    "\n",
    "            for l in range(self.L):\n",
    "                # Compute gradients for this layer ahead of time:\n",
    "                gradients = self.__grad_by_layer(l)\n",
    "\n",
    "                for i in range(subgraph_N): # Over all subgraph nodes\n",
    "                    n = subgraph_nodes[i]\n",
    "                    avg_gcam[i] += self.__get_gCAM_layer(walk_steps, l, n, gradients)\n",
    "\n",
    "            avg_gcam /= self.L # Apply average\n",
    "\n",
    "            exp.node_imp = avg_gcam\n",
    "\n",
    "        else:\n",
    "            assert layer < len(walk_steps), \"Layer must be an index of convolutional layers\"\n",
    "\n",
    "            gcam = torch.zeros(subgraph_N)\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "            for i in range(subgraph_N):\n",
    "                n = subgraph_nodes[i]\n",
    "                gcam[i] += self.__get_gCAM_layer(walk_steps, layer, n, gradients)#[0]\n",
    "\n",
    "            exp.node_imp = gcam\n",
    "\n",
    "        return exp\n",
    "        \n",
    "    def __forward_pass(self, x, label, edge_index, forward_kwargs):\n",
    "        x.requires_grad = True # Enforce that x needs gradient\n",
    "\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        loss = self.criterion(pred, label)\n",
    "        loss.backward() # Propagate loss backward through network\n",
    "\n",
    "        return pred, loss\n",
    "\n",
    "    def __grad_by_layer(self, layer):\n",
    "        # Index 0 of parameters to avoid calculating gradients for biases\n",
    "        module_at_layer = list(self.model.children())[layer]\n",
    "\n",
    "        if isinstance(module_at_layer, GCNConv):\n",
    "            grad = module_at_layer.lin.weight.grad\n",
    "        elif isinstance(module_at_layer, GINConv):\n",
    "            grad = module_at_layer.nn.weight.grad\n",
    "        else:\n",
    "            grad = module_at_layer.weight.grad\n",
    "\n",
    "        return grad.mean(dim=1)\n",
    "\n",
    "    def __get_gCAM_layer(self, walk_steps, layer, node_idx = None, gradients = None):\n",
    "        # Gets Grad CAM for one layer\n",
    "        if gradients is None:\n",
    "            # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "            # ''        '' shape: [k,] - k= # output features from layer l\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "\n",
    "        if node_idx is None: # Need to compute for entire graph:\n",
    "            node_explanations = []\n",
    "            for n in range(self.N):\n",
    "                node_explanations.append(self.__exp_node(n, walk_steps, layer, gradients))\n",
    "\n",
    "            return node_explanations\n",
    "\n",
    "        # Return for only one node:\n",
    "        return self.__exp_node(node_idx, walk_steps, layer, gradients)\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, layer, gradients):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after each convolutional layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "        # ''        '' shape: [k,] - k= # input features to layer l\n",
    "\n",
    "        # Activations for node n\n",
    "        F_l_n = F.relu(walk_steps[layer]['output'][node_idx,:]).detach()\n",
    "        L_cam_n = F.relu(torch.matmul(gradients, F_l_n)) # Combine gradients and activations\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "# from ._decomp_base_old import _BaseDecomposition\n",
    "\n",
    "def clip_hook(grad):\n",
    "    # Apply ReLU activation to gradient\n",
    "    return torch.clamp(grad, min=0)\n",
    "import gc\n",
    "\n",
    "class GuidedBP(_BaseDecomposition):\n",
    "\n",
    "    def __init__(self, model, criterion = F.cross_entropy, enforce_requires_grad = True):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.L = len([module for module in self.model.modules() if isinstance(module, MessagePassing)])\n",
    "\n",
    "        self.registered_hooks = []\n",
    "\n",
    "        self.enforce_requires_grad = enforce_requires_grad\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor,\n",
    "                edge_index: torch.Tensor,  \n",
    "                node_idx: int, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Get Guided Backpropagation explanation for one node in the graph\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            y (torch.Tensor): Ground truth labels correspond to each node's \n",
    "                classification. This argument is input to the `criterion` \n",
    "                function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the enclosing \n",
    "                subgraph. Must support `dim` argument.\n",
    "                (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        if self.enforce_requires_grad:\n",
    "            try:\n",
    "                x = x.detach().clone()\n",
    "                x.requires_grad = True\n",
    "            except:\n",
    "                pass\n",
    "        # assert x.requires_grad, 'x must have requires_grad == True'\n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        graph_exp = x.grad\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        node_imp = aggregate_node_imp(torch.stack([graph_exp[i,:] for i in subgraph_nodes]).detach(), dim=1)\n",
    "\n",
    "        # Get only those explanations for nodes in the subgraph:\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        \n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        return exp\n",
    "\n",
    "    def get_explanation_graph(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor, \n",
    "                edge_index: torch.Tensor, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a whole-graph prediction with Guided Backpropagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor of node features from the entire graph.\n",
    "            y (torch.tensor): Ground truth label of given input. This argument is \n",
    "                input to the `criterion` function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the graph. \n",
    "                Must support `dim` argument. (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)   \n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method. \n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [num_nodes, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `graph`: :obj:`torch_geometric.data.Data`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        try:\n",
    "            x.requires_grad = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        assert x.requires_grad, 'x must have requires_grad == True' \n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        node_imp = aggregate_node_imp(x.grad, dim=1)\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp\n",
    "        )\n",
    "    \n",
    "        exp.set_whole_graph(Data(x, edge_index))\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __apply_hooks(self):\n",
    "        self.registered_hooks = []\n",
    "        for p in self.model.parameters():\n",
    "            h = p.register_hook(clip_hook)\n",
    "            self.registered_hooks.append(h)\n",
    "\n",
    "    def __rm_hooks(self):\n",
    "        for h in self.registered_hooks:\n",
    "            h.remove()\n",
    "        self.registered_hooks = []\n",
    "    \n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        self.__apply_hooks()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "from graphxai.utils import Explanation\n",
    "class IG():\n",
    "    def __init__(self, model, hops: Optional[int] = 1, criterion = None):\n",
    "        self.model = model\n",
    "        self.num_hops = hops\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def node_explanations(self, node_idx: int, \n",
    "            x: torch.Tensor,\n",
    "            edge_index: torch.Tensor, \n",
    "            y: Optional[torch.Tensor] = None,):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): Index of the node to be explained.\n",
    "            edge_index (torch.Tensor, [2 x m]): Edge index of the graph.\n",
    "            x (torch.Tensor, [n x d]): Node features.\n",
    "            label (torch.Tensor, [n x ...]): Labels to explain.\n",
    "            y (torch.Tensor): Same as `label`, provided for general \n",
    "                compatibility in the arguments. (:default: :obj:`None`)\n",
    "            num_hops (int, optional): Number of hops in the enclosing \n",
    "                subgraph. If `None`, set to the number of layers in \n",
    "                the GNN. (:default: :obj:`None`)\n",
    "            steps (int, optional): Number of steps for the Riemannian \n",
    "                integration. (:default: :obj:`40`)\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`torch.Tensor, [x.shape[1],]`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :class:`graphxai.utils.EnclosingSubgraph`\n",
    "        \"\"\"\n",
    "\n",
    "        if (y is None):\n",
    "            raise ValueError('Either label or y should be provided for Integrated Gradients')\n",
    "\n",
    "        label = y[node_idx]\n",
    "        if len(label.shape) == 0:\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, self.num_hops, edge_index,\n",
    "                            relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "        steps = 40\n",
    "        self.model.eval()\n",
    "        grads = torch.zeros(steps+1, x.shape[1]).to(device)\n",
    "\n",
    "        # Perform Riemannian integration\n",
    "        for i in range(steps+1):\n",
    "            with torch.no_grad():\n",
    "                baseline = torch.zeros_like(sub_x).to(device)  # TODO: baseline all 0s, all 1s, ...?\n",
    "                temp_x = baseline + (float(i)/steps) * (sub_x.clone()-baseline)\n",
    "            temp_x.requires_grad = True\n",
    "            output = self.model(temp_x, sub_edge_index)\n",
    "            loss = self.criterion(output[mapping], label)\n",
    "            loss.backward()\n",
    "            grad = temp_x.grad[torch.where(subset==node_idx)[0].item()]\n",
    "            grads[i] = grad\n",
    "\n",
    "        grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "        avg_grads = torch.mean(grads, axis=0)\n",
    "\n",
    "        # Integrated gradients for only node_idx:\n",
    "        # baseline[0] just gets a single-value 0-tensor\n",
    "        integrated_gradients = ((x[torch.where(subset == node_idx)[0].item()]\n",
    "                                    - baseline[0]) * avg_grads)\n",
    "\n",
    "        # Integrated gradients across the enclosing subgraph:\n",
    "        all_node_ig = ((x[subset] - baseline) * avg_grads)\n",
    "        node_importances = torch.sum(all_node_ig, dim=1)\n",
    "        exp = Explanation(\n",
    "            feature_imp = integrated_gradients,\n",
    "            node_imp = node_importances,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        gc.collect()\n",
    "        return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import random\n",
    "from copy import deepcopy\n",
    "random.seed(12345)\n",
    "def perturbed_edge_list(data: torch_geometric.data.Data, n_to_add: int = 2)->torch_geometric.data.Data:\n",
    "    \"\"\"Adding two random nodes to each node\"\"\"\n",
    "    # Do not want seed here\n",
    "    edge_list = data.edge_index\n",
    "    # torch.cat((edge_list, torch.LongTensor((1,2)).to(device).reshape(1,-1)), dim=-1)\n",
    "    # print(edge_list)\n",
    "    data = deepcopy(data)\n",
    "    for node in range(data.x.shape[0]):\n",
    "        # generating two random nodes to add to its adjacency list\n",
    "        for i in range(n_to_add):\n",
    "            n1 = randint(0, data.x.shape[0]-1)\n",
    "            new1 = torch.cat((edge_list[0], torch.LongTensor([node]).to(device)), axis=-1)\n",
    "            new2 = torch.cat((edge_list[1], torch.LongTensor([n1]).to(device)), axis=-1)\n",
    "            edge_list = torch.cat([new1.reshape(1,-1), new2.reshape(1,-1)])\n",
    "    data.edge_index = edge_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def explanation_list_to_matrix(l: list, data)->torch.Tensor:\n",
    "    len_l = len(l)\n",
    "    matrix = torch.zeros((len_l, data.x.shape[0]))\n",
    "    with tqdm(total=len_l) as pbar:\n",
    "        for i, exp in enumerate(l):\n",
    "            pbar.update(1)\n",
    "            subgraph = exp.enc_subgraph.nodes\n",
    "            for j, n in enumerate(subgraph):\n",
    "                n = n.item()\n",
    "                matrix[i][n] = exp.node_imp[j].item()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def stability(generated_exp_unperturbed, generated_exp_perturbed ) -> float:\n",
    "    \"\"\"takes in two matrices the first is unperturbed explanations and the second are perturbed via the addition of a random node\n",
    "        - We assume here that the explanations are in their padded form that is: that the explanation vectors in the list have nodes at equal positions \"\"\"\n",
    "    stability = float() \n",
    "    # Accessing the enclosing subgraph. Will be the same for both explanation.:\n",
    "    stability = abs( np.linalg.norm(np.matrix(generated_exp_unperturbed.numpy())) - np.linalg.norm(np.matrix(generated_exp_perturbed.numpy())) )\n",
    "    return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the random nodes\n",
    "from random import sample\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "# I now want all nodes for each given class (there are 7), and I will randomly select 50 of each class\n",
    "class_0 = [idx for idx, val in enumerate(data.y) if val == 0]\n",
    "class_1 = [idx for idx, val in enumerate(data.y) if val == 1]\n",
    "class_2 = [idx for idx, val in enumerate(data.y) if val == 2]\n",
    "class_3 = [idx for idx, val in enumerate(data.y) if val == 3]\n",
    "class_4 = [idx for idx, val in enumerate(data.y) if val == 4]\n",
    "class_5 = [idx for idx, val in enumerate(data.y) if val == 5]\n",
    "class_6 = [idx for idx, val in enumerate(data.y) if val == 6]\n",
    "\n",
    "random_class_0 = sample(class_0, k=50)\n",
    "random_class_1 = sample(class_1, k=50)\n",
    "random_class_2 = sample(class_2, k=50)\n",
    "random_class_3 = sample(class_3, k=50)\n",
    "random_class_4 = sample(class_4, k=50)\n",
    "random_class_5 = sample(class_5, k=50)\n",
    "random_class_6 = sample(class_6, k=50)\n",
    "\n",
    "\n",
    "random_nodes = random_class_0\n",
    "random_nodes.extend(random_class_1)\n",
    "random_nodes.extend(random_class_2)\n",
    "random_nodes.extend(random_class_3)\n",
    "random_nodes.extend(random_class_4)\n",
    "random_nodes.extend(random_class_5)\n",
    "random_nodes.extend(random_class_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 818, 4: 426, 0: 351, 2: 418, 1: 217, 5: 298, 6: 180})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbp_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    bp_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = GuidedBP(model=model)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            bp_exps.append(exp)\n",
    "    return bp_exps\n",
    "\n",
    "def cam_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    cam_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = CAM(model=model)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x = data_object.x, edge_index = data_object.edge_index,  y = data_object.y)\n",
    "            cam_exps.append(exp)\n",
    "    return cam_exps\n",
    "\n",
    "def ig_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    ig_exps = list()\n",
    "    model.eval()\n",
    "    ig = IG(model=model, criterion=torch.nn.CrossEntropyLoss(), hops=1)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = ig.node_explanations(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            ig_exps.append(exp)\n",
    "    return ig_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_data = perturbed_edge_list(data=data).to(device) # this is our perturbed data to check against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 350/350 [00:06<00:00, 55.23it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 645.76it/s]\n",
      "100%|| 350/350 [00:01<00:00, 221.30it/s]\n",
      "100%|| 350/350 [00:05<00:00, 58.54it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.72it/s]\n",
      "100%|| 350/350 [00:00<00:00, 467.29it/s]\n",
      "100%|| 350/350 [00:01<00:00, 274.90it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.92it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.54it/s]\n",
      "100%|| 350/350 [00:00<00:00, 655.17it/s]\n",
      "100%|| 350/350 [00:01<00:00, 268.28it/s]\n",
      "100%|| 350/350 [00:06<00:00, 54.34it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.74it/s]\n",
      "100%|| 350/350 [00:00<00:00, 657.68it/s]\n",
      "100%|| 350/350 [00:01<00:00, 297.82it/s]\n",
      "100%|| 350/350 [00:06<00:00, 53.25it/s]\n",
      "100%|| 350/350 [00:12<00:00, 29.10it/s]\n",
      "100%|| 350/350 [00:00<00:00, 405.97it/s]\n",
      "100%|| 350/350 [00:01<00:00, 300.31it/s]\n",
      "100%|| 350/350 [00:05<00:00, 60.82it/s] \n",
      "100%|| 350/350 [00:12<00:00, 27.06it/s]\n",
      "100%|| 350/350 [00:00<00:00, 537.52it/s]\n",
      "100%|| 350/350 [00:01<00:00, 303.25it/s]\n",
      "100%|| 350/350 [00:05<00:00, 58.66it/s] \n",
      "100%|| 350/350 [00:11<00:00, 30.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 591.22it/s]\n",
      "100%|| 350/350 [00:01<00:00, 265.29it/s]\n",
      "100%|| 350/350 [00:06<00:00, 55.00it/s]\n",
      "100%|| 350/350 [00:12<00:00, 28.78it/s]\n",
      "100%|| 350/350 [00:00<00:00, 615.95it/s]\n",
      "100%|| 350/350 [00:01<00:00, 248.52it/s]\n",
      "100%|| 350/350 [00:06<00:00, 54.90it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.29it/s]\n",
      "100%|| 350/350 [00:00<00:00, 612.79it/s]\n",
      "100%|| 350/350 [00:01<00:00, 299.62it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.38it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.91it/s]\n",
      "100%|| 350/350 [00:00<00:00, 623.89it/s]\n",
      "100%|| 350/350 [00:01<00:00, 253.99it/s]\n",
      "100%|| 350/350 [00:06<00:00, 55.86it/s]\n",
      "100%|| 350/350 [00:12<00:00, 28.41it/s]\n",
      "100%|| 350/350 [00:00<00:00, 669.22it/s]\n",
      "100%|| 350/350 [00:01<00:00, 285.42it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.11it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.42it/s]\n",
      "100%|| 350/350 [00:00<00:00, 587.05it/s]\n",
      "100%|| 350/350 [00:01<00:00, 260.19it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.57it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.34it/s]\n",
      "100%|| 350/350 [00:00<00:00, 674.13it/s]\n",
      "100%|| 350/350 [00:01<00:00, 279.70it/s]\n",
      "100%|| 350/350 [00:06<00:00, 57.11it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 656.40it/s]\n",
      "100%|| 350/350 [00:01<00:00, 230.55it/s]\n",
      "100%|| 350/350 [00:06<00:00, 55.97it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.59it/s]\n",
      "100%|| 350/350 [00:00<00:00, 663.65it/s]\n",
      "100%|| 350/350 [00:01<00:00, 275.99it/s]\n",
      "100%|| 350/350 [00:06<00:00, 54.27it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.86it/s]\n",
      "100%|| 350/350 [00:00<00:00, 598.29it/s]\n",
      "100%|| 350/350 [00:01<00:00, 245.93it/s]\n",
      "100%|| 350/350 [00:06<00:00, 55.71it/s]\n",
      "100%|| 350/350 [00:12<00:00, 28.13it/s]\n",
      "100%|| 350/350 [00:00<00:00, 588.24it/s]\n",
      "100%|| 350/350 [00:01<00:00, 292.08it/s]\n",
      "100%|| 350/350 [00:06<00:00, 54.03it/s]\n",
      "100%|| 350/350 [00:11<00:00, 30.08it/s]\n",
      "100%|| 350/350 [00:00<00:00, 580.23it/s]\n",
      "100%|| 350/350 [00:01<00:00, 260.38it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.41it/s]\n",
      "100%|| 350/350 [00:11<00:00, 29.50it/s]\n",
      "100%|| 350/350 [00:00<00:00, 614.88it/s]\n",
      "100%|| 350/350 [00:01<00:00, 255.20it/s]\n",
      "100%|| 350/350 [00:05<00:00, 64.66it/s] \n",
      "100%|| 350/350 [00:09<00:00, 35.23it/s]\n",
      "100%|| 350/350 [00:00<00:00, 760.87it/s]\n",
      "100%|| 350/350 [00:01<00:00, 259.20it/s]\n",
      "100%|| 350/350 [00:06<00:00, 54.26it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.57it/s]\n",
      "100%|| 350/350 [00:00<00:00, 414.58it/s]\n",
      "100%|| 350/350 [00:01<00:00, 196.72it/s]\n",
      "100%|| 350/350 [00:07<00:00, 48.81it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.02it/s]\n",
      "100%|| 350/350 [00:00<00:00, 521.61it/s]\n",
      "100%|| 350/350 [00:01<00:00, 261.48it/s]\n",
      "100%|| 350/350 [00:06<00:00, 53.53it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.12it/s]\n",
      "100%|| 350/350 [00:00<00:00, 444.09it/s]\n",
      "100%|| 350/350 [00:01<00:00, 206.96it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.49it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.64it/s]\n",
      "100%|| 350/350 [00:00<00:00, 495.05it/s]\n",
      "100%|| 350/350 [00:01<00:00, 213.91it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.57it/s]\n",
      "100%|| 350/350 [00:12<00:00, 26.95it/s]\n",
      "100%|| 350/350 [00:00<00:00, 404.16it/s]\n",
      "100%|| 350/350 [00:01<00:00, 250.45it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.31it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.50it/s]\n",
      "100%|| 350/350 [00:00<00:00, 368.81it/s]\n",
      "100%|| 350/350 [00:01<00:00, 253.00it/s]\n",
      "100%|| 350/350 [00:06<00:00, 55.53it/s] \n",
      "100%|| 350/350 [00:13<00:00, 25.74it/s]\n",
      "100%|| 350/350 [00:00<00:00, 535.99it/s]\n",
      "100%|| 350/350 [00:01<00:00, 235.35it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.34it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.84it/s]\n",
      "100%|| 350/350 [00:00<00:00, 467.17it/s]\n",
      "100%|| 350/350 [00:01<00:00, 224.36it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.61it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.91it/s]\n",
      "100%|| 350/350 [00:00<00:00, 492.27it/s]\n",
      "100%|| 350/350 [00:01<00:00, 260.13it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.13it/s]\n",
      "100%|| 350/350 [00:12<00:00, 28.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 584.03it/s]\n",
      "100%|| 350/350 [00:01<00:00, 249.25it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.97it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.51it/s]\n",
      "100%|| 350/350 [00:00<00:00, 489.95it/s]\n",
      "100%|| 350/350 [00:01<00:00, 226.98it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.96it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.58it/s]\n",
      "100%|| 350/350 [00:00<00:00, 494.35it/s]\n",
      "100%|| 350/350 [00:01<00:00, 208.18it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.98it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.34it/s]\n",
      "100%|| 350/350 [00:00<00:00, 467.77it/s]\n",
      "100%|| 350/350 [00:01<00:00, 214.25it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.47it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.77it/s]\n",
      "100%|| 350/350 [00:00<00:00, 493.65it/s]\n",
      "100%|| 350/350 [00:01<00:00, 209.96it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.28it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 466.55it/s]\n",
      "100%|| 350/350 [00:01<00:00, 204.40it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.76it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.52it/s]\n",
      "100%|| 350/350 [00:00<00:00, 421.18it/s]\n",
      "100%|| 350/350 [00:01<00:00, 207.10it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.89it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.88it/s]\n",
      "100%|| 350/350 [00:00<00:00, 480.67it/s]\n",
      "100%|| 350/350 [00:01<00:00, 201.81it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.25it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.09it/s]\n",
      "100%|| 350/350 [00:00<00:00, 502.79it/s]\n",
      "100%|| 350/350 [00:01<00:00, 210.19it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.12it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.83it/s]\n",
      "100%|| 350/350 [00:00<00:00, 493.65it/s]\n",
      "100%|| 350/350 [00:01<00:00, 219.69it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.13it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.13it/s]\n",
      "100%|| 350/350 [00:00<00:00, 481.34it/s]\n",
      "100%|| 350/350 [00:01<00:00, 208.94it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.87it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.06it/s]\n",
      "100%|| 350/350 [00:00<00:00, 503.47it/s]\n",
      "100%|| 350/350 [00:01<00:00, 212.64it/s]\n",
      "100%|| 350/350 [00:04<00:00, 70.30it/s]\n",
      "100%|| 350/350 [00:10<00:00, 31.98it/s]\n",
      "100%|| 350/350 [00:00<00:00, 476.84it/s]\n",
      "100%|| 350/350 [00:01<00:00, 223.07it/s]\n",
      "100%|| 350/350 [00:07<00:00, 48.16it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.28it/s]\n",
      "100%|| 350/350 [00:00<00:00, 504.20it/s]\n",
      "100%|| 350/350 [00:01<00:00, 210.44it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.82it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.40it/s]\n",
      "100%|| 350/350 [00:00<00:00, 442.38it/s]\n",
      "100%|| 350/350 [00:01<00:00, 214.29it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.13it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.13it/s]\n",
      "100%|| 350/350 [00:00<00:00, 505.65it/s]\n",
      "100%|| 350/350 [00:01<00:00, 201.58it/s]\n",
      "100%|| 350/350 [00:05<00:00, 61.17it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.12it/s]\n",
      "100%|| 350/350 [00:00<00:00, 466.46it/s]\n",
      "100%|| 350/350 [00:01<00:00, 205.26it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.82it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 497.08it/s]\n",
      "100%|| 350/350 [00:01<00:00, 184.19it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.15it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.79it/s]\n",
      "100%|| 350/350 [00:00<00:00, 502.87it/s]\n",
      "100%|| 350/350 [00:01<00:00, 228.73it/s]\n",
      "100%|| 350/350 [00:06<00:00, 54.38it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.32it/s]\n",
      "100%|| 350/350 [00:00<00:00, 492.16it/s]\n",
      "100%|| 350/350 [00:01<00:00, 224.03it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.32it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.00it/s]\n",
      "100%|| 350/350 [00:00<00:00, 471.53it/s]\n",
      "100%|| 350/350 [00:01<00:00, 222.59it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.25it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.62it/s]\n",
      "100%|| 350/350 [00:00<00:00, 503.60it/s]\n",
      "100%|| 350/350 [00:01<00:00, 226.24it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.89it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.72it/s]\n",
      "100%|| 350/350 [00:00<00:00, 494.21it/s]\n",
      "100%|| 350/350 [00:01<00:00, 223.04it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.73it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.97it/s]\n",
      "100%|| 350/350 [00:00<00:00, 496.96it/s]\n",
      "100%|| 350/350 [00:01<00:00, 205.35it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.69it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.39it/s]\n",
      "100%|| 350/350 [00:00<00:00, 483.43it/s]\n",
      "100%|| 350/350 [00:01<00:00, 184.05it/s]\n",
      "100%|| 350/350 [00:06<00:00, 52.13it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.88it/s]\n",
      "100%|| 350/350 [00:00<00:00, 499.29it/s]\n",
      "100%|| 350/350 [00:02<00:00, 171.23it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.06it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.58it/s]\n",
      "100%|| 350/350 [00:00<00:00, 483.43it/s]\n",
      "100%|| 350/350 [00:01<00:00, 180.86it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.82it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 445.86it/s]\n",
      "100%|| 350/350 [00:01<00:00, 223.90it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.95it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.53it/s]\n",
      "100%|| 350/350 [00:00<00:00, 438.60it/s]\n",
      "100%|| 350/350 [00:01<00:00, 219.81it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.62it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 476.84it/s]\n",
      "100%|| 350/350 [00:01<00:00, 223.19it/s]\n",
      "100%|| 350/350 [00:07<00:00, 46.16it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.28it/s]\n",
      "100%|| 350/350 [00:00<00:00, 421.57it/s]\n",
      "100%|| 350/350 [00:01<00:00, 209.94it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.01it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.34it/s]\n",
      "100%|| 350/350 [00:00<00:00, 477.37it/s]\n",
      "100%|| 350/350 [00:01<00:00, 212.23it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.61it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.78it/s]\n",
      "100%|| 350/350 [00:00<00:00, 397.73it/s]\n",
      "100%|| 350/350 [00:01<00:00, 225.94it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.34it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.55it/s]\n",
      "100%|| 350/350 [00:00<00:00, 465.97it/s]\n",
      "100%|| 350/350 [00:01<00:00, 223.46it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.73it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.60it/s]\n",
      "100%|| 350/350 [00:00<00:00, 473.50it/s]\n",
      "100%|| 350/350 [00:01<00:00, 213.37it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.37it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.96it/s]\n",
      "100%|| 350/350 [00:00<00:00, 460.53it/s]\n",
      "100%|| 350/350 [00:01<00:00, 227.98it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.55it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.47it/s]\n",
      "100%|| 350/350 [00:00<00:00, 439.15it/s]\n",
      "100%|| 350/350 [00:01<00:00, 204.42it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.40it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 503.60it/s]\n",
      "100%|| 350/350 [00:01<00:00, 195.80it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.70it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.36it/s]\n",
      "100%|| 350/350 [00:00<00:00, 367.93it/s]\n",
      "100%|| 350/350 [00:01<00:00, 227.39it/s]\n",
      "100%|| 350/350 [00:06<00:00, 50.46it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.65it/s]\n",
      "100%|| 350/350 [00:00<00:00, 480.02it/s]\n",
      "100%|| 350/350 [00:01<00:00, 198.72it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.52it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 433.08it/s]\n",
      "100%|| 350/350 [00:01<00:00, 216.43it/s]\n",
      "100%|| 350/350 [00:06<00:00, 51.52it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.55it/s]\n",
      "100%|| 350/350 [00:00<00:00, 474.79it/s]\n",
      "100%|| 350/350 [00:01<00:00, 210.16it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.31it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.34it/s]\n",
      "100%|| 350/350 [00:00<00:00, 491.57it/s]\n",
      "100%|| 350/350 [00:01<00:00, 200.44it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.93it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.37it/s]\n",
      "100%|| 350/350 [00:00<00:00, 456.25it/s]\n",
      "100%|| 350/350 [00:01<00:00, 190.93it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.31it/s]\n",
      "100%|| 350/350 [00:14<00:00, 23.69it/s]\n",
      "100%|| 350/350 [00:00<00:00, 391.44it/s]\n",
      "100%|| 350/350 [00:02<00:00, 162.10it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.24it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.10it/s]\n",
      "100%|| 350/350 [00:00<00:00, 483.32it/s]\n",
      "100%|| 350/350 [00:01<00:00, 211.48it/s]\n",
      "100%|| 350/350 [00:05<00:00, 68.37it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.15it/s]\n",
      "100%|| 350/350 [00:00<00:00, 507.99it/s]\n",
      "100%|| 350/350 [00:01<00:00, 216.58it/s]\n",
      "100%|| 350/350 [00:07<00:00, 48.23it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.63it/s]\n",
      "100%|| 350/350 [00:00<00:00, 434.78it/s]\n",
      "100%|| 350/350 [00:01<00:00, 226.35it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.32it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.58it/s]\n",
      "100%|| 350/350 [00:00<00:00, 480.11it/s]\n",
      "100%|| 350/350 [00:01<00:00, 202.62it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.17it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.15it/s]\n",
      "100%|| 350/350 [00:00<00:00, 452.20it/s]\n",
      "100%|| 350/350 [00:01<00:00, 178.93it/s]\n",
      "100%|| 350/350 [00:05<00:00, 63.22it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.36it/s]\n",
      "100%|| 350/350 [00:00<00:00, 435.16it/s]\n",
      "100%|| 350/350 [00:01<00:00, 196.40it/s]\n",
      "100%|| 350/350 [00:07<00:00, 48.07it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.98it/s]\n",
      "100%|| 350/350 [00:00<00:00, 413.55it/s]\n",
      "100%|| 350/350 [00:02<00:00, 160.38it/s]\n",
      "100%|| 350/350 [00:07<00:00, 48.00it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.07it/s]\n",
      "100%|| 350/350 [00:00<00:00, 355.33it/s]\n",
      "100%|| 350/350 [00:01<00:00, 196.62it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.95it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.26it/s]\n",
      "100%|| 350/350 [00:00<00:00, 483.43it/s]\n",
      "100%|| 350/350 [00:01<00:00, 200.04it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.42it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.50it/s]\n",
      "100%|| 350/350 [00:00<00:00, 464.09it/s]\n",
      "100%|| 350/350 [00:01<00:00, 209.91it/s]\n",
      "100%|| 350/350 [00:05<00:00, 58.55it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.60it/s]\n",
      "100%|| 350/350 [00:00<00:00, 490.88it/s]\n",
      "100%|| 350/350 [00:01<00:00, 222.89it/s]\n",
      "100%|| 350/350 [00:07<00:00, 44.56it/s]\n",
      "100%|| 350/350 [00:12<00:00, 27.60it/s]\n",
      "100%|| 350/350 [00:00<00:00, 433.17it/s]\n",
      "100%|| 350/350 [00:01<00:00, 221.77it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.30it/s]\n",
      "100%|| 350/350 [00:13<00:00, 25.13it/s]\n",
      "100%|| 350/350 [00:00<00:00, 486.79it/s]\n",
      "100%|| 350/350 [00:01<00:00, 203.45it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.59it/s]\n",
      "100%|| 350/350 [00:13<00:00, 26.23it/s]\n",
      "100%|| 350/350 [00:00<00:00, 381.60it/s]\n",
      "100%|| 350/350 [00:02<00:00, 171.39it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.50it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.84it/s]\n",
      "100%|| 350/350 [00:00<00:00, 428.22it/s]\n",
      "100%|| 350/350 [00:01<00:00, 194.18it/s]\n",
      "100%|| 350/350 [00:07<00:00, 49.34it/s]\n",
      "100%|| 350/350 [00:15<00:00, 22.72it/s]\n",
      "100%|| 350/350 [00:00<00:00, 505.05it/s]\n",
      "100%|| 350/350 [00:01<00:00, 196.59it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.88it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 482.09it/s]\n",
      "100%|| 350/350 [00:01<00:00, 207.44it/s]\n",
      "100%|| 350/350 [00:08<00:00, 43.73it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 502.88it/s]\n",
      "100%|| 350/350 [00:01<00:00, 188.26it/s]\n",
      "100%|| 350/350 [00:07<00:00, 47.81it/s]\n",
      "100%|| 350/350 [00:14<00:00, 23.80it/s]\n",
      "100%|| 350/350 [00:00<00:00, 489.51it/s]\n",
      "100%|| 350/350 [00:01<00:00, 205.10it/s]\n",
      "100%|| 350/350 [00:07<00:00, 46.16it/s]\n",
      "100%|| 350/350 [00:14<00:00, 23.71it/s]\n",
      "100%|| 350/350 [00:00<00:00, 493.65it/s]\n",
      "100%|| 350/350 [00:01<00:00, 203.70it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.05it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.14it/s]\n",
      "100%|| 350/350 [00:00<00:00, 476.84it/s]\n",
      "100%|| 350/350 [00:01<00:00, 216.25it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.88it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.16it/s]\n",
      "100%|| 350/350 [00:00<00:00, 409.84it/s]\n",
      "100%|| 350/350 [00:01<00:00, 211.46it/s]\n",
      "100%|| 350/350 [00:07<00:00, 46.36it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.97it/s]\n",
      "100%|| 350/350 [00:00<00:00, 501.43it/s]\n",
      "100%|| 350/350 [00:01<00:00, 195.75it/s]\n",
      "100%|| 350/350 [00:07<00:00, 45.91it/s]\n",
      "100%|| 350/350 [00:14<00:00, 23.70it/s]\n",
      "100%|| 350/350 [00:00<00:00, 443.98it/s]\n",
      "100%|| 350/350 [00:01<00:00, 192.26it/s]\n",
      "100%|| 350/350 [00:07<00:00, 44.77it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.35it/s]\n",
      "100%|| 350/350 [00:00<00:00, 496.94it/s]\n",
      "100%|| 350/350 [00:01<00:00, 215.62it/s]\n",
      "100%|| 350/350 [00:07<00:00, 43.94it/s]\n",
      "100%|| 350/350 [00:14<00:00, 24.65it/s]\n",
      "100%|| 350/350 [00:00<00:00, 483.95it/s]\n",
      "100%|| 350/350 [00:01<00:00, 206.93it/s]\n",
      "100%|| 100/100 [37:35<00:00, 22.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "cam_stability_list = list()\n",
    "loss_list = list()\n",
    "f1_accuracy_list = list()\n",
    "\n",
    "with tqdm(total=100) as pbar:\n",
    "    for epoch in range(100):\n",
    "        pbar.update(1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "        # measuring the stability\n",
    "        cam_explanations_unperturbed = cam_exps(model, graph, data, random_nodes=random_nodes) # unperturbed\n",
    "        cam_explanations_perturbed = cam_exps(model, graph, perturbed_data, random_nodes=random_nodes) # unperturbed\n",
    "\n",
    "        cam_matrix_unperturbed = explanation_list_to_matrix(cam_explanations_unperturbed, data) \n",
    "        cam_matrix_perturbed = explanation_list_to_matrix(cam_explanations_perturbed, data) \n",
    "\n",
    "        # getting the stability\n",
    "        cam_stab = stability(cam_matrix_unperturbed, cam_matrix_perturbed)\n",
    "        loss = loss.add(torch.tensor([cam_stab], requires_grad=True).to(device) )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_list.append(loss)\n",
    "        cam_stability_list.append(cam_stab)\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = multiclass_f1_score(pred, data.y, num_classes=dataset.num_classes)\n",
    "        f1_accuracy_list.append(f1)\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving values to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Stability_100_cora_CAM.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ea9939c250>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i.item() for i in loss_list], label=\"Loss\")\n",
    "plt.plot([i for i in cam_stability_list], label=\"Stability\")\n",
    "plt.plot([i.item() for i in f1_accuracy_list], label=\"Macro F1\")\n",
    "plt.title(\"Loss, Stability & Accuracy vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(loss_list[i].item(), cam_stability_list[i], f1_accuracy_list[i].item()) for i in range(len(loss_list))], columns=[\"Loss\", \"CAM Stability\", \"F1 Accuracy\"])\n",
    "df.to_csv(\"Training_for_CAM_Sparsity_CORA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [16:38<00:00,  2.71it/s]\n",
      "100%|| 2708/2708 [26:29<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2708 [00:00<07:28,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6574, -0.7225, -0.6013, -0.5233], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2708 [00:00<08:56,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5203, -0.3700, -0.7551, -0.9783], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2708 [00:00<09:50,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8562, -0.5766, -0.4730, -1.1368, -0.3823,  0.0726], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2708 [00:01<10:19,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1077, -0.7583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2708 [00:01<11:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5199, -0.6340, -0.2173, -0.2145, -0.0319, -0.6756], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2708 [00:01<11:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4461, -0.9948, -0.4571, -0.6390], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2708 [00:01<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4153, -0.4828, -0.5654, -0.5037, -0.5363], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2708 [00:02<11:29,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7944, -0.2029], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2708 [00:02<11:34,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6189, -0.9601, -0.6968, -0.6772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2708 [00:02<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1621, -0.9223, -0.8898], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/2708 [00:02<11:29,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8606, -0.7249, -0.6413], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/2708 [00:03<11:26,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3526, -0.1813, -0.2870], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4200, -0.2410, -0.5283, -0.3195, -0.4002], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2708 [00:03<11:19,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0116, -0.7319, -0.6148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8901, -0.2864,  0.0708, -0.5744, -0.2016, -0.7190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2708 [00:04<11:21,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4788, -0.2618, -0.4735, -0.5339, -0.3104], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2708 [00:04<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9772, -0.3799, -0.5573, -0.5985, -0.6028], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4950, -0.8515, -0.5688, -0.4359, -0.5582, -0.3338], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3018, -1.0444, -0.6570, -0.8701, -0.1670, -0.8772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2708 [00:05<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0686, -0.9931], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2708 [00:05<11:26,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3826,  0.0631, -0.8968, -0.9487, -0.6614, -0.3889], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2708 [00:05<11:23,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6130,  0.0976, -0.6573], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2708 [00:05<11:31,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3956, -0.7277, -0.6689, -0.2478, -0.2256, -0.1082], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4049, -1.6713], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2708 [00:06<11:32,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3425, -0.5798, -0.1702, -0.2315, -0.4489, -0.2593, -0.5921, -0.3989],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7113, -0.5180, -0.6471, -0.6454, -0.7941], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2708 [00:07<11:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5213, -0.5076, -0.3410, -0.5158, -0.4208, -0.0247], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/2708 [00:07<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7930, -0.5129, -0.4541, -0.4210, -0.4524], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/2708 [00:07<11:46,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2461, -0.7360], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/2708 [00:07<11:57,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2923, -1.5444, -0.3596], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/2708 [00:08<12:08,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9600, -0.5965, -0.4892, -0.4216,  0.2531, -0.5733, -0.7309],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/2708 [00:08<11:52,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1677, -0.9148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 34/2708 [00:08<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0727, -0.4356, -0.0719, -0.8802, -0.3891], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 35/2708 [00:08<11:56,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6708, -0.2133, -0.4639, -0.0452, -0.1081, -0.2871, -0.5587, -0.3957,\n",
      "        -0.1813, -0.5420], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 36/2708 [00:09<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9400, -1.0512], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 37/2708 [00:09<11:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4529, -0.4503, -0.3648, -0.6088], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 38/2708 [00:09<11:38,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5024, -0.2346, -0.5609, -0.3737, -0.3356, -0.3844, -0.2932, -0.3747,\n",
      "        -0.2052], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 39/2708 [00:09<11:43,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3181, -0.1349, -0.4077, -0.1352], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 40/2708 [00:10<11:49,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9254, -0.6111, -0.1048, -0.3196, -0.2110], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 41/2708 [00:10<11:39,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4832, -0.8994, -0.2025, -0.5024, -0.3493, -0.3469, -0.3100, -0.1292],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 42/2708 [00:10<11:35,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9360, -0.1485, -0.8748, -0.8013], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 43/2708 [00:10<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5408, -0.5323, -0.5018, -0.2520, -0.5001], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 44/2708 [00:11<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9175, -0.6259, -0.8920], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 45/2708 [00:11<11:29,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5529, -0.4633, -0.6824, -0.1575, -0.6823, -0.4527, -0.1097],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 46/2708 [00:11<11:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7863, -0.6055, -0.3041, -0.7659], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 47/2708 [00:12<11:24,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6369, -0.1579,  0.0096, -0.2302, -0.7066, -0.8424, -0.8205],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 48/2708 [00:12<11:23,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5954, -0.7689, -1.0760], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/2708 [00:12<11:25,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6883, -0.7915, -0.8190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 50/2708 [00:12<11:31,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7514, -0.5609, -0.5929, -0.4977, -0.6895, -0.1147, -0.3839, -0.4977,\n",
      "        -0.3521, -0.1876], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 51/2708 [00:13<11:27,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9633, -0.3087, -0.7496], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 52/2708 [00:13<11:32,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0716, -0.7867], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8026, -0.6366, -0.5278, -0.3520, -0.0046, -0.2991, -0.3643],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 54/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2594, -0.6112, -0.5430, -0.0218, -0.8436, -0.6938], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 55/2708 [00:14<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6441, -0.4541, -0.7002, -0.3384], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 56/2708 [00:14<11:24,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5803, -0.7055, -1.0509], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 57/2708 [00:14<11:28,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9221,  0.3088, -0.4489, -0.3684, -0.2524, -0.0571, -0.5076, -0.1804,\n",
      "        -0.2160, -0.0491, -0.4002, -0.8905,  0.1593], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 58/2708 [00:14<11:34,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4749, -0.3756, -0.3725, -0.5048, -0.4532], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 59/2708 [00:15<11:46,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2448, -0.8058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 60/2708 [00:15<11:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3131, -1.6650], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 61/2708 [00:15<11:45,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4681, -0.5944, -0.3451, -0.4504, -0.3806, -0.3288, -0.3684, -0.7651,\n",
      "        -0.3525, -0.0654, -0.5855], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 62/2708 [00:15<11:42,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1158,  0.6875, -1.3673, -0.8284], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 63/2708 [00:16<11:49,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6049, -0.1793, -0.9846, -0.9551, -0.0148, -0.7559], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 64/2708 [00:16<11:47,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4189, -1.4566], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 65/2708 [00:16<11:40,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1445, -0.6135], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 66/2708 [00:17<11:26,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6229, -0.6396, -0.7113, -0.1714], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ig_spar \u001b[38;5;241m=\u001b[39m \u001b[43mig_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIG Spar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mig_spar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mig_sparsity\u001b[1;34m(model, graph, data_object)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[0;32m     33\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mIG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     total_sparse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_nonzeros(exp\u001b[38;5;241m.\u001b[39mnode_imp)\u001b[38;5;241m/\u001b[39mexp\u001b[38;5;241m.\u001b[39menc_subgraph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(exp\u001b[38;5;241m.\u001b[39mnode_imp)\n",
      "Cell \u001b[1;32mIn[3], line 1020\u001b[0m, in \u001b[0;36mIG\u001b[1;34m(node_idx, x, edge_index, y, num_hops, steps, model, criterion)\u001b[0m\n\u001b[0;32m   1018\u001b[0m output \u001b[38;5;241m=\u001b[39m model(temp_x, sub_edge_index)\n\u001b[0;32m   1019\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output[mapping], label)\n\u001b[1;32m-> 1020\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m grad \u001b[38;5;241m=\u001b[39m temp_x\u001b[38;5;241m.\u001b[39mgrad[torch\u001b[38;5;241m.\u001b[39mwhere(subset\u001b[38;5;241m==\u001b[39mnode_idx)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m   1022\u001b[0m grads[i] \u001b[38;5;241m=\u001b[39m grad\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [04:38<00:00,  9.73it/s]\n",
      "100%|| 2708/2708 [12:55<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [11:26<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [12:32:29<00:00, 16.67s/it]        \n",
      "100%|| 2708/2708 [17:32<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [10:33<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
