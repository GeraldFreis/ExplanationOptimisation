{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook trains a model with additional loss for Stability on Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "import torch\n",
    "dataset = Planetoid(root='/tmp/Citeseer/', name='Citeseer')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import k_hop_subgraph, to_undirected\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.data import Data\n",
    "from graphxai.explainers._base import _BaseExplainer\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "\n",
    "class _BaseExplainer:\n",
    "    \"\"\"\n",
    "    Base Class for Explainers\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            model: nn.Module,\n",
    "            emb_layer_name: Optional[str] = None,\n",
    "            is_subgraphx: Optional[bool] = False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "                The output of the model should be unnormalized class score.\n",
    "                For example, last layer = GCNConv or Linear.\n",
    "            emb_layer_name (str, optional): name of the embedding layer\n",
    "                If not specified, use the last but one layer by default.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.L = len([module for module in self.model.modules()\n",
    "                      if isinstance(module, MessagePassing)])\n",
    "        self.explain_graph = False  # Assume node-level explanation by default\n",
    "        self.subgraphx_flag = is_subgraphx\n",
    "        self.__set_embedding_layer(emb_layer_name)\n",
    "\n",
    "    def __set_embedding_layer(self, emb_layer_name: str = None):\n",
    "        \"\"\"\n",
    "        Set the embedding layer (by default is the last but one layer).\n",
    "        \"\"\"\n",
    "        if emb_layer_name:\n",
    "            try:\n",
    "                self.emb_layer = getattr(self.model, emb_layer_name)\n",
    "            except AttributeError:\n",
    "                raise ValueError(f'{emb_layer_name} does not exist in the model')\n",
    "        else:\n",
    "            self.emb_layer = list(self.model.modules())[-2]\n",
    "\n",
    "    def _get_embedding(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                       forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the embedding.\n",
    "        \"\"\"\n",
    "        emb = self._get_activation(self.emb_layer, x, edge_index, forward_kwargs)\n",
    "        return emb\n",
    "\n",
    "    def _set_masks(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                   edge_mask: torch.Tensor = None, explain_feature: bool = False,\n",
    "                   device = None):\n",
    "        \"\"\"\n",
    "        Initialize the edge (and feature) masks.\n",
    "        \"\"\"\n",
    "        (n, d), m = x.shape, edge_index.shape[1]\n",
    "\n",
    "        # Initialize edge_mask and feature_mask for learning\n",
    "        std = torch.nn.init.calculate_gain('relu') * np.sqrt(2.0 / (2 * n))\n",
    "        if edge_mask is None:\n",
    "            edge_mask = (torch.randn(m) * std).to(device)\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        else:\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        if explain_feature:\n",
    "            feature_mask = (torch.randn(d) * 0.1).to(device)\n",
    "            self.feature_mask = torch.nn.Parameter(feature_mask)\n",
    "\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # Tell pytorch geometric to apply edge masks\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def _clear_masks(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.edge_mask = None\n",
    "        self.feature_mask = None\n",
    "\n",
    "    def _flow(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def _predict(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                 return_type: str = 'label', forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the model's prediction.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            return_type (str): one of ['label', 'prob', 'log_prob']\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            pred (torch.Tensor, [n x ...]): model prediction\n",
    "        \"\"\"\n",
    "        # Compute unnormalized class score\n",
    "        with torch.no_grad():\n",
    "            out = self.model.to(device)(x, edge_index, **forward_kwargs)\n",
    "            if return_type == 'label':\n",
    "                out = out.argmax(dim=-1)\n",
    "            elif return_type == 'prob':\n",
    "                out = F.softmax(out, dim=-1)\n",
    "            elif return_type == 'log_prob':\n",
    "                out = F.log_softmax(out, dim=-1)\n",
    "            else:\n",
    "                raise ValueError(\"return_type must be 'label', 'prob', or 'log_prob'\")\n",
    "\n",
    "            if self.explain_graph:\n",
    "                out = out.squeeze()\n",
    "\n",
    "            return out\n",
    "\n",
    "    def _prob_score_func_graph(self, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probability that the input graphs\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            target_class (int): the targeted class of the graph\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        def get_prob_score(x: torch.Tensor,\n",
    "                           edge_index: torch.Tensor,\n",
    "                           forward_kwargs: dict = {}):\n",
    "            prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                 forward_kwargs=forward_kwargs)\n",
    "            score = prob[:, target_class]\n",
    "            return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _prob_score_func_node(self, node_idx: torch.Tensor, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probabilities that k specified nodes\n",
    "        in `torch_geometric.data.Batch` (disconnected union of the input graphs)\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            node_idx (torch.Tensor, [k]): the indices of the k nodes interested\n",
    "            target_class (torch.Tensor, [k]): the targeted classes of the k nodes\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        if self.subgraphx_flag:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[node_idx, target_class]\n",
    "                return score\n",
    "        else:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[:, node_idx, target_class]\n",
    "                return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _get_activation(self, layer: nn.Module, x: torch.Tensor,\n",
    "                        edge_index: torch.Tensor, forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the activation of the layer.\n",
    "        \"\"\"\n",
    "        activation = {}\n",
    "        def get_activation():\n",
    "            def hook(model, inp, out):\n",
    "                activation['layer'] = out.detach()\n",
    "            return hook\n",
    "\n",
    "        layer.register_forward_hook(get_activation())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return activation['layer']\n",
    "\n",
    "    def _get_k_hop_subgraph(self, node_idx: int, x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor, num_hops: int = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Extract the subgraph of target node\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): the node index\n",
    "            x (torch.Tensor, [n x d]): node feature matrix with shape\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index\n",
    "            kwargs (dict): additional parameters of the graph\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # TODO: use NamedTuple\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        return khop_info\n",
    "\n",
    "    def get_explanation_node(self, node_idx: int,\n",
    "                             x: torch.Tensor,\n",
    "                             edge_index: torch.Tensor,\n",
    "                             label: torch.Tensor = None,\n",
    "                             num_hops: int = None,\n",
    "                             forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): index of the node to be explained\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            label (torch.Tensor, optional, [n x ...]): labels to explain\n",
    "                If not provided, we use the output of the model.\n",
    "            num_hops (int, optional): number of hops to consider\n",
    "                If not provided, we use the number of graph layers of the GNN.\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "            khop_info (4-tuple of torch.Tensor):\n",
    "                0. the nodes involved in the subgraph\n",
    "                1. the filtered `edge_index`\n",
    "                2. the mapping from node indices in `node_idx` to their new location\n",
    "                3. the `edge_index` mask indicating which edges were preserved\n",
    "        \"\"\"\n",
    "        # If labels are needed\n",
    "        label = self._predict(x, edge_index, return_type='label') if label is None else label\n",
    "        # If probabilities / log probabilities are needed\n",
    "        prob = self._predict(x, edge_index, return_type='prob')\n",
    "        log_prob = self._predict(x, edge_index, return_type='log_prob')\n",
    "\n",
    "        num_hops = self.L if num_hops is None else num_hops\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return exp, khop_info\n",
    "\n",
    "    def get_explanation_graph(self, edge_index: torch.Tensor,\n",
    "                              x: torch.Tensor, label: torch.Tensor,\n",
    "                              forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a whole-graph prediction.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            label (torch.Tensor, [n x ...]): labels to explain\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "        \"\"\"\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_explanation_link(self):\n",
    "        \"\"\"\n",
    "        Explain a link prediction.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph as subgraph\n",
    "\n",
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class _BaseDecomposition(_BaseExplainer):\n",
    "    '''\n",
    "    Code adapted from Dive into Graphs (DIG)\n",
    "    Code: https://github.com/divelab/DIG\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__(model=model) # Will set self.model = model\n",
    "        # Other properties: self.L (number of layers)\n",
    "\n",
    "    @property\n",
    "    def __num_hops__(self):\n",
    "        if self.explain_graph:\n",
    "            return -1\n",
    "        else:\n",
    "            return self.L\n",
    "    \n",
    "    def set_graph_attr(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.num_edges = edge_index.shape[1]\n",
    "        self.num_nodes = x.shape[0]\n",
    "        self.device = x.device\n",
    "\n",
    "    def extract_step(self, x: Tensor, edge_index: Tensor, detach: bool = True, split_fc: bool = False, forward_kwargs: dict = None):\n",
    "        '''Gets information about every layer in the graph\n",
    "        Args:\n",
    "\n",
    "            forward_kwargs (tuple, optional): Additional arguments to model forward call (other than x and edge_index)\n",
    "                (default: :obj:`None`)\n",
    "        '''\n",
    "\n",
    "        layer_extractor = []\n",
    "        hooks = []\n",
    "\n",
    "        def register_hook(module: nn.Module):\n",
    "            if not list(module.children()) or isinstance(module, MessagePassing):\n",
    "                hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "        def forward_hook(module: nn.Module, input: Tuple[Tensor], output: Tensor):\n",
    "            # input contains x and edge_index\n",
    "            if detach:\n",
    "                layer_extractor.append((module, input[0].clone().detach(), output.clone().detach()))\n",
    "            else:\n",
    "                layer_extractor.append((module, input[0], output))\n",
    "\n",
    "        # --- register hooks ---\n",
    "        self.model.apply(register_hook)\n",
    "\n",
    "        # ADDED: OWEN QUEEN --------------\n",
    "        if forward_kwargs is None:\n",
    "            _ = self.model(x, edge_index)\n",
    "        else:\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "        # --------------------------------\n",
    "        # Remove hooks:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        # --- divide layer sets ---\n",
    "\n",
    "        # print('Layer extractor', [layer_extractor[i][0] for i in range(len(layer_extractor))])\n",
    "\n",
    "        walk_steps = []\n",
    "        fc_steps = []\n",
    "        pool_flag = False\n",
    "        step = {'input': None, 'module': [], 'output': None}\n",
    "        for layer in layer_extractor:\n",
    "            if isinstance(layer[0], MessagePassing):\n",
    "                if step['module']: # Append step that had previously been building\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], GNNPool):\n",
    "                pool_flag = True\n",
    "                if step['module']:\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                # Putting in GNNPool\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], nn.Linear):\n",
    "                if step['module']:\n",
    "                    if isinstance(step['module'][0], MessagePassing):\n",
    "                        walk_steps.append(step) # Append MessagePassing layer to walk_steps\n",
    "                    else: # Always append Linear layers to fc_steps\n",
    "                        fc_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            # Also appends non-trainable layers to step (not modifying input):\n",
    "            step['module'].append(layer[0])\n",
    "            step['output'] = layer[2]\n",
    "\n",
    "        if step['module']:\n",
    "            if isinstance(step['module'][0], MessagePassing):\n",
    "                walk_steps.append(step)\n",
    "            else: # Append anything to FC that is not MessagePassing at its origin\n",
    "                # Still supports sequential layers\n",
    "                fc_steps.append(step)\n",
    "            # print('layer', layer[0])\n",
    "            # if isinstance(layer[0], MessagePassing) or isinstance(layer[0], GNNPool):\n",
    "            #     if isinstance(layer[0], GNNPool):\n",
    "            #         pool_flag = True\n",
    "            #     if step['module'] and step['input'] is not None:\n",
    "            #         walk_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # if pool_flag and split_fc and isinstance(layer[0], nn.Linear):\n",
    "            #     if step['module']:\n",
    "            #         fc_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # step['module'].append(layer[0])\n",
    "            # step['output'] = layer[2]\n",
    "\n",
    "        for walk_step in walk_steps:\n",
    "            if hasattr(walk_step['module'][0], 'nn') and walk_step['module'][0].nn is not None:\n",
    "                # We don't allow any outside nn during message flow process in GINs\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "            elif hasattr(walk_step['module'][0], 'lin') and walk_step['module'][0].lin is not None:\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "\n",
    "        # print('Walk steps', [walk_steps[i]['module'] for i in range(len(walk_steps))])\n",
    "        # print('fc steps', [fc_steps[i]['module'] for i in range(len(fc_steps))])\n",
    "\n",
    "        return walk_steps, fc_steps\n",
    "\n",
    "    def walks_pick(self,\n",
    "                   edge_index: Tensor,\n",
    "                   pick_edge_indices: List,\n",
    "                   walk_indices: List=[],\n",
    "                   num_layers=0\n",
    "                   ):\n",
    "        walk_indices_list = []\n",
    "        for edge_idx in pick_edge_indices:\n",
    "\n",
    "            # Adding one edge\n",
    "            walk_indices.append(edge_idx)\n",
    "            _, new_src = src, tgt = edge_index[:, edge_idx]\n",
    "            next_edge_indices = np.array((edge_index[0, :] == new_src).nonzero().view(-1))\n",
    "\n",
    "            # Finding next edge\n",
    "            if len(walk_indices) >= num_layers:\n",
    "                # return one walk\n",
    "                walk_indices_list.append(walk_indices.copy())\n",
    "            else:\n",
    "                walk_indices_list += self.walks_pick(edge_index, next_edge_indices, walk_indices, num_layers)\n",
    "\n",
    "            # remove the last edge\n",
    "            walk_indices.pop(-1)\n",
    "\n",
    "        return walk_indices_list\n",
    "\n",
    "class CAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, activation = None):\n",
    "        '''\n",
    "        .. note::\n",
    "            From Pope et al., CAM requires that the layer immediately before the softmax layer be\n",
    "            a global average pooling layer, or in the case of node classification, a graph convolutional\n",
    "            layer. Therefore, for this algorithm to theoretically work, there can be no fully-connected\n",
    "            layers after global pooling. There is no restriction in the code for this, but be warned. \n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            activation (method, optional): activation funciton for final layer in network. If `activation = None`,\n",
    "                explainer assumes linear activation. Use `activation = None` if the activation is applied\n",
    "                within the `forward` method of `model`, only set this parameter if another activation is\n",
    "                applied in the training procedure outside of model. (:default: :obj:`None`)\n",
    "        '''\n",
    "        super().__init__(model=model)\n",
    "        self.model = model\n",
    "\n",
    "        # Set activation function\n",
    "        self.activation = lambda x: x  if activation is None else activation\n",
    "        # i.e. linear activation if none provided\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                node_idx: int, \n",
    "                edge_index: torch.Tensor, \n",
    "                label: int = None,  \n",
    "                y = None,\n",
    "                forward_kwargs: dict = {},\n",
    "                directed: bool = False\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Explain one node prediction by the model\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.tensor): edge_index of entire graph\n",
    "            label (int, optional): Label on which to compute the explanation for\n",
    "                this node. If `None`, the predicted label from the model will be\n",
    "                used. (default: :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "            directed (bool, optional): If True, graph is directed.\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        if not directed:\n",
    "            edge_index = to_undirected(edge_index)\n",
    "\n",
    "        if label is None:\n",
    "            if y is None:\n",
    "                label = int(self.__forward_pass(x, edge_index, forward_kwargs).argmax(dim=1).item())\n",
    "            else:\n",
    "                label = y[node_idx]\n",
    "\n",
    "        # Perform walk:\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=False, split_fc=False, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        # Get subgraph:\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        #cam = torch.zeros(N) # Compute CAM only over the subgraph (all others are zero)\n",
    "        cam = torch.zeros(subgraph_N)\n",
    "        for i in range(subgraph_N):\n",
    "            n = subgraph_nodes[i]\n",
    "            cam[i] += self.__exp_node(n, walk_steps, label)\n",
    "\n",
    "        # Set Explanation class:\n",
    "        exp = Explanation(\n",
    "            node_imp = cam,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs = {}):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, predicted_c):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after last convolutiuonal layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        last_conv_layer = walk_steps[-1]\n",
    "\n",
    "        if isinstance(last_conv_layer['module'][0], GINConv):\n",
    "            weight_vec = last_conv_layer['module'][0].nn.weight[predicted_c, :].detach()  # last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], GCNConv):\n",
    "            weight_vec = last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], torch.nn.Linear):\n",
    "            weight_vec = last_conv_layer['module'][0].weight[predicted_c, :].detach()\n",
    "\n",
    "        F_l_n = F.relu(last_conv_layer['input'][node_idx,:]).detach()\n",
    "\n",
    "        L_cam_n = F.relu(torch.matmul(weight_vec, F_l_n))\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "\n",
    "class GradCAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Gradient Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.Tensor, criterion = F.cross_entropy):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "            x: torch.Tensor, \n",
    "            y: torch.Tensor, \n",
    "            node_idx: int, \n",
    "            edge_index: torch.Tensor, \n",
    "            label: int = None, \n",
    "            forward_kwargs: dict = {}, \n",
    "            average_variant: bool = True, \n",
    "            layer: int = 0\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a node in the given graph\n",
    "        Args:\n",
    "            x (torch.Tensor, (n,)): Tensor of node features from the entire graph, with n nodes.\n",
    "            y (torch.Tensor, (n,)): Ground-truth labels for all n nodes in the graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.Tensor): Edge_index of entire graph.\n",
    "            label (int, optional): Label for which to compute Grad-CAM against. If None, computes\n",
    "                the Grad-CAM with respect to the model's predicted class for this node.\n",
    "                (default :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. (default: :obj:`None`)\n",
    "            average_variant (bool, optional): If True, computes the average Grad-CAM across all convolutional\n",
    "                layers in the model. If False, computes Grad-CAM for `layer`. (default: :obj:`True`)\n",
    "            layer (int, optional): Layer by which to compute the Grad-CAM. Argument only has an effect if \n",
    "                `average_variant == True`. Must be less-than the total number of convolutional layers\n",
    "                in the model. (default: :obj:`0`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        x = x.detach().clone()\n",
    "        y = y.detach().clone()\n",
    "\n",
    "        x.requires_grad = True\n",
    "\n",
    "        if label is None:\n",
    "            pred = self.__forward_pass(x, y, edge_index, forward_kwargs)[0][node_idx, :].reshape(1, -1)\n",
    "            y[node_idx] = pred.argmax(dim=1).item()\n",
    "        else: # Transform node_idx's label if provided by user\n",
    "            pred, loss = self.__forward_pass(x, y, edge_index, forward_kwargs)\n",
    "            y[node_idx] = label\n",
    "\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=True, split_fc=True, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx, self.L, edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        if average_variant:\n",
    "            # Size of all nodes in the subgraph:\n",
    "            avg_gcam = torch.zeros(subgraph_N)\n",
    "\n",
    "            for l in range(self.L):\n",
    "                # Compute gradients for this layer ahead of time:\n",
    "                gradients = self.__grad_by_layer(l)\n",
    "\n",
    "                for i in range(subgraph_N): # Over all subgraph nodes\n",
    "                    n = subgraph_nodes[i]\n",
    "                    avg_gcam[i] += self.__get_gCAM_layer(walk_steps, l, n, gradients)\n",
    "\n",
    "            avg_gcam /= self.L # Apply average\n",
    "\n",
    "            exp.node_imp = avg_gcam\n",
    "\n",
    "        else:\n",
    "            assert layer < len(walk_steps), \"Layer must be an index of convolutional layers\"\n",
    "\n",
    "            gcam = torch.zeros(subgraph_N)\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "            for i in range(subgraph_N):\n",
    "                n = subgraph_nodes[i]\n",
    "                gcam[i] += self.__get_gCAM_layer(walk_steps, layer, n, gradients)#[0]\n",
    "\n",
    "            exp.node_imp = gcam\n",
    "\n",
    "        return exp\n",
    "        \n",
    "    def __forward_pass(self, x, label, edge_index, forward_kwargs):\n",
    "        x.requires_grad = True # Enforce that x needs gradient\n",
    "\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        loss = self.criterion(pred, label)\n",
    "        loss.backward() # Propagate loss backward through network\n",
    "\n",
    "        return pred, loss\n",
    "\n",
    "    def __grad_by_layer(self, layer):\n",
    "        # Index 0 of parameters to avoid calculating gradients for biases\n",
    "        module_at_layer = list(self.model.children())[layer]\n",
    "\n",
    "        if isinstance(module_at_layer, GCNConv):\n",
    "            grad = module_at_layer.lin.weight.grad\n",
    "        elif isinstance(module_at_layer, GINConv):\n",
    "            grad = module_at_layer.nn.weight.grad\n",
    "        else:\n",
    "            grad = module_at_layer.weight.grad\n",
    "\n",
    "        return grad.mean(dim=1)\n",
    "\n",
    "    def __get_gCAM_layer(self, walk_steps, layer, node_idx = None, gradients = None):\n",
    "        # Gets Grad CAM for one layer\n",
    "        if gradients is None:\n",
    "            # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "            # ''        '' shape: [k,] - k= # output features from layer l\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "\n",
    "        if node_idx is None: # Need to compute for entire graph:\n",
    "            node_explanations = []\n",
    "            for n in range(self.N):\n",
    "                node_explanations.append(self.__exp_node(n, walk_steps, layer, gradients))\n",
    "\n",
    "            return node_explanations\n",
    "\n",
    "        # Return for only one node:\n",
    "        return self.__exp_node(node_idx, walk_steps, layer, gradients)\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, layer, gradients):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after each convolutional layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "        # ''        '' shape: [k,] - k= # input features to layer l\n",
    "\n",
    "        # Activations for node n\n",
    "        F_l_n = F.relu(walk_steps[layer]['output'][node_idx,:]).detach()\n",
    "        L_cam_n = F.relu(torch.matmul(gradients, F_l_n)) # Combine gradients and activations\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "# from ._decomp_base_old import _BaseDecomposition\n",
    "\n",
    "def clip_hook(grad):\n",
    "    # Apply ReLU activation to gradient\n",
    "    return torch.clamp(grad, min=0)\n",
    "import gc\n",
    "\n",
    "class GuidedBP(_BaseDecomposition):\n",
    "\n",
    "    def __init__(self, model, criterion = F.cross_entropy, enforce_requires_grad = True):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.L = len([module for module in self.model.modules() if isinstance(module, MessagePassing)])\n",
    "\n",
    "        self.registered_hooks = []\n",
    "\n",
    "        self.enforce_requires_grad = enforce_requires_grad\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor,\n",
    "                edge_index: torch.Tensor,  \n",
    "                node_idx: int, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Get Guided Backpropagation explanation for one node in the graph\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            y (torch.Tensor): Ground truth labels correspond to each node's \n",
    "                classification. This argument is input to the `criterion` \n",
    "                function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the enclosing \n",
    "                subgraph. Must support `dim` argument.\n",
    "                (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        if self.enforce_requires_grad:\n",
    "            try:\n",
    "                x = x.detach().clone()\n",
    "                x.requires_grad = True\n",
    "            except:\n",
    "                pass\n",
    "        # assert x.requires_grad, 'x must have requires_grad == True'\n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        graph_exp = x.grad\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        node_imp = aggregate_node_imp(torch.stack([graph_exp[i,:] for i in subgraph_nodes]).detach(), dim=1)\n",
    "\n",
    "        # Get only those explanations for nodes in the subgraph:\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        \n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        return exp\n",
    "\n",
    "    def get_explanation_graph(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor, \n",
    "                edge_index: torch.Tensor, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a whole-graph prediction with Guided Backpropagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor of node features from the entire graph.\n",
    "            y (torch.tensor): Ground truth label of given input. This argument is \n",
    "                input to the `criterion` function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the graph. \n",
    "                Must support `dim` argument. (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)   \n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method. \n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [num_nodes, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `graph`: :obj:`torch_geometric.data.Data`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        try:\n",
    "            x.requires_grad = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        assert x.requires_grad, 'x must have requires_grad == True' \n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        node_imp = aggregate_node_imp(x.grad, dim=1)\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp\n",
    "        )\n",
    "    \n",
    "        exp.set_whole_graph(Data(x, edge_index))\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __apply_hooks(self):\n",
    "        self.registered_hooks = []\n",
    "        for p in self.model.parameters():\n",
    "            h = p.register_hook(clip_hook)\n",
    "            self.registered_hooks.append(h)\n",
    "\n",
    "    def __rm_hooks(self):\n",
    "        for h in self.registered_hooks:\n",
    "            h.remove()\n",
    "        self.registered_hooks = []\n",
    "    \n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        self.__apply_hooks()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "from graphxai.utils import Explanation\n",
    "class IG():\n",
    "    def __init__(self, model, hops: Optional[int] = 1, criterion = None):\n",
    "        self.model = model\n",
    "        self.num_hops = hops\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def node_explanations(self, node_idx: int, \n",
    "            x: torch.Tensor,\n",
    "            edge_index: torch.Tensor, \n",
    "            y: Optional[torch.Tensor] = None,):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): Index of the node to be explained.\n",
    "            edge_index (torch.Tensor, [2 x m]): Edge index of the graph.\n",
    "            x (torch.Tensor, [n x d]): Node features.\n",
    "            label (torch.Tensor, [n x ...]): Labels to explain.\n",
    "            y (torch.Tensor): Same as `label`, provided for general \n",
    "                compatibility in the arguments. (:default: :obj:`None`)\n",
    "            num_hops (int, optional): Number of hops in the enclosing \n",
    "                subgraph. If `None`, set to the number of layers in \n",
    "                the GNN. (:default: :obj:`None`)\n",
    "            steps (int, optional): Number of steps for the Riemannian \n",
    "                integration. (:default: :obj:`40`)\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`torch.Tensor, [x.shape[1],]`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :class:`graphxai.utils.EnclosingSubgraph`\n",
    "        \"\"\"\n",
    "\n",
    "        if (y is None):\n",
    "            raise ValueError('Either label or y should be provided for Integrated Gradients')\n",
    "\n",
    "        label = y[node_idx]\n",
    "        if len(label.shape) == 0:\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, self.num_hops, edge_index,\n",
    "                            relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "        steps = 40\n",
    "        self.model.eval()\n",
    "        grads = torch.zeros(steps+1, x.shape[1]).to(device)\n",
    "\n",
    "        # Perform Riemannian integration\n",
    "        for i in range(steps+1):\n",
    "            with torch.no_grad():\n",
    "                baseline = torch.zeros_like(sub_x).to(device)  # TODO: baseline all 0s, all 1s, ...?\n",
    "                temp_x = baseline + (float(i)/steps) * (sub_x.clone()-baseline)\n",
    "            temp_x.requires_grad = True\n",
    "            output = self.model(temp_x, sub_edge_index)\n",
    "            loss = self.criterion(output[mapping], label)\n",
    "            loss.backward()\n",
    "            grad = temp_x.grad[torch.where(subset==node_idx)[0].item()]\n",
    "            grads[i] = grad\n",
    "\n",
    "        grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "        avg_grads = torch.mean(grads, axis=0)\n",
    "\n",
    "        # Integrated gradients for only node_idx:\n",
    "        # baseline[0] just gets a single-value 0-tensor\n",
    "        integrated_gradients = ((x[torch.where(subset == node_idx)[0].item()]\n",
    "                                    - baseline[0]) * avg_grads)\n",
    "\n",
    "        # Integrated gradients across the enclosing subgraph:\n",
    "        all_node_ig = ((x[subset] - baseline) * avg_grads)\n",
    "        node_importances = torch.sum(all_node_ig, dim=1)\n",
    "        exp = Explanation(\n",
    "            feature_imp = integrated_gradients,\n",
    "            node_imp = node_importances,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        gc.collect()\n",
    "        return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import random\n",
    "from copy import deepcopy\n",
    "random.seed(12345)\n",
    "def perturbed_edge_list(data: torch_geometric.data.Data, n_to_add: int = 2)->torch_geometric.data.Data:\n",
    "    \"\"\"Adding two random nodes to each node\"\"\"\n",
    "    # Do not want seed here\n",
    "    edge_list = data.edge_index\n",
    "    # torch.cat((edge_list, torch.LongTensor((1,2)).to(device).reshape(1,-1)), dim=-1)\n",
    "    # print(edge_list)\n",
    "    data = deepcopy(data)\n",
    "    for node in range(data.x.shape[0]):\n",
    "        # generating two random nodes to add to its adjacency list\n",
    "        for i in range(n_to_add):\n",
    "            n1 = randint(0, data.x.shape[0]-1)\n",
    "            new1 = torch.cat((edge_list[0], torch.LongTensor([node]).to(device)), axis=-1)\n",
    "            new2 = torch.cat((edge_list[1], torch.LongTensor([n1]).to(device)), axis=-1)\n",
    "            edge_list = torch.cat([new1.reshape(1,-1), new2.reshape(1,-1)])\n",
    "    data.edge_index = edge_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def explanation_list_to_matrix(l: list, data)->torch.Tensor:\n",
    "    len_l = len(l)\n",
    "    matrix = torch.zeros((len_l, data.x.shape[0]))\n",
    "    with tqdm(total=len_l) as pbar:\n",
    "        for i, exp in enumerate(l):\n",
    "            pbar.update(1)\n",
    "            subgraph = exp.enc_subgraph.nodes\n",
    "            for j, n in enumerate(subgraph):\n",
    "                n = n.item()\n",
    "                matrix[i][n] = exp.node_imp[j].item()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def stability(generated_exp_unperturbed, generated_exp_perturbed ) -> float:\n",
    "    \"\"\"takes in two matrices the first is unperturbed explanations and the second are perturbed via the addition of a random node\n",
    "        - We assume here that the explanations are in their padded form that is: that the explanation vectors in the list have nodes at equal positions \"\"\"\n",
    "    stability = float() \n",
    "    # Accessing the enclosing subgraph. Will be the same for both explanation.:\n",
    "    stability = abs( np.linalg.norm(np.matrix(generated_exp_unperturbed.numpy())) - np.linalg.norm(np.matrix(generated_exp_perturbed.numpy())) )\n",
    "    return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the random nodes\n",
    "from random import sample\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "# I now want all nodes for each given class (there are 7), and I will randomly select 50 of each class\n",
    "class_0 = [idx for idx, val in enumerate(data.y) if val == 0]\n",
    "class_1 = [idx for idx, val in enumerate(data.y) if val == 1]\n",
    "class_2 = [idx for idx, val in enumerate(data.y) if val == 2]\n",
    "class_3 = [idx for idx, val in enumerate(data.y) if val == 3]\n",
    "class_4 = [idx for idx, val in enumerate(data.y) if val == 4]\n",
    "class_5 = [idx for idx, val in enumerate(data.y) if val == 5]\n",
    "\n",
    "random_class_0 = sample(class_0, k=50)\n",
    "random_class_1 = sample(class_1, k=50)\n",
    "random_class_2 = sample(class_2, k=50)\n",
    "random_class_3 = sample(class_3, k=50)\n",
    "random_class_4 = sample(class_4, k=50)\n",
    "random_class_5 = sample(class_5, k=50)\n",
    "\n",
    "\n",
    "random_nodes = random_class_0\n",
    "random_nodes.extend(random_class_1)\n",
    "random_nodes.extend(random_class_2)\n",
    "random_nodes.extend(random_class_3)\n",
    "random_nodes.extend(random_class_4)\n",
    "random_nodes.extend(random_class_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbp_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    bp_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = GuidedBP(model=model)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            bp_exps.append(exp)\n",
    "    return bp_exps\n",
    "\n",
    "def cam_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    cam_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = CAM(model=model)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x = data_object.x, edge_index = data_object.edge_index,  y = data_object.y)\n",
    "            cam_exps.append(exp)\n",
    "    return cam_exps\n",
    "\n",
    "def ig_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    ig_exps = list()\n",
    "    model.eval()\n",
    "    ig = IG(model=model, criterion=torch.nn.CrossEntropyLoss(), hops=1)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = ig.node_explanations(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            ig_exps.append(exp)\n",
    "    return ig_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_data = perturbed_edge_list(data=data).to(device) # this is our perturbed data to check against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 300/300 [00:02<00:00, 126.38it/s]\n",
      "100%|| 300/300 [00:05<00:00, 51.36it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1646.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 456.39it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.63it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1646.69it/s]\n",
      "100%|| 300/300 [00:01<00:00, 288.42it/s]\n",
      "100%|| 300/300 [00:02<00:00, 101.23it/s]\n",
      "100%|| 300/300 [00:05<00:00, 50.74it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1775.16it/s]\n",
      "100%|| 300/300 [00:00<00:00, 423.13it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.31it/s]\n",
      "100%|| 300/300 [00:05<00:00, 52.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1703.27it/s]\n",
      "100%|| 300/300 [00:00<00:00, 358.42it/s]\n",
      "100%|| 300/300 [00:02<00:00, 106.54it/s]\n",
      "100%|| 300/300 [00:06<00:00, 45.77it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1612.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 467.12it/s]\n",
      "100%|| 300/300 [00:02<00:00, 104.29it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.74it/s]\n",
      "100%|| 300/300 [00:00<00:00, 435.23it/s]\n",
      "100%|| 300/300 [00:02<00:00, 104.69it/s]\n",
      "100%|| 300/300 [00:05<00:00, 53.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1754.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 482.14it/s]\n",
      "100%|| 300/300 [00:02<00:00, 148.41it/s]\n",
      "100%|| 300/300 [00:05<00:00, 51.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2205.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 486.10it/s]\n",
      "100%|| 300/300 [00:02<00:00, 122.03it/s]\n",
      "100%|| 300/300 [00:06<00:00, 45.50it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1714.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 477.97it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.62it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 490.02it/s]\n",
      "100%|| 300/300 [00:02<00:00, 101.64it/s]\n",
      "100%|| 300/300 [00:05<00:00, 50.06it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1694.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 492.61it/s]\n",
      "100%|| 300/300 [00:02<00:00, 102.00it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1754.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 333.70it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.20it/s]\n",
      "100%|| 300/300 [00:05<00:00, 51.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1840.50it/s]\n",
      "100%|| 300/300 [00:00<00:00, 485.44it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.76it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1522.82it/s]\n",
      "100%|| 300/300 [00:00<00:00, 487.02it/s]\n",
      "100%|| 300/300 [00:02<00:00, 103.26it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1714.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 497.51it/s]\n",
      "100%|| 300/300 [00:03<00:00, 98.19it/s] \n",
      "100%|| 300/300 [00:06<00:00, 46.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1724.14it/s]\n",
      "100%|| 300/300 [00:00<00:00, 464.92it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.48it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.12it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 481.54it/s]\n",
      "100%|| 300/300 [00:02<00:00, 123.54it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.34it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1714.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 482.31it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.35it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.23it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.72it/s]\n",
      "100%|| 300/300 [00:00<00:00, 462.84it/s]\n",
      "100%|| 300/300 [00:02<00:00, 113.03it/s]\n",
      "100%|| 300/300 [00:05<00:00, 51.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1851.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 505.05it/s]\n",
      "100%|| 300/300 [00:02<00:00, 112.18it/s]\n",
      "100%|| 300/300 [00:05<00:00, 52.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1829.26it/s]\n",
      "100%|| 300/300 [00:00<00:00, 475.34it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.85it/s]\n",
      "100%|| 300/300 [00:05<00:00, 54.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1744.18it/s]\n",
      "100%|| 300/300 [00:00<00:00, 460.74it/s]\n",
      "100%|| 300/300 [00:02<00:00, 108.77it/s]\n",
      "100%|| 300/300 [00:05<00:00, 50.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1714.30it/s]\n",
      "100%|| 300/300 [00:00<00:00, 448.43it/s]\n",
      "100%|| 300/300 [00:03<00:00, 99.22it/s] \n",
      "100%|| 300/300 [00:05<00:00, 50.75it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1734.12it/s]\n",
      "100%|| 300/300 [00:00<00:00, 465.84it/s]\n",
      "100%|| 300/300 [00:03<00:00, 99.85it/s] \n",
      "100%|| 300/300 [00:06<00:00, 47.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1744.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 482.81it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.95it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1672.46it/s]\n",
      "100%|| 300/300 [00:00<00:00, 479.23it/s]\n",
      "100%|| 300/300 [00:02<00:00, 118.51it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1829.27it/s]\n",
      "100%|| 300/300 [00:00<00:00, 477.56it/s]\n",
      "100%|| 300/300 [00:02<00:00, 109.05it/s]\n",
      "100%|| 300/300 [00:05<00:00, 50.10it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 482.32it/s]\n",
      "100%|| 300/300 [00:02<00:00, 112.48it/s]\n",
      "100%|| 300/300 [00:05<00:00, 51.26it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.19it/s]\n",
      "100%|| 300/300 [00:00<00:00, 453.63it/s]\n",
      "100%|| 300/300 [00:02<00:00, 103.65it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1796.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 374.45it/s]\n",
      "100%|| 300/300 [00:02<00:00, 120.37it/s]\n",
      "100%|| 300/300 [00:05<00:00, 52.58it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1775.18it/s]\n",
      "100%|| 300/300 [00:00<00:00, 399.40it/s]\n",
      "100%|| 300/300 [00:02<00:00, 101.62it/s]\n",
      "100%|| 300/300 [00:05<00:00, 50.02it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.24it/s]\n",
      "100%|| 300/300 [00:00<00:00, 373.46it/s]\n",
      "100%|| 300/300 [00:02<00:00, 102.37it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.65it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1796.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 485.23it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.15it/s]\n",
      "100%|| 300/300 [00:05<00:00, 51.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 454.30it/s]\n",
      "100%|| 300/300 [00:02<00:00, 121.11it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.50it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1734.12it/s]\n",
      "100%|| 300/300 [00:00<00:00, 461.45it/s]\n",
      "100%|| 300/300 [00:02<00:00, 108.79it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 483.87it/s]\n",
      "100%|| 300/300 [00:02<00:00, 111.66it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.41it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1775.17it/s]\n",
      "100%|| 300/300 [00:00<00:00, 432.90it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.71it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1420.70it/s]\n",
      "100%|| 300/300 [00:00<00:00, 481.54it/s]\n",
      "100%|| 300/300 [00:02<00:00, 100.58it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.43it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1666.67it/s]\n",
      "100%|| 300/300 [00:00<00:00, 460.66it/s]\n",
      "100%|| 300/300 [00:02<00:00, 102.29it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1829.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 508.48it/s]\n",
      "100%|| 300/300 [00:02<00:00, 106.82it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1832.33it/s]\n",
      "100%|| 300/300 [00:00<00:00, 490.90it/s]\n",
      "100%|| 300/300 [00:02<00:00, 103.56it/s]\n",
      "100%|| 300/300 [00:05<00:00, 54.39it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1815.05it/s]\n",
      "100%|| 300/300 [00:00<00:00, 506.76it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.57it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1796.41it/s]\n",
      "100%|| 300/300 [00:00<00:00, 392.67it/s]\n",
      "100%|| 300/300 [00:02<00:00, 106.74it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1536.70it/s]\n",
      "100%|| 300/300 [00:00<00:00, 413.79it/s]\n",
      "100%|| 300/300 [00:03<00:00, 93.23it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1816.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 494.23it/s]\n",
      "100%|| 300/300 [00:03<00:00, 89.01it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1675.99it/s]\n",
      "100%|| 300/300 [00:00<00:00, 448.91it/s]\n",
      "100%|| 300/300 [00:02<00:00, 101.41it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.34it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1724.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 444.13it/s]\n",
      "100%|| 300/300 [00:03<00:00, 97.36it/s]\n",
      "100%|| 300/300 [00:06<00:00, 49.30it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1794.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 431.66it/s]\n",
      "100%|| 300/300 [00:02<00:00, 112.09it/s]\n",
      "100%|| 300/300 [00:07<00:00, 40.71it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 424.93it/s]\n",
      "100%|| 300/300 [00:02<00:00, 112.06it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.48it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1742.68it/s]\n",
      "100%|| 300/300 [00:00<00:00, 443.02it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.44it/s]\n",
      "100%|| 300/300 [00:07<00:00, 40.70it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1685.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 421.19it/s]\n",
      "100%|| 300/300 [00:02<00:00, 108.44it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.44it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1612.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 495.05it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.17it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.81it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1796.43it/s]\n",
      "100%|| 300/300 [00:00<00:00, 499.01it/s]\n",
      "100%|| 300/300 [00:02<00:00, 112.23it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.21it/s]\n",
      "100%|| 300/300 [00:00<00:00, 451.81it/s]\n",
      "100%|| 300/300 [00:03<00:00, 99.45it/s] \n",
      "100%|| 300/300 [00:06<00:00, 45.14it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 468.02it/s]\n",
      "100%|| 300/300 [00:03<00:00, 95.07it/s] \n",
      "100%|| 300/300 [00:06<00:00, 46.23it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.71it/s]\n",
      "100%|| 300/300 [00:00<00:00, 405.41it/s]\n",
      "100%|| 300/300 [00:03<00:00, 98.15it/s] \n",
      "100%|| 300/300 [00:06<00:00, 48.95it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1639.35it/s]\n",
      "100%|| 300/300 [00:00<00:00, 392.16it/s]\n",
      "100%|| 300/300 [00:03<00:00, 81.78it/s] \n",
      "100%|| 300/300 [00:06<00:00, 46.03it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 327.03it/s]\n",
      "100%|| 300/300 [00:03<00:00, 95.84it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.65it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1785.76it/s]\n",
      "100%|| 300/300 [00:00<00:00, 463.55it/s]\n",
      "100%|| 300/300 [00:02<00:00, 117.70it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.95it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1693.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 448.14it/s]\n",
      "100%|| 300/300 [00:03<00:00, 90.00it/s] \n",
      "100%|| 300/300 [00:06<00:00, 47.39it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1639.36it/s]\n",
      "100%|| 300/300 [00:00<00:00, 483.70it/s]\n",
      "100%|| 300/300 [00:03<00:00, 99.35it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.65it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1694.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 489.25it/s]\n",
      "100%|| 300/300 [00:02<00:00, 112.82it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 453.17it/s]\n",
      "100%|| 300/300 [00:02<00:00, 104.77it/s]\n",
      "100%|| 300/300 [00:07<00:00, 42.75it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1840.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 492.61it/s]\n",
      "100%|| 300/300 [00:02<00:00, 111.25it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.72it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.21it/s]\n",
      "100%|| 300/300 [00:00<00:00, 488.60it/s]\n",
      "100%|| 300/300 [00:02<00:00, 106.56it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.19it/s]\n",
      "100%|| 300/300 [00:00<00:00, 465.12it/s]\n",
      "100%|| 300/300 [00:02<00:00, 106.26it/s]\n",
      "100%|| 300/300 [00:06<00:00, 45.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.21it/s]\n",
      "100%|| 300/300 [00:00<00:00, 361.01it/s]\n",
      "100%|| 300/300 [00:03<00:00, 95.74it/s] \n",
      "100%|| 300/300 [00:06<00:00, 44.27it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1851.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 471.70it/s]\n",
      "100%|| 300/300 [00:03<00:00, 99.23it/s] \n",
      "100%|| 300/300 [00:06<00:00, 47.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1851.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 386.10it/s]\n",
      "100%|| 300/300 [00:02<00:00, 102.98it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.75it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1298.71it/s]\n",
      "100%|| 300/300 [00:00<00:00, 326.80it/s]\n",
      "100%|| 300/300 [00:03<00:00, 93.59it/s] \n",
      "100%|| 300/300 [00:06<00:00, 49.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1754.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 469.78it/s]\n",
      "100%|| 300/300 [00:02<00:00, 103.90it/s]\n",
      "100%|| 300/300 [00:06<00:00, 45.99it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1327.44it/s]\n",
      "100%|| 300/300 [00:00<00:00, 393.12it/s]\n",
      "100%|| 300/300 [00:03<00:00, 89.13it/s]\n",
      "100%|| 300/300 [00:06<00:00, 45.00it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.20it/s]\n",
      "100%|| 300/300 [00:00<00:00, 384.06it/s]\n",
      "100%|| 300/300 [00:03<00:00, 89.17it/s] \n",
      "100%|| 300/300 [00:06<00:00, 46.53it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1873.10it/s]\n",
      "100%|| 300/300 [00:00<00:00, 339.31it/s]\n",
      "100%|| 300/300 [00:03<00:00, 92.56it/s] \n",
      "100%|| 300/300 [00:05<00:00, 50.31it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1714.30it/s]\n",
      "100%|| 300/300 [00:00<00:00, 428.57it/s]\n",
      "100%|| 300/300 [00:03<00:00, 88.25it/s]\n",
      "100%|| 300/300 [00:06<00:00, 47.33it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.22it/s]\n",
      "100%|| 300/300 [00:00<00:00, 450.97it/s]\n",
      "100%|| 300/300 [00:03<00:00, 93.83it/s] \n",
      "100%|| 300/300 [00:06<00:00, 48.09it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1724.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 434.64it/s]\n",
      "100%|| 300/300 [00:02<00:00, 100.65it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.95it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1851.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 503.36it/s]\n",
      "100%|| 300/300 [00:02<00:00, 102.17it/s]\n",
      "100%|| 300/300 [00:07<00:00, 42.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1675.98it/s]\n",
      "100%|| 300/300 [00:00<00:00, 437.74it/s]\n",
      "100%|| 300/300 [00:02<00:00, 107.28it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.07it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1500.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 504.20it/s]\n",
      "100%|| 300/300 [00:02<00:00, 109.28it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1648.35it/s]\n",
      "100%|| 300/300 [00:00<00:00, 465.84it/s]\n",
      "100%|| 300/300 [00:02<00:00, 109.54it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.60it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1818.21it/s]\n",
      "100%|| 300/300 [00:00<00:00, 423.73it/s]\n",
      "100%|| 300/300 [00:02<00:00, 104.40it/s]\n",
      "100%|| 300/300 [00:06<00:00, 48.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1744.22it/s]\n",
      "100%|| 300/300 [00:00<00:00, 431.04it/s]\n",
      "100%|| 300/300 [00:03<00:00, 88.09it/s] \n",
      "100%|| 300/300 [00:06<00:00, 47.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1714.32it/s]\n",
      "100%|| 300/300 [00:00<00:00, 428.50it/s]\n",
      "100%|| 300/300 [00:03<00:00, 95.17it/s] \n",
      "100%|| 300/300 [00:06<00:00, 47.14it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.74it/s]\n",
      "100%|| 300/300 [00:00<00:00, 427.88it/s]\n",
      "100%|| 300/300 [00:03<00:00, 89.57it/s] \n",
      "100%|| 300/300 [00:06<00:00, 45.29it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 432.77it/s]\n",
      "100%|| 300/300 [00:03<00:00, 89.14it/s] \n",
      "100%|| 300/300 [00:06<00:00, 45.16it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1796.45it/s]\n",
      "100%|| 300/300 [00:00<00:00, 305.76it/s]\n",
      "100%|| 300/300 [00:03<00:00, 93.44it/s]\n",
      "100%|| 300/300 [00:07<00:00, 41.81it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1673.99it/s]\n",
      "100%|| 300/300 [00:00<00:00, 393.70it/s]\n",
      "100%|| 300/300 [00:03<00:00, 83.21it/s]\n",
      "100%|| 300/300 [00:06<00:00, 45.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1639.37it/s]\n",
      "100%|| 300/300 [00:00<00:00, 505.90it/s]\n",
      "100%|| 300/300 [00:03<00:00, 93.07it/s]\n",
      "100%|| 300/300 [00:06<00:00, 44.77it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1752.43it/s]\n",
      "100%|| 300/300 [00:00<00:00, 446.35it/s]\n",
      "100%|| 300/300 [00:03<00:00, 83.39it/s]\n",
      "100%|| 300/300 [00:06<00:00, 46.26it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1754.41it/s]\n",
      "100%|| 300/300 [00:00<00:00, 451.66it/s]\n",
      "100%|| 300/300 [00:03<00:00, 85.34it/s] \n",
      "100%|| 300/300 [00:05<00:00, 51.04it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1724.17it/s]\n",
      "100%|| 300/300 [00:00<00:00, 387.10it/s]\n",
      "100%|| 300/300 [00:03<00:00, 93.09it/s] \n",
      "100%|| 300/300 [00:06<00:00, 44.79it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.25it/s]\n",
      "100%|| 300/300 [00:00<00:00, 468.02it/s]\n",
      "100%|| 300/300 [00:03<00:00, 98.48it/s] \n",
      "100%|| 300/300 [00:07<00:00, 40.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1395.36it/s]\n",
      "100%|| 300/300 [00:00<00:00, 493.42it/s]\n",
      "100%|| 300/300 [00:02<00:00, 100.17it/s]\n",
      "100%|| 300/300 [00:07<00:00, 42.78it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.24it/s]\n",
      "100%|| 300/300 [00:00<00:00, 488.60it/s]\n",
      "100%|| 300/300 [00:02<00:00, 104.07it/s]\n",
      "100%|| 300/300 [00:06<00:00, 43.39it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1754.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 424.81it/s]\n",
      "100%|| 300/300 [00:03<00:00, 95.56it/s]\n",
      "100%|| 300/300 [00:07<00:00, 40.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1807.26it/s]\n",
      "100%|| 300/300 [00:00<00:00, 476.84it/s]\n",
      "100%|| 300/300 [00:03<00:00, 99.68it/s] \n",
      "100%|| 300/300 [00:06<00:00, 45.36it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1764.72it/s]\n",
      "100%|| 300/300 [00:00<00:00, 495.05it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.84it/s]\n",
      "100%|| 300/300 [00:07<00:00, 42.21it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1785.72it/s]\n",
      "100%|| 300/300 [00:00<00:00, 474.56it/s]\n",
      "100%|| 300/300 [00:02<00:00, 105.76it/s]\n",
      "100%|| 300/300 [00:07<00:00, 40.82it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1840.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 504.90it/s]\n",
      "100%|| 100/100 [16:58<00:00, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "cam_stability_list = list()\n",
    "loss_list = list()\n",
    "f1_accuracy_list = list()\n",
    "\n",
    "with tqdm(total=100) as pbar:\n",
    "    for epoch in range(100):\n",
    "        pbar.update(1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "        # measuring the stability\n",
    "        cam_explanations_unperturbed = cam_exps(model, graph, data, random_nodes=random_nodes) # unperturbed\n",
    "        cam_explanations_perturbed = cam_exps(model, graph, perturbed_data, random_nodes=random_nodes) # unperturbed\n",
    "\n",
    "        cam_matrix_unperturbed = explanation_list_to_matrix(cam_explanations_unperturbed, data) \n",
    "        cam_matrix_perturbed = explanation_list_to_matrix(cam_explanations_perturbed, data) \n",
    "\n",
    "        # getting the stability\n",
    "        cam_stab = stability(cam_matrix_unperturbed, cam_matrix_perturbed)\n",
    "        loss = loss.add(torch.tensor([cam_stab], requires_grad=True).to(device) )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_list.append(loss)\n",
    "        cam_stability_list.append(cam_stab)\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = multiclass_f1_score(pred, data.y, num_classes=dataset.num_classes)\n",
    "        f1_accuracy_list.append(f1)\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving values to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Stability_100_citeseer_CAM.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2438285d190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i.item() for i in loss_list], label=\"Loss\")\n",
    "plt.plot([i for i in cam_stability_list], label=\"Stability\")\n",
    "plt.plot([i.item() for i in f1_accuracy_list], label=\"Macro F1\")\n",
    "plt.title(\"Loss, Stability & Accuracy vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(loss_list[i].item(), cam_stability_list[i], f1_accuracy_list[i].item()) for i in range(len(loss_list))], columns=[\"Loss\", \"CAM Stability\", \"F1 Accuracy\"])\n",
    "df.to_csv(\"Training_for_CAM_Stability_Citeseer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [16:38<00:00,  2.71it/s]\n",
      "100%|| 2708/2708 [26:29<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2708 [00:00<07:28,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6574, -0.7225, -0.6013, -0.5233], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2708 [00:00<08:56,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5203, -0.3700, -0.7551, -0.9783], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2708 [00:00<09:50,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8562, -0.5766, -0.4730, -1.1368, -0.3823,  0.0726], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2708 [00:01<10:19,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1077, -0.7583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2708 [00:01<11:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5199, -0.6340, -0.2173, -0.2145, -0.0319, -0.6756], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2708 [00:01<11:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4461, -0.9948, -0.4571, -0.6390], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2708 [00:01<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4153, -0.4828, -0.5654, -0.5037, -0.5363], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2708 [00:02<11:29,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7944, -0.2029], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2708 [00:02<11:34,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6189, -0.9601, -0.6968, -0.6772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2708 [00:02<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1621, -0.9223, -0.8898], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/2708 [00:02<11:29,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8606, -0.7249, -0.6413], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/2708 [00:03<11:26,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3526, -0.1813, -0.2870], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4200, -0.2410, -0.5283, -0.3195, -0.4002], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2708 [00:03<11:19,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0116, -0.7319, -0.6148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8901, -0.2864,  0.0708, -0.5744, -0.2016, -0.7190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2708 [00:04<11:21,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4788, -0.2618, -0.4735, -0.5339, -0.3104], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2708 [00:04<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9772, -0.3799, -0.5573, -0.5985, -0.6028], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4950, -0.8515, -0.5688, -0.4359, -0.5582, -0.3338], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3018, -1.0444, -0.6570, -0.8701, -0.1670, -0.8772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2708 [00:05<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0686, -0.9931], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2708 [00:05<11:26,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3826,  0.0631, -0.8968, -0.9487, -0.6614, -0.3889], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2708 [00:05<11:23,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6130,  0.0976, -0.6573], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2708 [00:05<11:31,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3956, -0.7277, -0.6689, -0.2478, -0.2256, -0.1082], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4049, -1.6713], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2708 [00:06<11:32,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3425, -0.5798, -0.1702, -0.2315, -0.4489, -0.2593, -0.5921, -0.3989],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7113, -0.5180, -0.6471, -0.6454, -0.7941], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2708 [00:07<11:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5213, -0.5076, -0.3410, -0.5158, -0.4208, -0.0247], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/2708 [00:07<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7930, -0.5129, -0.4541, -0.4210, -0.4524], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/2708 [00:07<11:46,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2461, -0.7360], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/2708 [00:07<11:57,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2923, -1.5444, -0.3596], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/2708 [00:08<12:08,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9600, -0.5965, -0.4892, -0.4216,  0.2531, -0.5733, -0.7309],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/2708 [00:08<11:52,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1677, -0.9148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 34/2708 [00:08<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0727, -0.4356, -0.0719, -0.8802, -0.3891], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 35/2708 [00:08<11:56,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6708, -0.2133, -0.4639, -0.0452, -0.1081, -0.2871, -0.5587, -0.3957,\n",
      "        -0.1813, -0.5420], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 36/2708 [00:09<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9400, -1.0512], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 37/2708 [00:09<11:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4529, -0.4503, -0.3648, -0.6088], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 38/2708 [00:09<11:38,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5024, -0.2346, -0.5609, -0.3737, -0.3356, -0.3844, -0.2932, -0.3747,\n",
      "        -0.2052], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 39/2708 [00:09<11:43,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3181, -0.1349, -0.4077, -0.1352], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 40/2708 [00:10<11:49,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9254, -0.6111, -0.1048, -0.3196, -0.2110], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 41/2708 [00:10<11:39,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4832, -0.8994, -0.2025, -0.5024, -0.3493, -0.3469, -0.3100, -0.1292],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 42/2708 [00:10<11:35,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9360, -0.1485, -0.8748, -0.8013], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 43/2708 [00:10<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5408, -0.5323, -0.5018, -0.2520, -0.5001], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 44/2708 [00:11<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9175, -0.6259, -0.8920], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 45/2708 [00:11<11:29,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5529, -0.4633, -0.6824, -0.1575, -0.6823, -0.4527, -0.1097],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 46/2708 [00:11<11:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7863, -0.6055, -0.3041, -0.7659], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 47/2708 [00:12<11:24,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6369, -0.1579,  0.0096, -0.2302, -0.7066, -0.8424, -0.8205],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 48/2708 [00:12<11:23,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5954, -0.7689, -1.0760], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/2708 [00:12<11:25,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6883, -0.7915, -0.8190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 50/2708 [00:12<11:31,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7514, -0.5609, -0.5929, -0.4977, -0.6895, -0.1147, -0.3839, -0.4977,\n",
      "        -0.3521, -0.1876], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 51/2708 [00:13<11:27,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9633, -0.3087, -0.7496], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 52/2708 [00:13<11:32,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0716, -0.7867], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8026, -0.6366, -0.5278, -0.3520, -0.0046, -0.2991, -0.3643],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 54/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2594, -0.6112, -0.5430, -0.0218, -0.8436, -0.6938], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 55/2708 [00:14<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6441, -0.4541, -0.7002, -0.3384], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 56/2708 [00:14<11:24,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5803, -0.7055, -1.0509], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 57/2708 [00:14<11:28,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9221,  0.3088, -0.4489, -0.3684, -0.2524, -0.0571, -0.5076, -0.1804,\n",
      "        -0.2160, -0.0491, -0.4002, -0.8905,  0.1593], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 58/2708 [00:14<11:34,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4749, -0.3756, -0.3725, -0.5048, -0.4532], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 59/2708 [00:15<11:46,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2448, -0.8058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 60/2708 [00:15<11:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3131, -1.6650], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 61/2708 [00:15<11:45,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4681, -0.5944, -0.3451, -0.4504, -0.3806, -0.3288, -0.3684, -0.7651,\n",
      "        -0.3525, -0.0654, -0.5855], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 62/2708 [00:15<11:42,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1158,  0.6875, -1.3673, -0.8284], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 63/2708 [00:16<11:49,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6049, -0.1793, -0.9846, -0.9551, -0.0148, -0.7559], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 64/2708 [00:16<11:47,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4189, -1.4566], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 65/2708 [00:16<11:40,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1445, -0.6135], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 66/2708 [00:17<11:26,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6229, -0.6396, -0.7113, -0.1714], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ig_spar \u001b[38;5;241m=\u001b[39m \u001b[43mig_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIG Spar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mig_spar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mig_sparsity\u001b[1;34m(model, graph, data_object)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[0;32m     33\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mIG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     total_sparse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_nonzeros(exp\u001b[38;5;241m.\u001b[39mnode_imp)\u001b[38;5;241m/\u001b[39mexp\u001b[38;5;241m.\u001b[39menc_subgraph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(exp\u001b[38;5;241m.\u001b[39mnode_imp)\n",
      "Cell \u001b[1;32mIn[3], line 1020\u001b[0m, in \u001b[0;36mIG\u001b[1;34m(node_idx, x, edge_index, y, num_hops, steps, model, criterion)\u001b[0m\n\u001b[0;32m   1018\u001b[0m output \u001b[38;5;241m=\u001b[39m model(temp_x, sub_edge_index)\n\u001b[0;32m   1019\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output[mapping], label)\n\u001b[1;32m-> 1020\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m grad \u001b[38;5;241m=\u001b[39m temp_x\u001b[38;5;241m.\u001b[39mgrad[torch\u001b[38;5;241m.\u001b[39mwhere(subset\u001b[38;5;241m==\u001b[39mnode_idx)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m   1022\u001b[0m grads[i] \u001b[38;5;241m=\u001b[39m grad\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [04:38<00:00,  9.73it/s]\n",
      "100%|| 2708/2708 [12:55<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [11:26<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [12:32:29<00:00, 16.67s/it]        \n",
      "100%|| 2708/2708 [17:32<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [10:33<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
