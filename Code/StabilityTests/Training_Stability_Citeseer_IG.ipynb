{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook trains a model with additional loss for Stability on Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "import torch\n",
    "dataset = Planetoid(root='/tmp/Citeseer/', name='Citeseer')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import k_hop_subgraph, to_undirected\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.data import Data\n",
    "from graphxai.explainers._base import _BaseExplainer\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "\n",
    "class _BaseExplainer:\n",
    "    \"\"\"\n",
    "    Base Class for Explainers\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            model: nn.Module,\n",
    "            emb_layer_name: Optional[str] = None,\n",
    "            is_subgraphx: Optional[bool] = False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "                The output of the model should be unnormalized class score.\n",
    "                For example, last layer = GCNConv or Linear.\n",
    "            emb_layer_name (str, optional): name of the embedding layer\n",
    "                If not specified, use the last but one layer by default.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.L = len([module for module in self.model.modules()\n",
    "                      if isinstance(module, MessagePassing)])\n",
    "        self.explain_graph = False  # Assume node-level explanation by default\n",
    "        self.subgraphx_flag = is_subgraphx\n",
    "        self.__set_embedding_layer(emb_layer_name)\n",
    "\n",
    "    def __set_embedding_layer(self, emb_layer_name: str = None):\n",
    "        \"\"\"\n",
    "        Set the embedding layer (by default is the last but one layer).\n",
    "        \"\"\"\n",
    "        if emb_layer_name:\n",
    "            try:\n",
    "                self.emb_layer = getattr(self.model, emb_layer_name)\n",
    "            except AttributeError:\n",
    "                raise ValueError(f'{emb_layer_name} does not exist in the model')\n",
    "        else:\n",
    "            self.emb_layer = list(self.model.modules())[-2]\n",
    "\n",
    "    def _get_embedding(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                       forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the embedding.\n",
    "        \"\"\"\n",
    "        emb = self._get_activation(self.emb_layer, x, edge_index, forward_kwargs)\n",
    "        return emb\n",
    "\n",
    "    def _set_masks(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                   edge_mask: torch.Tensor = None, explain_feature: bool = False,\n",
    "                   device = None):\n",
    "        \"\"\"\n",
    "        Initialize the edge (and feature) masks.\n",
    "        \"\"\"\n",
    "        (n, d), m = x.shape, edge_index.shape[1]\n",
    "\n",
    "        # Initialize edge_mask and feature_mask for learning\n",
    "        std = torch.nn.init.calculate_gain('relu') * np.sqrt(2.0 / (2 * n))\n",
    "        if edge_mask is None:\n",
    "            edge_mask = (torch.randn(m) * std).to(device)\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        else:\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        if explain_feature:\n",
    "            feature_mask = (torch.randn(d) * 0.1).to(device)\n",
    "            self.feature_mask = torch.nn.Parameter(feature_mask)\n",
    "\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # Tell pytorch geometric to apply edge masks\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def _clear_masks(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.edge_mask = None\n",
    "        self.feature_mask = None\n",
    "\n",
    "    def _flow(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def _predict(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                 return_type: str = 'label', forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the model's prediction.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            return_type (str): one of ['label', 'prob', 'log_prob']\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            pred (torch.Tensor, [n x ...]): model prediction\n",
    "        \"\"\"\n",
    "        # Compute unnormalized class score\n",
    "        with torch.no_grad():\n",
    "            out = self.model.to(device)(x, edge_index, **forward_kwargs)\n",
    "            if return_type == 'label':\n",
    "                out = out.argmax(dim=-1)\n",
    "            elif return_type == 'prob':\n",
    "                out = F.softmax(out, dim=-1)\n",
    "            elif return_type == 'log_prob':\n",
    "                out = F.log_softmax(out, dim=-1)\n",
    "            else:\n",
    "                raise ValueError(\"return_type must be 'label', 'prob', or 'log_prob'\")\n",
    "\n",
    "            if self.explain_graph:\n",
    "                out = out.squeeze()\n",
    "\n",
    "            return out\n",
    "\n",
    "    def _prob_score_func_graph(self, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probability that the input graphs\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            target_class (int): the targeted class of the graph\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        def get_prob_score(x: torch.Tensor,\n",
    "                           edge_index: torch.Tensor,\n",
    "                           forward_kwargs: dict = {}):\n",
    "            prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                 forward_kwargs=forward_kwargs)\n",
    "            score = prob[:, target_class]\n",
    "            return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _prob_score_func_node(self, node_idx: torch.Tensor, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probabilities that k specified nodes\n",
    "        in `torch_geometric.data.Batch` (disconnected union of the input graphs)\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            node_idx (torch.Tensor, [k]): the indices of the k nodes interested\n",
    "            target_class (torch.Tensor, [k]): the targeted classes of the k nodes\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        if self.subgraphx_flag:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[node_idx, target_class]\n",
    "                return score\n",
    "        else:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[:, node_idx, target_class]\n",
    "                return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _get_activation(self, layer: nn.Module, x: torch.Tensor,\n",
    "                        edge_index: torch.Tensor, forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the activation of the layer.\n",
    "        \"\"\"\n",
    "        activation = {}\n",
    "        def get_activation():\n",
    "            def hook(model, inp, out):\n",
    "                activation['layer'] = out.detach()\n",
    "            return hook\n",
    "\n",
    "        layer.register_forward_hook(get_activation())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return activation['layer']\n",
    "\n",
    "    def _get_k_hop_subgraph(self, node_idx: int, x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor, num_hops: int = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Extract the subgraph of target node\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): the node index\n",
    "            x (torch.Tensor, [n x d]): node feature matrix with shape\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index\n",
    "            kwargs (dict): additional parameters of the graph\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # TODO: use NamedTuple\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        return khop_info\n",
    "\n",
    "    def get_explanation_node(self, node_idx: int,\n",
    "                             x: torch.Tensor,\n",
    "                             edge_index: torch.Tensor,\n",
    "                             label: torch.Tensor = None,\n",
    "                             num_hops: int = None,\n",
    "                             forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): index of the node to be explained\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            label (torch.Tensor, optional, [n x ...]): labels to explain\n",
    "                If not provided, we use the output of the model.\n",
    "            num_hops (int, optional): number of hops to consider\n",
    "                If not provided, we use the number of graph layers of the GNN.\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "            khop_info (4-tuple of torch.Tensor):\n",
    "                0. the nodes involved in the subgraph\n",
    "                1. the filtered `edge_index`\n",
    "                2. the mapping from node indices in `node_idx` to their new location\n",
    "                3. the `edge_index` mask indicating which edges were preserved\n",
    "        \"\"\"\n",
    "        # If labels are needed\n",
    "        label = self._predict(x, edge_index, return_type='label') if label is None else label\n",
    "        # If probabilities / log probabilities are needed\n",
    "        prob = self._predict(x, edge_index, return_type='prob')\n",
    "        log_prob = self._predict(x, edge_index, return_type='log_prob')\n",
    "\n",
    "        num_hops = self.L if num_hops is None else num_hops\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return exp, khop_info\n",
    "\n",
    "    def get_explanation_graph(self, edge_index: torch.Tensor,\n",
    "                              x: torch.Tensor, label: torch.Tensor,\n",
    "                              forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a whole-graph prediction.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            label (torch.Tensor, [n x ...]): labels to explain\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "        \"\"\"\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_explanation_link(self):\n",
    "        \"\"\"\n",
    "        Explain a link prediction.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph as subgraph\n",
    "\n",
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class _BaseDecomposition(_BaseExplainer):\n",
    "    '''\n",
    "    Code adapted from Dive into Graphs (DIG)\n",
    "    Code: https://github.com/divelab/DIG\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__(model=model) # Will set self.model = model\n",
    "        # Other properties: self.L (number of layers)\n",
    "\n",
    "    @property\n",
    "    def __num_hops__(self):\n",
    "        if self.explain_graph:\n",
    "            return -1\n",
    "        else:\n",
    "            return self.L\n",
    "    \n",
    "    def set_graph_attr(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.num_edges = edge_index.shape[1]\n",
    "        self.num_nodes = x.shape[0]\n",
    "        self.device = x.device\n",
    "\n",
    "    def extract_step(self, x: Tensor, edge_index: Tensor, detach: bool = True, split_fc: bool = False, forward_kwargs: dict = None):\n",
    "        '''Gets information about every layer in the graph\n",
    "        Args:\n",
    "\n",
    "            forward_kwargs (tuple, optional): Additional arguments to model forward call (other than x and edge_index)\n",
    "                (default: :obj:`None`)\n",
    "        '''\n",
    "\n",
    "        layer_extractor = []\n",
    "        hooks = []\n",
    "\n",
    "        def register_hook(module: nn.Module):\n",
    "            if not list(module.children()) or isinstance(module, MessagePassing):\n",
    "                hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "        def forward_hook(module: nn.Module, input: Tuple[Tensor], output: Tensor):\n",
    "            # input contains x and edge_index\n",
    "            if detach:\n",
    "                layer_extractor.append((module, input[0].clone().detach(), output.clone().detach()))\n",
    "            else:\n",
    "                layer_extractor.append((module, input[0], output))\n",
    "\n",
    "        # --- register hooks ---\n",
    "        self.model.apply(register_hook)\n",
    "\n",
    "        # ADDED: OWEN QUEEN --------------\n",
    "        if forward_kwargs is None:\n",
    "            _ = self.model(x, edge_index)\n",
    "        else:\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "        # --------------------------------\n",
    "        # Remove hooks:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        # --- divide layer sets ---\n",
    "\n",
    "        # print('Layer extractor', [layer_extractor[i][0] for i in range(len(layer_extractor))])\n",
    "\n",
    "        walk_steps = []\n",
    "        fc_steps = []\n",
    "        pool_flag = False\n",
    "        step = {'input': None, 'module': [], 'output': None}\n",
    "        for layer in layer_extractor:\n",
    "            if isinstance(layer[0], MessagePassing):\n",
    "                if step['module']: # Append step that had previously been building\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], GNNPool):\n",
    "                pool_flag = True\n",
    "                if step['module']:\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                # Putting in GNNPool\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], nn.Linear):\n",
    "                if step['module']:\n",
    "                    if isinstance(step['module'][0], MessagePassing):\n",
    "                        walk_steps.append(step) # Append MessagePassing layer to walk_steps\n",
    "                    else: # Always append Linear layers to fc_steps\n",
    "                        fc_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            # Also appends non-trainable layers to step (not modifying input):\n",
    "            step['module'].append(layer[0])\n",
    "            step['output'] = layer[2]\n",
    "\n",
    "        if step['module']:\n",
    "            if isinstance(step['module'][0], MessagePassing):\n",
    "                walk_steps.append(step)\n",
    "            else: # Append anything to FC that is not MessagePassing at its origin\n",
    "                # Still supports sequential layers\n",
    "                fc_steps.append(step)\n",
    "            # print('layer', layer[0])\n",
    "            # if isinstance(layer[0], MessagePassing) or isinstance(layer[0], GNNPool):\n",
    "            #     if isinstance(layer[0], GNNPool):\n",
    "            #         pool_flag = True\n",
    "            #     if step['module'] and step['input'] is not None:\n",
    "            #         walk_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # if pool_flag and split_fc and isinstance(layer[0], nn.Linear):\n",
    "            #     if step['module']:\n",
    "            #         fc_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # step['module'].append(layer[0])\n",
    "            # step['output'] = layer[2]\n",
    "\n",
    "        for walk_step in walk_steps:\n",
    "            if hasattr(walk_step['module'][0], 'nn') and walk_step['module'][0].nn is not None:\n",
    "                # We don't allow any outside nn during message flow process in GINs\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "            elif hasattr(walk_step['module'][0], 'lin') and walk_step['module'][0].lin is not None:\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "\n",
    "        # print('Walk steps', [walk_steps[i]['module'] for i in range(len(walk_steps))])\n",
    "        # print('fc steps', [fc_steps[i]['module'] for i in range(len(fc_steps))])\n",
    "\n",
    "        return walk_steps, fc_steps\n",
    "\n",
    "    def walks_pick(self,\n",
    "                   edge_index: Tensor,\n",
    "                   pick_edge_indices: List,\n",
    "                   walk_indices: List=[],\n",
    "                   num_layers=0\n",
    "                   ):\n",
    "        walk_indices_list = []\n",
    "        for edge_idx in pick_edge_indices:\n",
    "\n",
    "            # Adding one edge\n",
    "            walk_indices.append(edge_idx)\n",
    "            _, new_src = src, tgt = edge_index[:, edge_idx]\n",
    "            next_edge_indices = np.array((edge_index[0, :] == new_src).nonzero().view(-1))\n",
    "\n",
    "            # Finding next edge\n",
    "            if len(walk_indices) >= num_layers:\n",
    "                # return one walk\n",
    "                walk_indices_list.append(walk_indices.copy())\n",
    "            else:\n",
    "                walk_indices_list += self.walks_pick(edge_index, next_edge_indices, walk_indices, num_layers)\n",
    "\n",
    "            # remove the last edge\n",
    "            walk_indices.pop(-1)\n",
    "\n",
    "        return walk_indices_list\n",
    "\n",
    "class CAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, activation = None):\n",
    "        '''\n",
    "        .. note::\n",
    "            From Pope et al., CAM requires that the layer immediately before the softmax layer be\n",
    "            a global average pooling layer, or in the case of node classification, a graph convolutional\n",
    "            layer. Therefore, for this algorithm to theoretically work, there can be no fully-connected\n",
    "            layers after global pooling. There is no restriction in the code for this, but be warned. \n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            activation (method, optional): activation funciton for final layer in network. If `activation = None`,\n",
    "                explainer assumes linear activation. Use `activation = None` if the activation is applied\n",
    "                within the `forward` method of `model`, only set this parameter if another activation is\n",
    "                applied in the training procedure outside of model. (:default: :obj:`None`)\n",
    "        '''\n",
    "        super().__init__(model=model)\n",
    "        self.model = model\n",
    "\n",
    "        # Set activation function\n",
    "        self.activation = lambda x: x  if activation is None else activation\n",
    "        # i.e. linear activation if none provided\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                node_idx: int, \n",
    "                edge_index: torch.Tensor, \n",
    "                label: int = None,  \n",
    "                y = None,\n",
    "                forward_kwargs: dict = {},\n",
    "                directed: bool = False\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Explain one node prediction by the model\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.tensor): edge_index of entire graph\n",
    "            label (int, optional): Label on which to compute the explanation for\n",
    "                this node. If `None`, the predicted label from the model will be\n",
    "                used. (default: :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "            directed (bool, optional): If True, graph is directed.\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        if not directed:\n",
    "            edge_index = to_undirected(edge_index)\n",
    "\n",
    "        if label is None:\n",
    "            if y is None:\n",
    "                label = int(self.__forward_pass(x, edge_index, forward_kwargs).argmax(dim=1).item())\n",
    "            else:\n",
    "                label = y[node_idx]\n",
    "\n",
    "        # Perform walk:\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=False, split_fc=False, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        # Get subgraph:\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        #cam = torch.zeros(N) # Compute CAM only over the subgraph (all others are zero)\n",
    "        cam = torch.zeros(subgraph_N)\n",
    "        for i in range(subgraph_N):\n",
    "            n = subgraph_nodes[i]\n",
    "            cam[i] += self.__exp_node(n, walk_steps, label)\n",
    "\n",
    "        # Set Explanation class:\n",
    "        exp = Explanation(\n",
    "            node_imp = cam,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs = {}):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, predicted_c):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after last convolutiuonal layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        last_conv_layer = walk_steps[-1]\n",
    "\n",
    "        if isinstance(last_conv_layer['module'][0], GINConv):\n",
    "            weight_vec = last_conv_layer['module'][0].nn.weight[predicted_c, :].detach()  # last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], GCNConv):\n",
    "            weight_vec = last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], torch.nn.Linear):\n",
    "            weight_vec = last_conv_layer['module'][0].weight[predicted_c, :].detach()\n",
    "\n",
    "        F_l_n = F.relu(last_conv_layer['input'][node_idx,:]).detach()\n",
    "\n",
    "        L_cam_n = F.relu(torch.matmul(weight_vec, F_l_n))\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "\n",
    "class GradCAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Gradient Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.Tensor, criterion = F.cross_entropy):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "            x: torch.Tensor, \n",
    "            y: torch.Tensor, \n",
    "            node_idx: int, \n",
    "            edge_index: torch.Tensor, \n",
    "            label: int = None, \n",
    "            forward_kwargs: dict = {}, \n",
    "            average_variant: bool = True, \n",
    "            layer: int = 0\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a node in the given graph\n",
    "        Args:\n",
    "            x (torch.Tensor, (n,)): Tensor of node features from the entire graph, with n nodes.\n",
    "            y (torch.Tensor, (n,)): Ground-truth labels for all n nodes in the graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.Tensor): Edge_index of entire graph.\n",
    "            label (int, optional): Label for which to compute Grad-CAM against. If None, computes\n",
    "                the Grad-CAM with respect to the model's predicted class for this node.\n",
    "                (default :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. (default: :obj:`None`)\n",
    "            average_variant (bool, optional): If True, computes the average Grad-CAM across all convolutional\n",
    "                layers in the model. If False, computes Grad-CAM for `layer`. (default: :obj:`True`)\n",
    "            layer (int, optional): Layer by which to compute the Grad-CAM. Argument only has an effect if \n",
    "                `average_variant == True`. Must be less-than the total number of convolutional layers\n",
    "                in the model. (default: :obj:`0`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        x = x.detach().clone()\n",
    "        y = y.detach().clone()\n",
    "\n",
    "        x.requires_grad = True\n",
    "\n",
    "        if label is None:\n",
    "            pred = self.__forward_pass(x, y, edge_index, forward_kwargs)[0][node_idx, :].reshape(1, -1)\n",
    "            y[node_idx] = pred.argmax(dim=1).item()\n",
    "        else: # Transform node_idx's label if provided by user\n",
    "            pred, loss = self.__forward_pass(x, y, edge_index, forward_kwargs)\n",
    "            y[node_idx] = label\n",
    "\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=True, split_fc=True, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx, self.L, edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        if average_variant:\n",
    "            # Size of all nodes in the subgraph:\n",
    "            avg_gcam = torch.zeros(subgraph_N)\n",
    "\n",
    "            for l in range(self.L):\n",
    "                # Compute gradients for this layer ahead of time:\n",
    "                gradients = self.__grad_by_layer(l)\n",
    "\n",
    "                for i in range(subgraph_N): # Over all subgraph nodes\n",
    "                    n = subgraph_nodes[i]\n",
    "                    avg_gcam[i] += self.__get_gCAM_layer(walk_steps, l, n, gradients)\n",
    "\n",
    "            avg_gcam /= self.L # Apply average\n",
    "\n",
    "            exp.node_imp = avg_gcam\n",
    "\n",
    "        else:\n",
    "            assert layer < len(walk_steps), \"Layer must be an index of convolutional layers\"\n",
    "\n",
    "            gcam = torch.zeros(subgraph_N)\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "            for i in range(subgraph_N):\n",
    "                n = subgraph_nodes[i]\n",
    "                gcam[i] += self.__get_gCAM_layer(walk_steps, layer, n, gradients)#[0]\n",
    "\n",
    "            exp.node_imp = gcam\n",
    "\n",
    "        return exp\n",
    "        \n",
    "    def __forward_pass(self, x, label, edge_index, forward_kwargs):\n",
    "        x.requires_grad = True # Enforce that x needs gradient\n",
    "\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        loss = self.criterion(pred, label)\n",
    "        loss.backward() # Propagate loss backward through network\n",
    "\n",
    "        return pred, loss\n",
    "\n",
    "    def __grad_by_layer(self, layer):\n",
    "        # Index 0 of parameters to avoid calculating gradients for biases\n",
    "        module_at_layer = list(self.model.children())[layer]\n",
    "\n",
    "        if isinstance(module_at_layer, GCNConv):\n",
    "            grad = module_at_layer.lin.weight.grad\n",
    "        elif isinstance(module_at_layer, GINConv):\n",
    "            grad = module_at_layer.nn.weight.grad\n",
    "        else:\n",
    "            grad = module_at_layer.weight.grad\n",
    "\n",
    "        return grad.mean(dim=1)\n",
    "\n",
    "    def __get_gCAM_layer(self, walk_steps, layer, node_idx = None, gradients = None):\n",
    "        # Gets Grad CAM for one layer\n",
    "        if gradients is None:\n",
    "            # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "            # ''        '' shape: [k,] - k= # output features from layer l\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "\n",
    "        if node_idx is None: # Need to compute for entire graph:\n",
    "            node_explanations = []\n",
    "            for n in range(self.N):\n",
    "                node_explanations.append(self.__exp_node(n, walk_steps, layer, gradients))\n",
    "\n",
    "            return node_explanations\n",
    "\n",
    "        # Return for only one node:\n",
    "        return self.__exp_node(node_idx, walk_steps, layer, gradients)\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, layer, gradients):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after each convolutional layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "        # ''        '' shape: [k,] - k= # input features to layer l\n",
    "\n",
    "        # Activations for node n\n",
    "        F_l_n = F.relu(walk_steps[layer]['output'][node_idx,:]).detach()\n",
    "        L_cam_n = F.relu(torch.matmul(gradients, F_l_n)) # Combine gradients and activations\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "# from ._decomp_base_old import _BaseDecomposition\n",
    "\n",
    "def clip_hook(grad):\n",
    "    # Apply ReLU activation to gradient\n",
    "    return torch.clamp(grad, min=0)\n",
    "import gc\n",
    "\n",
    "class GuidedBP(_BaseDecomposition):\n",
    "\n",
    "    def __init__(self, model, criterion = F.cross_entropy, enforce_requires_grad = True):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.L = len([module for module in self.model.modules() if isinstance(module, MessagePassing)])\n",
    "\n",
    "        self.registered_hooks = []\n",
    "\n",
    "        self.enforce_requires_grad = enforce_requires_grad\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor,\n",
    "                edge_index: torch.Tensor,  \n",
    "                node_idx: int, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Get Guided Backpropagation explanation for one node in the graph\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            y (torch.Tensor): Ground truth labels correspond to each node's \n",
    "                classification. This argument is input to the `criterion` \n",
    "                function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the enclosing \n",
    "                subgraph. Must support `dim` argument.\n",
    "                (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        if self.enforce_requires_grad:\n",
    "            try:\n",
    "                x = x.detach().clone()\n",
    "                x.requires_grad = True\n",
    "            except:\n",
    "                pass\n",
    "        # assert x.requires_grad, 'x must have requires_grad == True'\n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        graph_exp = x.grad\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        node_imp = aggregate_node_imp(torch.stack([graph_exp[i,:] for i in subgraph_nodes]).detach(), dim=1)\n",
    "\n",
    "        # Get only those explanations for nodes in the subgraph:\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        \n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        return exp\n",
    "\n",
    "    def get_explanation_graph(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor, \n",
    "                edge_index: torch.Tensor, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a whole-graph prediction with Guided Backpropagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor of node features from the entire graph.\n",
    "            y (torch.tensor): Ground truth label of given input. This argument is \n",
    "                input to the `criterion` function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the graph. \n",
    "                Must support `dim` argument. (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)   \n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method. \n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [num_nodes, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `graph`: :obj:`torch_geometric.data.Data`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        try:\n",
    "            x.requires_grad = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        assert x.requires_grad, 'x must have requires_grad == True' \n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        node_imp = aggregate_node_imp(x.grad, dim=1)\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp\n",
    "        )\n",
    "    \n",
    "        exp.set_whole_graph(Data(x, edge_index))\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __apply_hooks(self):\n",
    "        self.registered_hooks = []\n",
    "        for p in self.model.parameters():\n",
    "            h = p.register_hook(clip_hook)\n",
    "            self.registered_hooks.append(h)\n",
    "\n",
    "    def __rm_hooks(self):\n",
    "        for h in self.registered_hooks:\n",
    "            h.remove()\n",
    "        self.registered_hooks = []\n",
    "    \n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        self.__apply_hooks()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "from graphxai.utils import Explanation\n",
    "class IG():\n",
    "    def __init__(self, model, hops: Optional[int] = 1, criterion = None):\n",
    "        self.model = model\n",
    "        self.num_hops = hops\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def node_explanations(self, node_idx: int, \n",
    "            x: torch.Tensor,\n",
    "            edge_index: torch.Tensor, \n",
    "            y: Optional[torch.Tensor] = None,):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): Index of the node to be explained.\n",
    "            edge_index (torch.Tensor, [2 x m]): Edge index of the graph.\n",
    "            x (torch.Tensor, [n x d]): Node features.\n",
    "            label (torch.Tensor, [n x ...]): Labels to explain.\n",
    "            y (torch.Tensor): Same as `label`, provided for general \n",
    "                compatibility in the arguments. (:default: :obj:`None`)\n",
    "            num_hops (int, optional): Number of hops in the enclosing \n",
    "                subgraph. If `None`, set to the number of layers in \n",
    "                the GNN. (:default: :obj:`None`)\n",
    "            steps (int, optional): Number of steps for the Riemannian \n",
    "                integration. (:default: :obj:`40`)\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`torch.Tensor, [x.shape[1],]`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :class:`graphxai.utils.EnclosingSubgraph`\n",
    "        \"\"\"\n",
    "\n",
    "        if (y is None):\n",
    "            raise ValueError('Either label or y should be provided for Integrated Gradients')\n",
    "\n",
    "        label = y[node_idx]\n",
    "        if len(label.shape) == 0:\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, self.num_hops, edge_index,\n",
    "                            relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "        steps = 40\n",
    "        self.model.eval()\n",
    "        grads = torch.zeros(steps+1, x.shape[1]).to(device)\n",
    "\n",
    "        # Perform Riemannian integration\n",
    "        for i in range(steps+1):\n",
    "            with torch.no_grad():\n",
    "                baseline = torch.zeros_like(sub_x).to(device)  # TODO: baseline all 0s, all 1s, ...?\n",
    "                temp_x = baseline + (float(i)/steps) * (sub_x.clone()-baseline)\n",
    "            temp_x.requires_grad = True\n",
    "            output = self.model(temp_x, sub_edge_index)\n",
    "            loss = self.criterion(output[mapping], label)\n",
    "            loss.backward()\n",
    "            grad = temp_x.grad[torch.where(subset==node_idx)[0].item()]\n",
    "            grads[i] = grad\n",
    "\n",
    "        grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "        avg_grads = torch.mean(grads, axis=0)\n",
    "\n",
    "        # Integrated gradients for only node_idx:\n",
    "        # baseline[0] just gets a single-value 0-tensor\n",
    "        integrated_gradients = ((x[torch.where(subset == node_idx)[0].item()]\n",
    "                                    - baseline[0]) * avg_grads)\n",
    "\n",
    "        # Integrated gradients across the enclosing subgraph:\n",
    "        all_node_ig = ((x[subset] - baseline) * avg_grads)\n",
    "        node_importances = torch.sum(all_node_ig, dim=1)\n",
    "        exp = Explanation(\n",
    "            feature_imp = integrated_gradients,\n",
    "            node_imp = node_importances,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        gc.collect()\n",
    "        return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import random\n",
    "from copy import deepcopy\n",
    "random.seed(12345)\n",
    "def perturbed_edge_list(data: torch_geometric.data.Data, n_to_add: int = 2)->torch_geometric.data.Data:\n",
    "    \"\"\"Adding two random nodes to each node\"\"\"\n",
    "    # Do not want seed here\n",
    "    edge_list = data.edge_index\n",
    "    # torch.cat((edge_list, torch.LongTensor((1,2)).to(device).reshape(1,-1)), dim=-1)\n",
    "    # print(edge_list)\n",
    "    data = deepcopy(data)\n",
    "    for node in range(data.x.shape[0]):\n",
    "        # generating two random nodes to add to its adjacency list\n",
    "        for i in range(n_to_add):\n",
    "            n1 = randint(0, data.x.shape[0]-1)\n",
    "            new1 = torch.cat((edge_list[0], torch.LongTensor([node]).to(device)), axis=-1)\n",
    "            new2 = torch.cat((edge_list[1], torch.LongTensor([n1]).to(device)), axis=-1)\n",
    "            edge_list = torch.cat([new1.reshape(1,-1), new2.reshape(1,-1)])\n",
    "    data.edge_index = edge_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def explanation_list_to_matrix(l: list, data)->torch.Tensor:\n",
    "    len_l = len(l)\n",
    "    matrix = torch.zeros((len_l, data.x.shape[0]))\n",
    "    with tqdm(total=len_l) as pbar:\n",
    "        for i, exp in enumerate(l):\n",
    "            pbar.update(1)\n",
    "            subgraph = exp.enc_subgraph.nodes\n",
    "            for j, n in enumerate(subgraph):\n",
    "                n = n.item()\n",
    "                matrix[i][n] = exp.node_imp[j].item()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def stability(generated_exp_unperturbed, generated_exp_perturbed ) -> float:\n",
    "    \"\"\"takes in two matrices the first is unperturbed explanations and the second are perturbed via the addition of a random node\n",
    "        - We assume here that the explanations are in their padded form that is: that the explanation vectors in the list have nodes at equal positions \"\"\"\n",
    "    stability = float() \n",
    "    # Accessing the enclosing subgraph. Will be the same for both explanation.:\n",
    "    stability = abs( np.linalg.norm(np.matrix(generated_exp_unperturbed.numpy())) - np.linalg.norm(np.matrix(generated_exp_perturbed.numpy())) )\n",
    "    return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the random nodes\n",
    "from random import sample\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "# I now want all nodes for each given class (there are 7), and I will randomly select 50 of each class\n",
    "class_0 = [idx for idx, val in enumerate(data.y) if val == 0]\n",
    "class_1 = [idx for idx, val in enumerate(data.y) if val == 1]\n",
    "class_2 = [idx for idx, val in enumerate(data.y) if val == 2]\n",
    "class_3 = [idx for idx, val in enumerate(data.y) if val == 3]\n",
    "class_4 = [idx for idx, val in enumerate(data.y) if val == 4]\n",
    "class_5 = [idx for idx, val in enumerate(data.y) if val == 5]\n",
    "\n",
    "random_class_0 = sample(class_0, k=50)\n",
    "random_class_1 = sample(class_1, k=50)\n",
    "random_class_2 = sample(class_2, k=50)\n",
    "random_class_3 = sample(class_3, k=50)\n",
    "random_class_4 = sample(class_4, k=50)\n",
    "random_class_5 = sample(class_5, k=50)\n",
    "\n",
    "\n",
    "random_nodes = random_class_0\n",
    "random_nodes.extend(random_class_1)\n",
    "random_nodes.extend(random_class_2)\n",
    "random_nodes.extend(random_class_3)\n",
    "random_nodes.extend(random_class_4)\n",
    "random_nodes.extend(random_class_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbp_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    bp_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = GuidedBP(model=model)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            bp_exps.append(exp)\n",
    "    return bp_exps\n",
    "\n",
    "def cam_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    cam_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = CAM(model=model)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x = data_object.x, edge_index = data_object.edge_index,  y = data_object.y)\n",
    "            cam_exps.append(exp)\n",
    "    return cam_exps\n",
    "\n",
    "def ig_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    ig_exps = list()\n",
    "    model.eval()\n",
    "    ig = IG(model=model, criterion=torch.nn.CrossEntropyLoss(), hops=1)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = ig.node_explanations(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            ig_exps.append(exp)\n",
    "    return ig_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_data = perturbed_edge_list(data=data).to(device) # this is our perturbed data to check against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 300/300 [01:18<00:00,  3.85it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3668.66it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2290.07it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2265.20it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.74it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2500.01it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.53it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.22it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.50it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2459.04it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.50it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2400.00it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2290.08it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]]\n",
      "100%|| 300/300 [01:17<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3750.13it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2400.01it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.20it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.55it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2307.72it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.77it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2189.81it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3834.73it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2290.09it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2255.68it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.83it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2142.86it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]t]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.61it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2380.95it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.79it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2380.99it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.55it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.24it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3488.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2189.76it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.55it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2399.96it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.82it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3750.16it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.04it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]t]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2205.87it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]t]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.77it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2375.08it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3604.77it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1948.07it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2399.98it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3608.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2380.98it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.53it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2205.92it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1674.58it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.42it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.80it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.85it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.72it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.01it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.83it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.23it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.68it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2083.35it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2222.25it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.53it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2419.41it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.54it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2173.91it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3750.10it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.24it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3296.72it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2400.03it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2255.65it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3692.60it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.23it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.82it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3217.97it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2400.03it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3409.13it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2125.42it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.46it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2222.23it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2189.77it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.75it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.76it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2380.97it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3448.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2400.03it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.81it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.53it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.05it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.85it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.66it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2399.99it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.55it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2290.09it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2419.41it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.61it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.75it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.55it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1875.02it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.43it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1875.02it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.63it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.75it/s]\n",
      "100%|| 300/300 [01:18<00:00,  3.81it/s]/it]\n",
      "100%|| 300/300 [01:18<00:00,  3.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.08it/s]\n",
      "100%|| 300/300 [01:38<00:00,  3.05it/s]/it]\n",
      "100%|| 300/300 [02:04<00:00,  2.41it/s]\n",
      "100%|| 300/300 [00:00<00:00, 4190.11it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2723.31it/s]\n",
      "100%|| 300/300 [02:03<00:00,  2.43it/s]/it]\n",
      "100%|| 300/300 [02:42<00:00,  1.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3523.12it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2425.22it/s]\n",
      "100%|| 300/300 [03:10<00:00,  1.57it/s]/it]\n",
      "100%|| 300/300 [02:29<00:00,  2.01it/s]\n",
      "100%|| 300/300 [00:00<00:00, 4159.70it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2549.11it/s]\n",
      "100%|| 300/300 [02:41<00:00,  1.86it/s]/it]\n",
      "100%|| 300/300 [02:18<00:00,  2.17it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3543.64it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2571.09it/s]\n",
      "100%|| 300/300 [02:18<00:00,  2.16it/s]/it]\n",
      "100%|| 300/300 [02:22<00:00,  2.10it/s]\n",
      "100%|| 300/300 [00:00<00:00, 4189.04it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2645.21it/s]\n",
      "100%|| 300/300 [02:17<00:00,  2.18it/s]/it]\n",
      "100%|| 300/300 [02:29<00:00,  2.00it/s]\n",
      "100%|| 300/300 [00:00<00:00, 4048.63it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2723.10it/s]\n",
      "100%|| 300/300 [02:26<00:00,  2.04it/s]/it]\n",
      "100%|| 300/300 [02:31<00:00,  1.98it/s]\n",
      "100%|| 300/300 [00:00<00:00, 4340.75it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2651.15it/s]\n",
      "100%|| 300/300 [02:13<00:00,  2.25it/s]/it]\n",
      "100%|| 300/300 [02:22<00:00,  2.11it/s]\n",
      "100%|| 300/300 [00:00<00:00, 4278.97it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2748.51it/s]\n",
      "100%|| 300/300 [02:42<00:00,  1.85it/s]/it]\n",
      "100%|| 300/300 [02:36<00:00,  1.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2419.40it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.78it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]/it]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.56it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2040.83it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3061.28it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2325.62it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.35it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2112.68it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3750.03it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.04it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3333.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2272.77it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2307.72it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.64it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2173.94it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.87it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3409.15it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2419.38it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3448.37it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2343.77it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]/it]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.51it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2203.50it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.95it/s]/it]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.86it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2189.81it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.97it/s]t]  \n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3751.00it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.23it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]t]\n",
      "100%|| 300/300 [01:14<00:00,  4.04it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.48it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2325.60it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.96it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3448.45it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2272.78it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.90it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.62it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2400.00it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]t]\n",
      "100%|| 300/300 [01:15<00:00,  3.97it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.60it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2283.82it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.97it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2608.77it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2255.68it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2413.29it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3750.09it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.04it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.97it/s]t]\n",
      "100%|| 300/300 [01:15<00:00,  3.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.52it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2380.96it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]t]\n",
      "100%|| 300/300 [01:15<00:00,  3.96it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.43it/s]\n",
      "100%|| 300/300 [00:00<00:00, 1785.73it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3750.07it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2380.95it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3409.18it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2439.06it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.92it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3488.44it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.26it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.84it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2419.41it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.89it/s]t]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3614.57it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2184.83it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]t]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3607.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2362.19it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]t]\n",
      "100%|| 300/300 [01:15<00:00,  3.97it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3658.59it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2399.98it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.45it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2290.11it/s]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]t]\n",
      "100%|| 300/300 [01:15<00:00,  3.95it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3571.47it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2079.54it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.93it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.94it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.36it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2340.19it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.90it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3370.87it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2307.72it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.90it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3797.63it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2515.76it/s]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]t]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3529.40it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2238.80it/s]\n",
      "100%|| 300/300 [01:17<00:00,  3.88it/s]it]\n",
      "100%|| 300/300 [01:16<00:00,  3.91it/s]\n",
      "100%|| 300/300 [00:00<00:00, 3703.83it/s]\n",
      "100%|| 300/300 [00:00<00:00, 2419.36it/s]\n",
      "100%|| 100/100 [4:37:26<00:00, 166.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "ig_stability_list = list()\n",
    "loss_list = list()\n",
    "f1_accuracy_list = list()\n",
    "\n",
    "with tqdm(total=100) as pbar:\n",
    "    for epoch in range(100):\n",
    "        pbar.update(1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "        # measuring the stability\n",
    "        ig_explanations_unperturbed = ig_exps(model, graph, data, random_nodes=random_nodes) # unperturbed\n",
    "        ig_explanations_perturbed = ig_exps(model, graph, perturbed_data, random_nodes=random_nodes) # unperturbed\n",
    "\n",
    "        ig_matrix_unperturbed = explanation_list_to_matrix(ig_explanations_unperturbed, data) \n",
    "        ig_matrix_perturbed = explanation_list_to_matrix(ig_explanations_perturbed, data) \n",
    "\n",
    "        # getting the stability\n",
    "        ig_stab = stability(ig_matrix_unperturbed, ig_matrix_perturbed)\n",
    "        loss = loss.add(torch.tensor([ig_stab], requires_grad=True).to(device) )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_list.append(loss)\n",
    "        ig_stability_list.append(ig_stab)\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = multiclass_f1_score(pred, data.y, num_classes=dataset.num_classes)\n",
    "        f1_accuracy_list.append(f1)\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving values to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Stability_100_citeseer_IG.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x242bcf00370>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i.item() for i in loss_list], label=\"Loss\")\n",
    "plt.plot([i for i in ig_stability_list], label=\"Stability\")\n",
    "plt.plot([i.item() for i in f1_accuracy_list], label=\"Macro F1\")\n",
    "plt.title(\"Loss, Stability & Accuracy vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(loss_list[i].item(), ig_stability_list[i], f1_accuracy_list[i].item()) for i in range(len(loss_list))], columns=[\"Loss\", \"IG Stability\", \"F1 Accuracy\"])\n",
    "df.to_csv(\"Training_for_IG_Stability_Citeseer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [16:38<00:00,  2.71it/s]\n",
      "100%|| 2708/2708 [26:29<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2708 [00:00<07:28,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6574, -0.7225, -0.6013, -0.5233], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2708 [00:00<08:56,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5203, -0.3700, -0.7551, -0.9783], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2708 [00:00<09:50,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8562, -0.5766, -0.4730, -1.1368, -0.3823,  0.0726], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2708 [00:01<10:19,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1077, -0.7583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2708 [00:01<11:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5199, -0.6340, -0.2173, -0.2145, -0.0319, -0.6756], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2708 [00:01<11:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4461, -0.9948, -0.4571, -0.6390], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2708 [00:01<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4153, -0.4828, -0.5654, -0.5037, -0.5363], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2708 [00:02<11:29,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7944, -0.2029], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2708 [00:02<11:34,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6189, -0.9601, -0.6968, -0.6772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2708 [00:02<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1621, -0.9223, -0.8898], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/2708 [00:02<11:29,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8606, -0.7249, -0.6413], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/2708 [00:03<11:26,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3526, -0.1813, -0.2870], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4200, -0.2410, -0.5283, -0.3195, -0.4002], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2708 [00:03<11:19,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0116, -0.7319, -0.6148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8901, -0.2864,  0.0708, -0.5744, -0.2016, -0.7190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2708 [00:04<11:21,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4788, -0.2618, -0.4735, -0.5339, -0.3104], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2708 [00:04<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9772, -0.3799, -0.5573, -0.5985, -0.6028], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4950, -0.8515, -0.5688, -0.4359, -0.5582, -0.3338], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3018, -1.0444, -0.6570, -0.8701, -0.1670, -0.8772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2708 [00:05<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0686, -0.9931], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2708 [00:05<11:26,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3826,  0.0631, -0.8968, -0.9487, -0.6614, -0.3889], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2708 [00:05<11:23,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6130,  0.0976, -0.6573], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2708 [00:05<11:31,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3956, -0.7277, -0.6689, -0.2478, -0.2256, -0.1082], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4049, -1.6713], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2708 [00:06<11:32,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3425, -0.5798, -0.1702, -0.2315, -0.4489, -0.2593, -0.5921, -0.3989],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7113, -0.5180, -0.6471, -0.6454, -0.7941], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2708 [00:07<11:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5213, -0.5076, -0.3410, -0.5158, -0.4208, -0.0247], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/2708 [00:07<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7930, -0.5129, -0.4541, -0.4210, -0.4524], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/2708 [00:07<11:46,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2461, -0.7360], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/2708 [00:07<11:57,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2923, -1.5444, -0.3596], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/2708 [00:08<12:08,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9600, -0.5965, -0.4892, -0.4216,  0.2531, -0.5733, -0.7309],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/2708 [00:08<11:52,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1677, -0.9148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 34/2708 [00:08<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0727, -0.4356, -0.0719, -0.8802, -0.3891], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 35/2708 [00:08<11:56,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6708, -0.2133, -0.4639, -0.0452, -0.1081, -0.2871, -0.5587, -0.3957,\n",
      "        -0.1813, -0.5420], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 36/2708 [00:09<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9400, -1.0512], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 37/2708 [00:09<11:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4529, -0.4503, -0.3648, -0.6088], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 38/2708 [00:09<11:38,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5024, -0.2346, -0.5609, -0.3737, -0.3356, -0.3844, -0.2932, -0.3747,\n",
      "        -0.2052], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 39/2708 [00:09<11:43,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3181, -0.1349, -0.4077, -0.1352], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 40/2708 [00:10<11:49,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9254, -0.6111, -0.1048, -0.3196, -0.2110], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 41/2708 [00:10<11:39,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4832, -0.8994, -0.2025, -0.5024, -0.3493, -0.3469, -0.3100, -0.1292],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 42/2708 [00:10<11:35,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9360, -0.1485, -0.8748, -0.8013], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 43/2708 [00:10<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5408, -0.5323, -0.5018, -0.2520, -0.5001], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 44/2708 [00:11<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9175, -0.6259, -0.8920], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 45/2708 [00:11<11:29,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5529, -0.4633, -0.6824, -0.1575, -0.6823, -0.4527, -0.1097],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 46/2708 [00:11<11:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7863, -0.6055, -0.3041, -0.7659], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 47/2708 [00:12<11:24,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6369, -0.1579,  0.0096, -0.2302, -0.7066, -0.8424, -0.8205],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 48/2708 [00:12<11:23,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5954, -0.7689, -1.0760], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/2708 [00:12<11:25,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6883, -0.7915, -0.8190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 50/2708 [00:12<11:31,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7514, -0.5609, -0.5929, -0.4977, -0.6895, -0.1147, -0.3839, -0.4977,\n",
      "        -0.3521, -0.1876], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 51/2708 [00:13<11:27,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9633, -0.3087, -0.7496], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 52/2708 [00:13<11:32,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0716, -0.7867], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8026, -0.6366, -0.5278, -0.3520, -0.0046, -0.2991, -0.3643],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 54/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2594, -0.6112, -0.5430, -0.0218, -0.8436, -0.6938], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 55/2708 [00:14<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6441, -0.4541, -0.7002, -0.3384], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 56/2708 [00:14<11:24,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5803, -0.7055, -1.0509], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 57/2708 [00:14<11:28,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9221,  0.3088, -0.4489, -0.3684, -0.2524, -0.0571, -0.5076, -0.1804,\n",
      "        -0.2160, -0.0491, -0.4002, -0.8905,  0.1593], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 58/2708 [00:14<11:34,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4749, -0.3756, -0.3725, -0.5048, -0.4532], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 59/2708 [00:15<11:46,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2448, -0.8058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 60/2708 [00:15<11:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3131, -1.6650], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 61/2708 [00:15<11:45,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4681, -0.5944, -0.3451, -0.4504, -0.3806, -0.3288, -0.3684, -0.7651,\n",
      "        -0.3525, -0.0654, -0.5855], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 62/2708 [00:15<11:42,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1158,  0.6875, -1.3673, -0.8284], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 63/2708 [00:16<11:49,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6049, -0.1793, -0.9846, -0.9551, -0.0148, -0.7559], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 64/2708 [00:16<11:47,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4189, -1.4566], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 65/2708 [00:16<11:40,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1445, -0.6135], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 66/2708 [00:17<11:26,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6229, -0.6396, -0.7113, -0.1714], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ig_spar \u001b[38;5;241m=\u001b[39m \u001b[43mig_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIG Spar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mig_spar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mig_sparsity\u001b[1;34m(model, graph, data_object)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[0;32m     33\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mIG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     total_sparse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_nonzeros(exp\u001b[38;5;241m.\u001b[39mnode_imp)\u001b[38;5;241m/\u001b[39mexp\u001b[38;5;241m.\u001b[39menc_subgraph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(exp\u001b[38;5;241m.\u001b[39mnode_imp)\n",
      "Cell \u001b[1;32mIn[3], line 1020\u001b[0m, in \u001b[0;36mIG\u001b[1;34m(node_idx, x, edge_index, y, num_hops, steps, model, criterion)\u001b[0m\n\u001b[0;32m   1018\u001b[0m output \u001b[38;5;241m=\u001b[39m model(temp_x, sub_edge_index)\n\u001b[0;32m   1019\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output[mapping], label)\n\u001b[1;32m-> 1020\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m grad \u001b[38;5;241m=\u001b[39m temp_x\u001b[38;5;241m.\u001b[39mgrad[torch\u001b[38;5;241m.\u001b[39mwhere(subset\u001b[38;5;241m==\u001b[39mnode_idx)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m   1022\u001b[0m grads[i] \u001b[38;5;241m=\u001b[39m grad\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [04:38<00:00,  9.73it/s]\n",
      "100%|| 2708/2708 [12:55<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [11:26<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [12:32:29<00:00, 16.67s/it]        \n",
      "100%|| 2708/2708 [17:32<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [10:33<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
