{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook trains a model with additional loss for Stability on Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import numpy as np\n",
    "import torch\n",
    "dataset = Planetoid(root='/tmp/Cora/', name='Cora')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.utils import k_hop_subgraph, to_undirected\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.data import Data\n",
    "from graphxai.explainers._base import _BaseExplainer\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "\n",
    "\n",
    "class _BaseExplainer:\n",
    "    \"\"\"\n",
    "    Base Class for Explainers\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "            model: nn.Module,\n",
    "            emb_layer_name: Optional[str] = None,\n",
    "            is_subgraphx: Optional[bool] = False\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "                The output of the model should be unnormalized class score.\n",
    "                For example, last layer = GCNConv or Linear.\n",
    "            emb_layer_name (str, optional): name of the embedding layer\n",
    "                If not specified, use the last but one layer by default.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.L = len([module for module in self.model.modules()\n",
    "                      if isinstance(module, MessagePassing)])\n",
    "        self.explain_graph = False  # Assume node-level explanation by default\n",
    "        self.subgraphx_flag = is_subgraphx\n",
    "        self.__set_embedding_layer(emb_layer_name)\n",
    "\n",
    "    def __set_embedding_layer(self, emb_layer_name: str = None):\n",
    "        \"\"\"\n",
    "        Set the embedding layer (by default is the last but one layer).\n",
    "        \"\"\"\n",
    "        if emb_layer_name:\n",
    "            try:\n",
    "                self.emb_layer = getattr(self.model, emb_layer_name)\n",
    "            except AttributeError:\n",
    "                raise ValueError(f'{emb_layer_name} does not exist in the model')\n",
    "        else:\n",
    "            self.emb_layer = list(self.model.modules())[-2]\n",
    "\n",
    "    def _get_embedding(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                       forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the embedding.\n",
    "        \"\"\"\n",
    "        emb = self._get_activation(self.emb_layer, x, edge_index, forward_kwargs)\n",
    "        return emb\n",
    "\n",
    "    def _set_masks(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                   edge_mask: torch.Tensor = None, explain_feature: bool = False,\n",
    "                   device = None):\n",
    "        \"\"\"\n",
    "        Initialize the edge (and feature) masks.\n",
    "        \"\"\"\n",
    "        (n, d), m = x.shape, edge_index.shape[1]\n",
    "\n",
    "        # Initialize edge_mask and feature_mask for learning\n",
    "        std = torch.nn.init.calculate_gain('relu') * np.sqrt(2.0 / (2 * n))\n",
    "        if edge_mask is None:\n",
    "            edge_mask = (torch.randn(m) * std).to(device)\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        else:\n",
    "            self.edge_mask = torch.nn.Parameter(edge_mask)\n",
    "        if explain_feature:\n",
    "            feature_mask = (torch.randn(d) * 0.1).to(device)\n",
    "            self.feature_mask = torch.nn.Parameter(feature_mask)\n",
    "\n",
    "        self.loop_mask = edge_index[0] != edge_index[1]\n",
    "\n",
    "        # Tell pytorch geometric to apply edge masks\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "                module.__loop_mask__ = self.loop_mask\n",
    "\n",
    "    def _clear_masks(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.edge_mask = None\n",
    "        self.feature_mask = None\n",
    "\n",
    "    def _flow(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def _predict(self, x: torch.Tensor, edge_index: torch.Tensor,\n",
    "                 return_type: str = 'label', forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the model's prediction.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            return_type (str): one of ['label', 'prob', 'log_prob']\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            pred (torch.Tensor, [n x ...]): model prediction\n",
    "        \"\"\"\n",
    "        # Compute unnormalized class score\n",
    "        with torch.no_grad():\n",
    "            out = self.model.to(device)(x, edge_index, **forward_kwargs)\n",
    "            if return_type == 'label':\n",
    "                out = out.argmax(dim=-1)\n",
    "            elif return_type == 'prob':\n",
    "                out = F.softmax(out, dim=-1)\n",
    "            elif return_type == 'log_prob':\n",
    "                out = F.log_softmax(out, dim=-1)\n",
    "            else:\n",
    "                raise ValueError(\"return_type must be 'label', 'prob', or 'log_prob'\")\n",
    "\n",
    "            if self.explain_graph:\n",
    "                out = out.squeeze()\n",
    "\n",
    "            return out\n",
    "\n",
    "    def _prob_score_func_graph(self, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probability that the input graphs\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            target_class (int): the targeted class of the graph\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        def get_prob_score(x: torch.Tensor,\n",
    "                           edge_index: torch.Tensor,\n",
    "                           forward_kwargs: dict = {}):\n",
    "            prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                 forward_kwargs=forward_kwargs)\n",
    "            score = prob[:, target_class]\n",
    "            return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _prob_score_func_node(self, node_idx: torch.Tensor, target_class: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get a function that computes the predicted probabilities that k specified nodes\n",
    "        in `torch_geometric.data.Batch` (disconnected union of the input graphs)\n",
    "        are classified as target classes.\n",
    "\n",
    "        Args:\n",
    "            node_idx (torch.Tensor, [k]): the indices of the k nodes interested\n",
    "            target_class (torch.Tensor, [k]): the targeted classes of the k nodes\n",
    "\n",
    "        Returns:\n",
    "            get_prob_score (callable): the probability score function\n",
    "        \"\"\"\n",
    "        if self.subgraphx_flag:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[node_idx, target_class]\n",
    "                return score\n",
    "        else:\n",
    "            def get_prob_score(x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor,\n",
    "                            forward_kwargs: dict = {}):\n",
    "                prob = self._predict(x, edge_index, return_type='prob',\n",
    "                                    forward_kwargs=forward_kwargs)\n",
    "                score = prob[:, node_idx, target_class]\n",
    "                return score\n",
    "\n",
    "        return get_prob_score\n",
    "\n",
    "    def _get_activation(self, layer: nn.Module, x: torch.Tensor,\n",
    "                        edge_index: torch.Tensor, forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Get the activation of the layer.\n",
    "        \"\"\"\n",
    "        activation = {}\n",
    "        def get_activation():\n",
    "            def hook(model, inp, out):\n",
    "                activation['layer'] = out.detach()\n",
    "            return hook\n",
    "\n",
    "        layer.register_forward_hook(get_activation())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return activation['layer']\n",
    "\n",
    "    def _get_k_hop_subgraph(self, node_idx: int, x: torch.Tensor,\n",
    "                            edge_index: torch.Tensor, num_hops: int = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Extract the subgraph of target node\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): the node index\n",
    "            x (torch.Tensor, [n x d]): node feature matrix with shape\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index\n",
    "            kwargs (dict): additional parameters of the graph\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # TODO: use NamedTuple\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        return khop_info\n",
    "\n",
    "    def get_explanation_node(self, node_idx: int,\n",
    "                             x: torch.Tensor,\n",
    "                             edge_index: torch.Tensor,\n",
    "                             label: torch.Tensor = None,\n",
    "                             num_hops: int = None,\n",
    "                             forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): index of the node to be explained\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            label (torch.Tensor, optional, [n x ...]): labels to explain\n",
    "                If not provided, we use the output of the model.\n",
    "            num_hops (int, optional): number of hops to consider\n",
    "                If not provided, we use the number of graph layers of the GNN.\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "            khop_info (4-tuple of torch.Tensor):\n",
    "                0. the nodes involved in the subgraph\n",
    "                1. the filtered `edge_index`\n",
    "                2. the mapping from node indices in `node_idx` to their new location\n",
    "                3. the `edge_index` mask indicating which edges were preserved\n",
    "        \"\"\"\n",
    "        # If labels are needed\n",
    "        label = self._predict(x, edge_index, return_type='label') if label is None else label\n",
    "        # If probabilities / log probabilities are needed\n",
    "        prob = self._predict(x, edge_index, return_type='prob')\n",
    "        log_prob = self._predict(x, edge_index, return_type='log_prob')\n",
    "\n",
    "        num_hops = self.L if num_hops is None else num_hops\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, num_hops, edge_index,\n",
    "                           relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        return exp, khop_info\n",
    "\n",
    "    def get_explanation_graph(self, edge_index: torch.Tensor,\n",
    "                              x: torch.Tensor, label: torch.Tensor,\n",
    "                              forward_kwargs: dict = {}):\n",
    "        \"\"\"\n",
    "        Explain a whole-graph prediction.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor, [2 x m]): edge index of the graph\n",
    "            x (torch.Tensor, [n x d]): node features\n",
    "            label (torch.Tensor, [n x ...]): labels to explain\n",
    "            forward_kwargs (dict, optional): additional arguments to model.forward\n",
    "                beyond x and edge_index\n",
    "\n",
    "        Returns:\n",
    "            exp (dict):\n",
    "                exp['feature_imp'] (torch.Tensor, [d]): feature mask explanation\n",
    "                exp['edge_imp'] (torch.Tensor, [m]): k-hop edge importance\n",
    "                exp['node_imp'] (torch.Tensor, [m]): k-hop node importance\n",
    "        \"\"\"\n",
    "        exp = {'feature_imp': None, 'edge_imp': None}\n",
    "\n",
    "        # Compute exp\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_explanation_link(self):\n",
    "        \"\"\"\n",
    "        Explain a link prediction.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph as subgraph\n",
    "\n",
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class _BaseDecomposition(_BaseExplainer):\n",
    "    '''\n",
    "    Code adapted from Dive into Graphs (DIG)\n",
    "    Code: https://github.com/divelab/DIG\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__(model=model) # Will set self.model = model\n",
    "        # Other properties: self.L (number of layers)\n",
    "\n",
    "    @property\n",
    "    def __num_hops__(self):\n",
    "        if self.explain_graph:\n",
    "            return -1\n",
    "        else:\n",
    "            return self.L\n",
    "    \n",
    "    def set_graph_attr(self,\n",
    "                x: Tensor,\n",
    "                edge_index: Tensor,\n",
    "                **kwargs\n",
    "                ):\n",
    "        self.num_edges = edge_index.shape[1]\n",
    "        self.num_nodes = x.shape[0]\n",
    "        self.device = x.device\n",
    "\n",
    "    def extract_step(self, x: Tensor, edge_index: Tensor, detach: bool = True, split_fc: bool = False, forward_kwargs: dict = None):\n",
    "        '''Gets information about every layer in the graph\n",
    "        Args:\n",
    "\n",
    "            forward_kwargs (tuple, optional): Additional arguments to model forward call (other than x and edge_index)\n",
    "                (default: :obj:`None`)\n",
    "        '''\n",
    "\n",
    "        layer_extractor = []\n",
    "        hooks = []\n",
    "\n",
    "        def register_hook(module: nn.Module):\n",
    "            if not list(module.children()) or isinstance(module, MessagePassing):\n",
    "                hooks.append(module.register_forward_hook(forward_hook))\n",
    "\n",
    "        def forward_hook(module: nn.Module, input: Tuple[Tensor], output: Tensor):\n",
    "            # input contains x and edge_index\n",
    "            if detach:\n",
    "                layer_extractor.append((module, input[0].clone().detach(), output.clone().detach()))\n",
    "            else:\n",
    "                layer_extractor.append((module, input[0], output))\n",
    "\n",
    "        # --- register hooks ---\n",
    "        self.model.apply(register_hook)\n",
    "\n",
    "        # ADDED: OWEN QUEEN --------------\n",
    "        if forward_kwargs is None:\n",
    "            _ = self.model(x, edge_index)\n",
    "        else:\n",
    "            _ = self.model(x, edge_index, **forward_kwargs)\n",
    "        # --------------------------------\n",
    "        # Remove hooks:\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        # --- divide layer sets ---\n",
    "\n",
    "        # print('Layer extractor', [layer_extractor[i][0] for i in range(len(layer_extractor))])\n",
    "\n",
    "        walk_steps = []\n",
    "        fc_steps = []\n",
    "        pool_flag = False\n",
    "        step = {'input': None, 'module': [], 'output': None}\n",
    "        for layer in layer_extractor:\n",
    "            if isinstance(layer[0], MessagePassing):\n",
    "                if step['module']: # Append step that had previously been building\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], GNNPool):\n",
    "                pool_flag = True\n",
    "                if step['module']:\n",
    "                    walk_steps.append(step)\n",
    "\n",
    "                # Putting in GNNPool\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            elif isinstance(layer[0], nn.Linear):\n",
    "                if step['module']:\n",
    "                    if isinstance(step['module'][0], MessagePassing):\n",
    "                        walk_steps.append(step) # Append MessagePassing layer to walk_steps\n",
    "                    else: # Always append Linear layers to fc_steps\n",
    "                        fc_steps.append(step)\n",
    "\n",
    "                step = {'input': layer[1], 'module': [], 'output': None}\n",
    "\n",
    "            # Also appends non-trainable layers to step (not modifying input):\n",
    "            step['module'].append(layer[0])\n",
    "            step['output'] = layer[2]\n",
    "\n",
    "        if step['module']:\n",
    "            if isinstance(step['module'][0], MessagePassing):\n",
    "                walk_steps.append(step)\n",
    "            else: # Append anything to FC that is not MessagePassing at its origin\n",
    "                # Still supports sequential layers\n",
    "                fc_steps.append(step)\n",
    "            # print('layer', layer[0])\n",
    "            # if isinstance(layer[0], MessagePassing) or isinstance(layer[0], GNNPool):\n",
    "            #     if isinstance(layer[0], GNNPool):\n",
    "            #         pool_flag = True\n",
    "            #     if step['module'] and step['input'] is not None:\n",
    "            #         walk_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # if pool_flag and split_fc and isinstance(layer[0], nn.Linear):\n",
    "            #     if step['module']:\n",
    "            #         fc_steps.append(step)\n",
    "            #     step = {'input': layer[1], 'module': [], 'output': None}\n",
    "            # step['module'].append(layer[0])\n",
    "            # step['output'] = layer[2]\n",
    "\n",
    "        for walk_step in walk_steps:\n",
    "            if hasattr(walk_step['module'][0], 'nn') and walk_step['module'][0].nn is not None:\n",
    "                # We don't allow any outside nn during message flow process in GINs\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "            elif hasattr(walk_step['module'][0], 'lin') and walk_step['module'][0].lin is not None:\n",
    "                walk_step['module'] = [walk_step['module'][0]]\n",
    "\n",
    "        # print('Walk steps', [walk_steps[i]['module'] for i in range(len(walk_steps))])\n",
    "        # print('fc steps', [fc_steps[i]['module'] for i in range(len(fc_steps))])\n",
    "\n",
    "        return walk_steps, fc_steps\n",
    "\n",
    "    def walks_pick(self,\n",
    "                   edge_index: Tensor,\n",
    "                   pick_edge_indices: List,\n",
    "                   walk_indices: List=[],\n",
    "                   num_layers=0\n",
    "                   ):\n",
    "        walk_indices_list = []\n",
    "        for edge_idx in pick_edge_indices:\n",
    "\n",
    "            # Adding one edge\n",
    "            walk_indices.append(edge_idx)\n",
    "            _, new_src = src, tgt = edge_index[:, edge_idx]\n",
    "            next_edge_indices = np.array((edge_index[0, :] == new_src).nonzero().view(-1))\n",
    "\n",
    "            # Finding next edge\n",
    "            if len(walk_indices) >= num_layers:\n",
    "                # return one walk\n",
    "                walk_indices_list.append(walk_indices.copy())\n",
    "            else:\n",
    "                walk_indices_list += self.walks_pick(edge_index, next_edge_indices, walk_indices, num_layers)\n",
    "\n",
    "            # remove the last edge\n",
    "            walk_indices.pop(-1)\n",
    "\n",
    "        return walk_indices_list\n",
    "\n",
    "class CAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, activation = None):\n",
    "        '''\n",
    "        .. note::\n",
    "            From Pope et al., CAM requires that the layer immediately before the softmax layer be\n",
    "            a global average pooling layer, or in the case of node classification, a graph convolutional\n",
    "            layer. Therefore, for this algorithm to theoretically work, there can be no fully-connected\n",
    "            layers after global pooling. There is no restriction in the code for this, but be warned. \n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            activation (method, optional): activation funciton for final layer in network. If `activation = None`,\n",
    "                explainer assumes linear activation. Use `activation = None` if the activation is applied\n",
    "                within the `forward` method of `model`, only set this parameter if another activation is\n",
    "                applied in the training procedure outside of model. (:default: :obj:`None`)\n",
    "        '''\n",
    "        super().__init__(model=model)\n",
    "        self.model = model\n",
    "\n",
    "        # Set activation function\n",
    "        self.activation = lambda x: x  if activation is None else activation\n",
    "        # i.e. linear activation if none provided\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                node_idx: int, \n",
    "                edge_index: torch.Tensor, \n",
    "                label: int = None,  \n",
    "                y = None,\n",
    "                forward_kwargs: dict = {},\n",
    "                directed: bool = False\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Explain one node prediction by the model\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.tensor): edge_index of entire graph\n",
    "            label (int, optional): Label on which to compute the explanation for\n",
    "                this node. If `None`, the predicted label from the model will be\n",
    "                used. (default: :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "            directed (bool, optional): If True, graph is directed.\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        if not directed:\n",
    "            edge_index = to_undirected(edge_index)\n",
    "\n",
    "        if label is None:\n",
    "            if y is None:\n",
    "                label = int(self.__forward_pass(x, edge_index, forward_kwargs).argmax(dim=1).item())\n",
    "            else:\n",
    "                label = y[node_idx]\n",
    "\n",
    "        # Perform walk:\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=False, split_fc=False, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        # Get subgraph:\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        #cam = torch.zeros(N) # Compute CAM only over the subgraph (all others are zero)\n",
    "        cam = torch.zeros(subgraph_N)\n",
    "        for i in range(subgraph_N):\n",
    "            n = subgraph_nodes[i]\n",
    "            cam[i] += self.__exp_node(n, walk_steps, label)\n",
    "\n",
    "        # Set Explanation class:\n",
    "        exp = Explanation(\n",
    "            node_imp = cam,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs = {}):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, predicted_c):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after last convolutiuonal layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        last_conv_layer = walk_steps[-1]\n",
    "\n",
    "        if isinstance(last_conv_layer['module'][0], GINConv):\n",
    "            weight_vec = last_conv_layer['module'][0].nn.weight[predicted_c, :].detach()  # last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], GCNConv):\n",
    "            weight_vec = last_conv_layer['module'][0].lin.weight[predicted_c, :].detach()\n",
    "        elif isinstance(last_conv_layer['module'][0], torch.nn.Linear):\n",
    "            weight_vec = last_conv_layer['module'][0].weight[predicted_c, :].detach()\n",
    "\n",
    "        F_l_n = F.relu(last_conv_layer['input'][node_idx,:]).detach()\n",
    "\n",
    "        L_cam_n = F.relu(torch.matmul(weight_vec, F_l_n))\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "\n",
    "class GradCAM(_BaseDecomposition):\n",
    "    '''\n",
    "    Gradient Class-Activation Mapping for GNNs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model: torch.Tensor, criterion = F.cross_entropy):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "            x: torch.Tensor, \n",
    "            y: torch.Tensor, \n",
    "            node_idx: int, \n",
    "            edge_index: torch.Tensor, \n",
    "            label: int = None, \n",
    "            forward_kwargs: dict = {}, \n",
    "            average_variant: bool = True, \n",
    "            layer: int = 0\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a node in the given graph\n",
    "        Args:\n",
    "            x (torch.Tensor, (n,)): Tensor of node features from the entire graph, with n nodes.\n",
    "            y (torch.Tensor, (n,)): Ground-truth labels for all n nodes in the graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            edge_index (torch.Tensor): Edge_index of entire graph.\n",
    "            label (int, optional): Label for which to compute Grad-CAM against. If None, computes\n",
    "                the Grad-CAM with respect to the model's predicted class for this node.\n",
    "                (default :obj:`None`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. (default: :obj:`None`)\n",
    "            average_variant (bool, optional): If True, computes the average Grad-CAM across all convolutional\n",
    "                layers in the model. If False, computes Grad-CAM for `layer`. (default: :obj:`True`)\n",
    "            layer (int, optional): Layer by which to compute the Grad-CAM. Argument only has an effect if \n",
    "                `average_variant == True`. Must be less-than the total number of convolutional layers\n",
    "                in the model. (default: :obj:`0`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        x = x.detach().clone()\n",
    "        y = y.detach().clone()\n",
    "\n",
    "        x.requires_grad = True\n",
    "\n",
    "        if label is None:\n",
    "            pred = self.__forward_pass(x, y, edge_index, forward_kwargs)[0][node_idx, :].reshape(1, -1)\n",
    "            y[node_idx] = pred.argmax(dim=1).item()\n",
    "        else: # Transform node_idx's label if provided by user\n",
    "            pred, loss = self.__forward_pass(x, y, edge_index, forward_kwargs)\n",
    "            y[node_idx] = label\n",
    "\n",
    "        walk_steps, _ = self.extract_step(x, edge_index, detach=True, split_fc=True, forward_kwargs = forward_kwargs)\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx, self.L, edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        N = maybe_num_nodes(edge_index, None)\n",
    "        subgraph_N = len(subgraph_nodes.tolist())\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "\n",
    "        if average_variant:\n",
    "            # Size of all nodes in the subgraph:\n",
    "            avg_gcam = torch.zeros(subgraph_N)\n",
    "\n",
    "            for l in range(self.L):\n",
    "                # Compute gradients for this layer ahead of time:\n",
    "                gradients = self.__grad_by_layer(l)\n",
    "\n",
    "                for i in range(subgraph_N): # Over all subgraph nodes\n",
    "                    n = subgraph_nodes[i]\n",
    "                    avg_gcam[i] += self.__get_gCAM_layer(walk_steps, l, n, gradients)\n",
    "\n",
    "            avg_gcam /= self.L # Apply average\n",
    "\n",
    "            exp.node_imp = avg_gcam\n",
    "\n",
    "        else:\n",
    "            assert layer < len(walk_steps), \"Layer must be an index of convolutional layers\"\n",
    "\n",
    "            gcam = torch.zeros(subgraph_N)\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "            for i in range(subgraph_N):\n",
    "                n = subgraph_nodes[i]\n",
    "                gcam[i] += self.__get_gCAM_layer(walk_steps, layer, n, gradients)#[0]\n",
    "\n",
    "            exp.node_imp = gcam\n",
    "\n",
    "        return exp\n",
    "        \n",
    "    def __forward_pass(self, x, label, edge_index, forward_kwargs):\n",
    "        x.requires_grad = True # Enforce that x needs gradient\n",
    "\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        loss = self.criterion(pred, label)\n",
    "        loss.backward() # Propagate loss backward through network\n",
    "\n",
    "        return pred, loss\n",
    "\n",
    "    def __grad_by_layer(self, layer):\n",
    "        # Index 0 of parameters to avoid calculating gradients for biases\n",
    "        module_at_layer = list(self.model.children())[layer]\n",
    "\n",
    "        if isinstance(module_at_layer, GCNConv):\n",
    "            grad = module_at_layer.lin.weight.grad\n",
    "        elif isinstance(module_at_layer, GINConv):\n",
    "            grad = module_at_layer.nn.weight.grad\n",
    "        else:\n",
    "            grad = module_at_layer.weight.grad\n",
    "\n",
    "        return grad.mean(dim=1)\n",
    "\n",
    "    def __get_gCAM_layer(self, walk_steps, layer, node_idx = None, gradients = None):\n",
    "        # Gets Grad CAM for one layer\n",
    "        if gradients is None:\n",
    "            # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "            # ''        '' shape: [k,] - k= # output features from layer l\n",
    "            gradients = self.__grad_by_layer(layer)\n",
    "\n",
    "        if node_idx is None: # Need to compute for entire graph:\n",
    "            node_explanations = []\n",
    "            for n in range(self.N):\n",
    "                node_explanations.append(self.__exp_node(n, walk_steps, layer, gradients))\n",
    "\n",
    "            return node_explanations\n",
    "\n",
    "        # Return for only one node:\n",
    "        return self.__exp_node(node_idx, walk_steps, layer, gradients)\n",
    "\n",
    "    def __exp_node(self, node_idx, walk_steps, layer, gradients):\n",
    "        '''\n",
    "        Gets explanation for one node\n",
    "        Assumes ReLU activation after each convolutional layer\n",
    "        TODO: Fix activation function assumption\n",
    "        '''\n",
    "        # \\alpha^{l,c} = Average over nodes of gradients for layer l, after activation over c\n",
    "        # ''        '' shape: [k,] - k= # input features to layer l\n",
    "\n",
    "        # Activations for node n\n",
    "        F_l_n = F.relu(walk_steps[layer]['output'][node_idx,:]).detach()\n",
    "        L_cam_n = F.relu(torch.matmul(gradients, F_l_n)) # Combine gradients and activations\n",
    "\n",
    "        return L_cam_n.item()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from graphxai.utils import Explanation\n",
    "# from ._decomp_base_old import _BaseDecomposition\n",
    "\n",
    "def clip_hook(grad):\n",
    "    # Apply ReLU activation to gradient\n",
    "    return torch.clamp(grad, min=0)\n",
    "import gc\n",
    "\n",
    "class GuidedBP(_BaseDecomposition):\n",
    "\n",
    "    def __init__(self, model, criterion = F.cross_entropy, enforce_requires_grad = True):\n",
    "        '''\n",
    "        Args:\n",
    "            model (torch.nn.Module): model on which to make predictions\n",
    "            criterion (PyTorch Loss Function): loss function used to train the model.\n",
    "                Needed to pass gradients backwards in the network to obtain gradients.\n",
    "        '''\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.L = len([module for module in self.model.modules() if isinstance(module, MessagePassing)])\n",
    "\n",
    "        self.registered_hooks = []\n",
    "\n",
    "        self.enforce_requires_grad = enforce_requires_grad\n",
    "\n",
    "    def get_explanation_node(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor,\n",
    "                edge_index: torch.Tensor,  \n",
    "                node_idx: int, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "            ) -> Explanation:\n",
    "        '''\n",
    "        Get Guided Backpropagation explanation for one node in the graph\n",
    "        Args:\n",
    "            x (torch.tensor): tensor of node features from the entire graph\n",
    "            y (torch.Tensor): Ground truth labels correspond to each node's \n",
    "                classification. This argument is input to the `criterion` \n",
    "                function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            node_idx (int): node index for which to explain a prediction around\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the enclosing \n",
    "                subgraph. Must support `dim` argument.\n",
    "                (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)\n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :obj:`graphxai.utils.EnclosingSubgraph`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        if self.enforce_requires_grad:\n",
    "            try:\n",
    "                x = x.detach().clone()\n",
    "                x.requires_grad = True\n",
    "            except:\n",
    "                pass\n",
    "        # assert x.requires_grad, 'x must have requires_grad == True'\n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        graph_exp = x.grad\n",
    "\n",
    "        khop_info = k_hop_subgraph(node_idx = node_idx, num_hops = self.L, edge_index = edge_index)\n",
    "        subgraph_nodes = khop_info[0]\n",
    "\n",
    "        node_imp = aggregate_node_imp(torch.stack([graph_exp[i,:] for i in subgraph_nodes]).detach(), dim=1)\n",
    "\n",
    "        # Get only those explanations for nodes in the subgraph:\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        \n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        return exp\n",
    "\n",
    "    def get_explanation_graph(self, \n",
    "                x: torch.Tensor, \n",
    "                y: torch.Tensor, \n",
    "                edge_index: torch.Tensor, \n",
    "                aggregate_node_imp = torch.sum,\n",
    "                forward_kwargs: dict = {}\n",
    "        ) -> Explanation:\n",
    "        '''\n",
    "        Explain a whole-graph prediction with Guided Backpropagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor of node features from the entire graph.\n",
    "            y (torch.tensor): Ground truth label of given input. This argument is \n",
    "                input to the `criterion` function provided in `__init__()`.\n",
    "            edge_index (torch.tensor): Edge_index of entire graph.\n",
    "            aggregate_node_imp (function, optional): torch function that aggregates\n",
    "                all node importance feature-wise scores across the graph. \n",
    "                Must support `dim` argument. (:default: :obj:`torch.sum`)\n",
    "            forward_kwargs (dict, optional): Additional arguments to model.forward \n",
    "                beyond x and edge_index. Must be keyed on argument name. \n",
    "                (default: :obj:`{}`)   \n",
    "\n",
    "        :rtype: :class:`graphxai.Explanation`\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method. \n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`None`\n",
    "                `node_imp`: :obj:`torch.Tensor, [num_nodes, features]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `graph`: :obj:`torch_geometric.data.Data`\n",
    "        '''\n",
    "\n",
    "        # Run whole-graph prediction:\n",
    "        try:\n",
    "            x.requires_grad = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        assert x.requires_grad, 'x must have requires_grad == True' \n",
    "\n",
    "        # Perform the guided backprop:\n",
    "        xhook = x.register_hook(clip_hook)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        pred = self.__forward_pass(x, edge_index, forward_kwargs)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.__apply_hooks()\n",
    "        loss.backward()\n",
    "        self.__rm_hooks()\n",
    "\n",
    "        xhook.remove() # Remove hook from x\n",
    "\n",
    "        node_imp = aggregate_node_imp(x.grad, dim=1)\n",
    "\n",
    "        exp = Explanation(\n",
    "            node_imp = node_imp\n",
    "        )\n",
    "    \n",
    "        exp.set_whole_graph(Data(x, edge_index))\n",
    "\n",
    "        return exp\n",
    "\n",
    "    def __apply_hooks(self):\n",
    "        self.registered_hooks = []\n",
    "        for p in self.model.parameters():\n",
    "            h = p.register_hook(clip_hook)\n",
    "            self.registered_hooks.append(h)\n",
    "\n",
    "    def __rm_hooks(self):\n",
    "        for h in self.registered_hooks:\n",
    "            h.remove()\n",
    "        self.registered_hooks = []\n",
    "    \n",
    "    def __forward_pass(self, x, edge_index, forward_kwargs):\n",
    "        # Forward pass:\n",
    "        self.model.eval()\n",
    "        self.__apply_hooks()\n",
    "        pred = self.model(x, edge_index, **forward_kwargs)\n",
    "\n",
    "        return pred\n",
    "from graphxai.utils import Explanation\n",
    "class IG():\n",
    "    def __init__(self, model, hops: Optional[int] = 1, criterion = None):\n",
    "        self.model = model\n",
    "        self.num_hops = hops\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def node_explanations(self, node_idx: int, \n",
    "            x: torch.Tensor,\n",
    "            edge_index: torch.Tensor, \n",
    "            y: Optional[torch.Tensor] = None,):\n",
    "        \"\"\"\n",
    "        Explain a node prediction.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): Index of the node to be explained.\n",
    "            edge_index (torch.Tensor, [2 x m]): Edge index of the graph.\n",
    "            x (torch.Tensor, [n x d]): Node features.\n",
    "            label (torch.Tensor, [n x ...]): Labels to explain.\n",
    "            y (torch.Tensor): Same as `label`, provided for general \n",
    "                compatibility in the arguments. (:default: :obj:`None`)\n",
    "            num_hops (int, optional): Number of hops in the enclosing \n",
    "                subgraph. If `None`, set to the number of layers in \n",
    "                the GNN. (:default: :obj:`None`)\n",
    "            steps (int, optional): Number of steps for the Riemannian \n",
    "                integration. (:default: :obj:`40`)\n",
    "\n",
    "        Returns:\n",
    "            exp (:class:`Explanation`): Explanation output from the method.\n",
    "                Fields are:\n",
    "                `feature_imp`: :obj:`torch.Tensor, [x.shape[1],]`\n",
    "                `node_imp`: :obj:`torch.Tensor, [nodes_in_khop,]`\n",
    "                `edge_imp`: :obj:`None`\n",
    "                `enc_subgraph`: :class:`graphxai.utils.EnclosingSubgraph`\n",
    "        \"\"\"\n",
    "\n",
    "        if (y is None):\n",
    "            raise ValueError('Either label or y should be provided for Integrated Gradients')\n",
    "\n",
    "        label = y[node_idx]\n",
    "        if len(label.shape) == 0:\n",
    "            label = label.unsqueeze(dim=0)\n",
    "\n",
    "        khop_info = subset, sub_edge_index, mapping, _ = \\\n",
    "            k_hop_subgraph(node_idx, self.num_hops, edge_index,\n",
    "                            relabel_nodes=True, num_nodes=x.shape[0])\n",
    "        sub_x = x[subset]\n",
    "        steps = 40\n",
    "        self.model.eval()\n",
    "        grads = torch.zeros(steps+1, x.shape[1]).to(device)\n",
    "\n",
    "        # Perform Riemannian integration\n",
    "        for i in range(steps+1):\n",
    "            with torch.no_grad():\n",
    "                baseline = torch.zeros_like(sub_x).to(device)  # TODO: baseline all 0s, all 1s, ...?\n",
    "                temp_x = baseline + (float(i)/steps) * (sub_x.clone()-baseline)\n",
    "            temp_x.requires_grad = True\n",
    "            output = self.model(temp_x, sub_edge_index)\n",
    "            loss = self.criterion(output[mapping], label)\n",
    "            loss.backward()\n",
    "            grad = temp_x.grad[torch.where(subset==node_idx)[0].item()]\n",
    "            grads[i] = grad\n",
    "\n",
    "        grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "        avg_grads = torch.mean(grads, axis=0)\n",
    "\n",
    "        # Integrated gradients for only node_idx:\n",
    "        # baseline[0] just gets a single-value 0-tensor\n",
    "        integrated_gradients = ((x[torch.where(subset == node_idx)[0].item()]\n",
    "                                    - baseline[0]) * avg_grads)\n",
    "\n",
    "        # Integrated gradients across the enclosing subgraph:\n",
    "        all_node_ig = ((x[subset] - baseline) * avg_grads)\n",
    "        node_importances = torch.sum(all_node_ig, dim=1)\n",
    "        exp = Explanation(\n",
    "            feature_imp = integrated_gradients,\n",
    "            node_imp = node_importances,\n",
    "            node_idx = node_idx\n",
    "        )\n",
    "        exp.set_enclosing_subgraph(khop_info)\n",
    "        gc.collect()\n",
    "        return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import random\n",
    "from copy import deepcopy\n",
    "random.seed(12345)\n",
    "def perturbed_edge_list(data: torch_geometric.data.Data, n_to_add: int = 2)->torch_geometric.data.Data:\n",
    "    \"\"\"Adding two random nodes to each node\"\"\"\n",
    "    # Do not want seed here\n",
    "    edge_list = data.edge_index\n",
    "    # torch.cat((edge_list, torch.LongTensor((1,2)).to(device).reshape(1,-1)), dim=-1)\n",
    "    # print(edge_list)\n",
    "    data = deepcopy(data)\n",
    "    for node in range(data.x.shape[0]):\n",
    "        # generating two random nodes to add to its adjacency list\n",
    "        for i in range(n_to_add):\n",
    "            n1 = randint(0, data.x.shape[0]-1)\n",
    "            new1 = torch.cat((edge_list[0], torch.LongTensor([node]).to(device)), axis=-1)\n",
    "            new2 = torch.cat((edge_list[1], torch.LongTensor([n1]).to(device)), axis=-1)\n",
    "            edge_list = torch.cat([new1.reshape(1,-1), new2.reshape(1,-1)])\n",
    "    data.edge_index = edge_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def explanation_list_to_matrix(l: list, data)->torch.Tensor:\n",
    "    len_l = len(l)\n",
    "    matrix = torch.zeros((len_l, data.x.shape[0]))\n",
    "    with tqdm(total=len_l) as pbar:\n",
    "        for i, exp in enumerate(l):\n",
    "            pbar.update(1)\n",
    "            subgraph = exp.enc_subgraph.nodes\n",
    "            for j, n in enumerate(subgraph):\n",
    "                n = n.item()\n",
    "                matrix[i][n] = exp.node_imp[j].item()\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def stability(generated_exp_unperturbed, generated_exp_perturbed ) -> float:\n",
    "    \"\"\"takes in two matrices the first is unperturbed explanations and the second are perturbed via the addition of a random node\n",
    "        - We assume here that the explanations are in their padded form that is: that the explanation vectors in the list have nodes at equal positions \"\"\"\n",
    "    stability = float() \n",
    "    # Accessing the enclosing subgraph. Will be the same for both explanation.:\n",
    "    stability = abs( np.linalg.norm(np.matrix(generated_exp_unperturbed.numpy())) - np.linalg.norm(np.matrix(generated_exp_perturbed.numpy())) )\n",
    "    return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the random nodes\n",
    "from random import sample\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "# I now want all nodes for each given class (there are 7), and I will randomly select 50 of each class\n",
    "class_0 = [idx for idx, val in enumerate(data.y) if val == 0]\n",
    "class_1 = [idx for idx, val in enumerate(data.y) if val == 1]\n",
    "class_2 = [idx for idx, val in enumerate(data.y) if val == 2]\n",
    "class_3 = [idx for idx, val in enumerate(data.y) if val == 3]\n",
    "class_4 = [idx for idx, val in enumerate(data.y) if val == 4]\n",
    "class_5 = [idx for idx, val in enumerate(data.y) if val == 5]\n",
    "class_6 = [idx for idx, val in enumerate(data.y) if val == 6]\n",
    "\n",
    "random_class_0 = sample(class_0, k=50)\n",
    "random_class_1 = sample(class_1, k=50)\n",
    "random_class_2 = sample(class_2, k=50)\n",
    "random_class_3 = sample(class_3, k=50)\n",
    "random_class_4 = sample(class_4, k=50)\n",
    "random_class_5 = sample(class_5, k=50)\n",
    "random_class_6 = sample(class_6, k=50)\n",
    "\n",
    "\n",
    "random_nodes = random_class_0\n",
    "random_nodes.extend(random_class_1)\n",
    "random_nodes.extend(random_class_2)\n",
    "random_nodes.extend(random_class_3)\n",
    "random_nodes.extend(random_class_4)\n",
    "random_nodes.extend(random_class_5)\n",
    "random_nodes.extend(random_class_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 701, 1: 590, 5: 508, 0: 264, 2: 668, 4: 596})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in data.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbp_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    bp_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = GuidedBP(model=model)\n",
    "    with tqdm(total=len(graph.nodes())) as pbar:\n",
    "        for node in graph.nodes():\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            bp_exps.append(exp)\n",
    "    return bp_exps\n",
    "\n",
    "def cam_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    cam_exps = list()\n",
    "    model.eval()\n",
    "    explainability_model = CAM(model=model)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = explainability_model.get_explanation_node(node_idx=node, x = data_object.x, edge_index = data_object.edge_index,  y = data_object.y)\n",
    "            cam_exps.append(exp)\n",
    "    return cam_exps\n",
    "\n",
    "def ig_exps(model: torch.nn.Module, graph, data_object: torch_geometric.data.Data, random_nodes: list)->list:\n",
    "    \"\"\"For all nodes, we get the explanations from the current model, returned as list\"\"\"\n",
    "    ig_exps = list()\n",
    "    model.eval()\n",
    "    ig = IG(model=model, criterion=torch.nn.CrossEntropyLoss(), hops=1)\n",
    "    with tqdm(total=len(random_nodes)) as pbar:\n",
    "\n",
    "        for node in random_nodes:\n",
    "            pbar.update(1)\n",
    "            exp = ig.node_explanations(node_idx=node, x=data_object.x, edge_index=data_object.edge_index, y=data_object.y)\n",
    "            ig_exps.append(exp)\n",
    "    return ig_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_data = perturbed_edge_list(data=data).to(device) # this is our perturbed data to check against\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2430.57it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1923.10it/s]\n",
      "100%|| 350/350 [01:24<00:00,  4.16it/s]\n",
      "100%|| 350/350 [01:25<00:00,  4.12it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2611.98it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2083.35it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]]\n",
      "100%|| 350/350 [01:22<00:00,  4.23it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2611.97it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1583.72it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]]\n",
      "100%|| 350/350 [01:22<00:00,  4.22it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2554.74it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1891.91it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2800.01it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2011.49it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2612.00it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1955.31it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.27it/s]]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2397.31it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1891.92it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.23it/s]]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2554.80it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1977.40it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2592.66it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1739.13it/s]\n",
      "100%|| 350/350 [01:24<00:00,  4.16it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2631.63it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1881.72it/s]\n",
      "100%|| 350/350 [01:24<00:00,  4.17it/s]t]\n",
      "100%|| 350/350 [01:24<00:00,  4.16it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.80it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1902.20it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.80it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1871.68it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2573.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1923.08it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.79it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1944.47it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2397.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1912.58it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2536.28it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2023.12it/s]\n",
      "100%|| 350/350 [01:24<00:00,  4.16it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2631.62it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1944.44it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.18it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2500.02it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1933.71it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2611.97it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1832.48it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2592.61it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1955.31it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.27it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2651.55it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1690.81it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.27it/s]t]\n",
      "100%|| 350/350 [01:21<00:00,  4.28it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2592.62it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1859.53it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.29it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2592.63it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1842.12it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2287.62it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1955.32it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1840.62it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1489.37it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.18it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2500.07it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1923.08it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.22it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.82it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1931.78it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2573.55it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1933.73it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.23it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2692.35it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1944.47it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.22it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2692.32it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2000.03it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]/it]\n",
      "100%|| 350/350 [01:24<00:00,  4.14it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2573.54it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1933.71it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2631.62it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1999.99it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2413.82it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2058.82it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2713.17it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1881.73it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.29it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2573.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2000.02it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.30it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2651.57it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1944.46it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.26it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2611.97it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1977.43it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.69it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1832.48it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.22it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2734.47it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2000.03it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.22it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2482.31it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1822.93it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.18it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2517.98it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1842.10it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.41it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.35it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2430.54it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1850.10it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.28it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2380.98it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1879.32it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.34it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2413.79it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1840.36it/s]\n",
      "100%|| 350/350 [01:20<00:00,  4.35it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.34it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2255.74it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1699.03it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.41it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2430.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1802.98it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.29it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2631.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1949.92it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.43it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.40it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2317.88it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1765.66it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.30it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2134.16it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1785.72it/s]\n",
      "100%|| 350/350 [01:25<00:00,  4.08it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.33it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2536.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1966.29it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.45it/s]/it]\n",
      "100%|| 350/350 [01:18<00:00,  4.44it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2651.51it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1912.60it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.45it/s]/it]\n",
      "100%|| 350/350 [01:18<00:00,  4.47it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2611.94it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1891.90it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.47it/s]/it]\n",
      "100%|| 350/350 [01:18<00:00,  4.44it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.77it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1871.64it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.46it/s]/it]\n",
      "100%|| 350/350 [01:18<00:00,  4.44it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2734.39it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1986.34it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.46it/s]/it]\n",
      "100%|| 350/350 [01:18<00:00,  4.45it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2631.57it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1871.66it/s]\n",
      "100%|| 350/350 [01:18<00:00,  4.46it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.33it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2631.57it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1851.88it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.23it/s]/it]\n",
      "100%|| 350/350 [01:22<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2443.46it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1912.58it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.40it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.36it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2573.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1871.65it/s]\n",
      "100%|| 350/350 [01:21<00:00,  4.28it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.32it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2536.26it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1405.62it/s]\n",
      "100%|| 350/350 [01:20<00:00,  4.33it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.43it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2121.26it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1666.68it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.42it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.33it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2258.07it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1804.12it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.43it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.38it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2364.86it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1842.11it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.41it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.37it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2447.56it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1861.70it/s]\n",
      "100%|| 350/350 [01:20<00:00,  4.37it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.37it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2302.67it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1811.07it/s]\n",
      "100%|| 350/350 [01:20<00:00,  4.36it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.36it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2447.55it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1870.06it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.36it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2243.60it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1832.46it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.38it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.37it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2317.88it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1674.64it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.41it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2447.53it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1830.83it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.41it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.40it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2272.73it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1794.88it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.42it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.42it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2397.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1776.65it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.41it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2464.82it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1643.20it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.40it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.38it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1832.42it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1650.94it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.40it/s]/it]\n",
      "100%|| 350/350 [01:20<00:00,  4.37it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2447.55it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1861.73it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.38it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.38it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2333.33it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1715.69it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]/it]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1977.39it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1830.30it/s]\n",
      "100%|| 350/350 [01:19<00:00,  4.39it/s]/it]\n",
      "100%|| 350/350 [01:21<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2549.33it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1776.66it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]/it]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2734.43it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1822.92it/s]\n",
      "100%|| 350/350 [01:27<00:00,  3.99it/s]t]  \n",
      "100%|| 350/350 [02:38<00:00,  2.21it/s]\n",
      "100%|| 350/350 [00:00<00:00, 3039.18it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2306.81it/s]\n",
      "100%|| 350/350 [02:51<00:00,  2.04it/s]/it]\n",
      "100%|| 350/350 [02:52<00:00,  2.03it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2936.86it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2247.04it/s]\n",
      "100%|| 350/350 [02:39<00:00,  2.19it/s]/it]\n",
      "100%|| 350/350 [03:02<00:00,  1.92it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2900.40it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2079.47it/s]\n",
      "100%|| 350/350 [02:30<00:00,  2.33it/s]/it]\n",
      "100%|| 350/350 [02:32<00:00,  2.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2949.72it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2156.42it/s]\n",
      "100%|| 350/350 [02:52<00:00,  2.02it/s]/it]\n",
      "100%|| 350/350 [03:11<00:00,  1.83it/s]\n",
      "100%|| 350/350 [00:00<00:00, 3086.03it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2204.85it/s]\n",
      "100%|| 350/350 [03:00<00:00,  1.94it/s]/it]\n",
      "100%|| 350/350 [02:47<00:00,  2.09it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2949.14it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2254.88it/s]\n",
      "100%|| 350/350 [02:54<00:00,  2.01it/s]/it]\n",
      "100%|| 350/350 [02:33<00:00,  2.28it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2987.07it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2191.05it/s]\n",
      "100%|| 350/350 [01:57<00:00,  2.99it/s]/it]\n",
      "100%|| 350/350 [02:14<00:00,  2.59it/s]\n",
      "100%|| 350/350 [00:00<00:00, 3025.84it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1903.38it/s]\n",
      "100%|| 350/350 [02:21<00:00,  2.48it/s]/it]\n",
      "100%|| 350/350 [01:58<00:00,  2.96it/s]\n",
      "100%|| 350/350 [00:00<00:00, 3008.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2144.03it/s]\n",
      "100%|| 350/350 [02:47<00:00,  2.09it/s]/it]\n",
      "100%|| 350/350 [02:35<00:00,  2.25it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2887.92it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2314.84it/s]\n",
      "100%|| 350/350 [01:50<00:00,  3.17it/s]t]  \n",
      "100%|| 350/350 [02:22<00:00,  2.45it/s]\n",
      "100%|| 350/350 [00:00<00:00, 3038.84it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2118.22it/s]\n",
      "100%|| 350/350 [02:25<00:00,  2.40it/s]t]\n",
      "100%|| 350/350 [02:17<00:00,  2.54it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2899.49it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2184.14it/s]\n",
      "100%|| 350/350 [01:42<00:00,  3.43it/s]t]\n",
      "100%|| 350/350 [01:58<00:00,  2.94it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2967.15it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2092.25it/s]\n",
      "100%|| 350/350 [02:18<00:00,  2.53it/s]t]\n",
      "100%|| 350/350 [02:43<00:00,  2.15it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2708.22it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2218.83it/s]\n",
      "100%|| 350/350 [01:27<00:00,  4.00it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.20it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2588.23it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1912.59it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2447.57it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1923.09it/s]\n",
      "100%|| 350/350 [01:24<00:00,  4.13it/s]t]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.77it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1944.46it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.17it/s]t]\n",
      "100%|| 350/350 [01:24<00:00,  4.15it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2573.54it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1953.78it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.18it/s]t]\n",
      "100%|| 350/350 [01:24<00:00,  4.17it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2671.77it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1986.11it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.24it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2611.99it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1851.88it/s]\n",
      "100%|| 350/350 [01:23<00:00,  4.21it/s]t]\n",
      "100%|| 350/350 [01:22<00:00,  4.27it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2518.02it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1944.46it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]t]\n",
      "100%|| 350/350 [01:21<00:00,  4.30it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2464.78it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1921.61it/s]\n",
      "100%|| 350/350 [01:22<00:00,  4.25it/s]it]\n",
      "100%|| 350/350 [01:23<00:00,  4.19it/s]\n",
      "100%|| 350/350 [00:00<00:00, 2554.79it/s]\n",
      "100%|| 350/350 [00:00<00:00, 1881.74it/s]\n",
      "100%|| 100/100 [5:04:38<00:00, 182.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "ig_stability_list = list()\n",
    "loss_list = list()\n",
    "f1_accuracy_list = list()\n",
    "\n",
    "with tqdm(total=100) as pbar:\n",
    "    for epoch in range(100):\n",
    "        pbar.update(1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "        # measuring the stability\n",
    "        ig_explanations_unperturbed = ig_exps(model, graph, data, random_nodes=random_nodes) # unperturbed\n",
    "        ig_explanations_perturbed = ig_exps(model, graph, perturbed_data, random_nodes=random_nodes) # unperturbed\n",
    "\n",
    "        ig_matrix_unperturbed = explanation_list_to_matrix(ig_explanations_unperturbed, data) \n",
    "        ig_matrix_perturbed = explanation_list_to_matrix(ig_explanations_perturbed, data) \n",
    "\n",
    "        # getting the stability\n",
    "        ig_stab = stability(ig_matrix_unperturbed, ig_matrix_perturbed)\n",
    "        loss = loss.add(torch.tensor([ig_stab], requires_grad=True).to(device) )\n",
    "\n",
    "        loss.backward()\n",
    "        loss_list.append(loss)\n",
    "        ig_stability_list.append(ig_stab)\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = multiclass_f1_score(pred, data.y, num_classes=dataset.num_classes)\n",
    "        f1_accuracy_list.append(f1)\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving values to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Stability_100_cora_IG.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17f464e26d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i.item() for i in loss_list], label=\"Loss\")\n",
    "plt.plot([i for i in ig_stability_list], label=\"Stability\")\n",
    "plt.plot([i.item() for i in f1_accuracy_list], label=\"Macro F1\")\n",
    "plt.title(\"Loss, Stability & Accuracy vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(loss_list[i].item()-ig_stability_list[i], ig_stability_list[i], f1_accuracy_list[i].item()) for i in range(len(loss_list))], columns=[\"Loss\", \"IG Stability\", \"F1 Accuracy\"])\n",
    "df.to_csv(\"Training_for_IG_Stability_Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [16:38<00:00,  2.71it/s]\n",
      "100%|| 2708/2708 [26:29<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2708 [00:00<07:28,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6574, -0.7225, -0.6013, -0.5233], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2708 [00:00<08:56,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5203, -0.3700, -0.7551, -0.9783], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2708 [00:00<09:50,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8562, -0.5766, -0.4730, -1.1368, -0.3823,  0.0726], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2708 [00:01<10:19,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1077, -0.7583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2708 [00:01<11:07,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5199, -0.6340, -0.2173, -0.2145, -0.0319, -0.6756], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2708 [00:01<11:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4461, -0.9948, -0.4571, -0.6390], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2708 [00:01<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4153, -0.4828, -0.5654, -0.5037, -0.5363], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2708 [00:02<11:29,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7944, -0.2029], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2708 [00:02<11:34,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6189, -0.9601, -0.6968, -0.6772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/2708 [00:02<11:33,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1621, -0.9223, -0.8898], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/2708 [00:02<11:29,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8606, -0.7249, -0.6413], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/2708 [00:03<11:26,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3526, -0.1813, -0.2870], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4200, -0.2410, -0.5283, -0.3195, -0.4002], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2708 [00:03<11:19,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0116, -0.7319, -0.6148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2708 [00:03<11:23,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8901, -0.2864,  0.0708, -0.5744, -0.2016, -0.7190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2708 [00:04<11:21,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4788, -0.2618, -0.4735, -0.5339, -0.3104], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2708 [00:04<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9772, -0.3799, -0.5573, -0.5985, -0.6028], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4950, -0.8515, -0.5688, -0.4359, -0.5582, -0.3338], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2708 [00:04<11:27,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3018, -1.0444, -0.6570, -0.8701, -0.1670, -0.8772], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2708 [00:05<11:25,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0686, -0.9931], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2708 [00:05<11:26,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3826,  0.0631, -0.8968, -0.9487, -0.6614, -0.3889], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2708 [00:05<11:23,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6130,  0.0976, -0.6573], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2708 [00:05<11:31,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3956, -0.7277, -0.6689, -0.2478, -0.2256, -0.1082], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4049, -1.6713], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2708 [00:06<11:32,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3425, -0.5798, -0.1702, -0.2315, -0.4489, -0.2593, -0.5921, -0.3989],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/2708 [00:06<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7113, -0.5180, -0.6471, -0.6454, -0.7941], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/2708 [00:07<11:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5213, -0.5076, -0.3410, -0.5158, -0.4208, -0.0247], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/2708 [00:07<11:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7930, -0.5129, -0.4541, -0.4210, -0.4524], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/2708 [00:07<11:46,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2461, -0.7360], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/2708 [00:07<11:57,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2923, -1.5444, -0.3596], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/2708 [00:08<12:08,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9600, -0.5965, -0.4892, -0.4216,  0.2531, -0.5733, -0.7309],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/2708 [00:08<11:52,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1677, -0.9148], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 34/2708 [00:08<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0727, -0.4356, -0.0719, -0.8802, -0.3891], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 35/2708 [00:08<11:56,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6708, -0.2133, -0.4639, -0.0452, -0.1081, -0.2871, -0.5587, -0.3957,\n",
      "        -0.1813, -0.5420], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 36/2708 [00:09<11:49,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9400, -1.0512], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 37/2708 [00:09<11:40,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4529, -0.4503, -0.3648, -0.6088], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 38/2708 [00:09<11:38,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5024, -0.2346, -0.5609, -0.3737, -0.3356, -0.3844, -0.2932, -0.3747,\n",
      "        -0.2052], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 39/2708 [00:09<11:43,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3181, -0.1349, -0.4077, -0.1352], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 40/2708 [00:10<11:49,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9254, -0.6111, -0.1048, -0.3196, -0.2110], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 41/2708 [00:10<11:39,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4832, -0.8994, -0.2025, -0.5024, -0.3493, -0.3469, -0.3100, -0.1292],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 42/2708 [00:10<11:35,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9360, -0.1485, -0.8748, -0.8013], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 43/2708 [00:10<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5408, -0.5323, -0.5018, -0.2520, -0.5001], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 44/2708 [00:11<11:30,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9175, -0.6259, -0.8920], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 45/2708 [00:11<11:29,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5529, -0.4633, -0.6824, -0.1575, -0.6823, -0.4527, -0.1097],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 46/2708 [00:11<11:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7863, -0.6055, -0.3041, -0.7659], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 47/2708 [00:12<11:24,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6369, -0.1579,  0.0096, -0.2302, -0.7066, -0.8424, -0.8205],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 48/2708 [00:12<11:23,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5954, -0.7689, -1.0760], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 49/2708 [00:12<11:25,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6883, -0.7915, -0.8190], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 50/2708 [00:12<11:31,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7514, -0.5609, -0.5929, -0.4977, -0.6895, -0.1147, -0.3839, -0.4977,\n",
      "        -0.3521, -0.1876], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 51/2708 [00:13<11:27,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9633, -0.3087, -0.7496], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 52/2708 [00:13<11:32,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0716, -0.7867], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 53/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8026, -0.6366, -0.5278, -0.3520, -0.0046, -0.2991, -0.3643],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 54/2708 [00:13<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2594, -0.6112, -0.5430, -0.0218, -0.8436, -0.6938], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 55/2708 [00:14<11:26,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6441, -0.4541, -0.7002, -0.3384], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 56/2708 [00:14<11:24,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5803, -0.7055, -1.0509], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 57/2708 [00:14<11:28,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9221,  0.3088, -0.4489, -0.3684, -0.2524, -0.0571, -0.5076, -0.1804,\n",
      "        -0.2160, -0.0491, -0.4002, -0.8905,  0.1593], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 58/2708 [00:14<11:34,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4749, -0.3756, -0.3725, -0.5048, -0.4532], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 59/2708 [00:15<11:46,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2448, -0.8058], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 60/2708 [00:15<11:38,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3131, -1.6650], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 61/2708 [00:15<11:45,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4681, -0.5944, -0.3451, -0.4504, -0.3806, -0.3288, -0.3684, -0.7651,\n",
      "        -0.3525, -0.0654, -0.5855], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 62/2708 [00:15<11:42,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1158,  0.6875, -1.3673, -0.8284], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 63/2708 [00:16<11:49,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6049, -0.1793, -0.9846, -0.9551, -0.0148, -0.7559], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 64/2708 [00:16<11:47,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4189, -1.4566], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 65/2708 [00:16<11:40,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1445, -0.6135], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 66/2708 [00:17<11:26,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6229, -0.6396, -0.7113, -0.1714], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ig_spar \u001b[38;5;241m=\u001b[39m \u001b[43mig_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIG Spar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mig_spar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mig_sparsity\u001b[1;34m(model, graph, data_object)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[0;32m     33\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mIG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     total_sparse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count_nonzeros(exp\u001b[38;5;241m.\u001b[39mnode_imp)\u001b[38;5;241m/\u001b[39mexp\u001b[38;5;241m.\u001b[39menc_subgraph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(exp\u001b[38;5;241m.\u001b[39mnode_imp)\n",
      "Cell \u001b[1;32mIn[3], line 1020\u001b[0m, in \u001b[0;36mIG\u001b[1;34m(node_idx, x, edge_index, y, num_hops, steps, model, criterion)\u001b[0m\n\u001b[0;32m   1018\u001b[0m output \u001b[38;5;241m=\u001b[39m model(temp_x, sub_edge_index)\n\u001b[0;32m   1019\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output[mapping], label)\n\u001b[1;32m-> 1020\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m grad \u001b[38;5;241m=\u001b[39m temp_x\u001b[38;5;241m.\u001b[39mgrad[torch\u001b[38;5;241m.\u001b[39mwhere(subset\u001b[38;5;241m==\u001b[39mnode_idx)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m   1022\u001b[0m grads[i] \u001b[38;5;241m=\u001b[39m grad\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\mainEnv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [04:38<00:00,  9.73it/s]\n",
      "100%|| 2708/2708 [12:55<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [11:26<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from statistics import median\n",
    "torch.manual_seed(12345)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = GCNConv(dataset[0].num_nodes, 16)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "graph = to_networkx(data)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [12:32:29<00:00, 16.67s/it]        \n",
      "100%|| 2708/2708 [17:32<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP Sparsity: 1.0\n",
      "CAM Sparsity: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gbp = GuidedBP(model=model)\n",
    "cam = CAM(model=model)\n",
    "\n",
    "# getting explanations for each model\n",
    "gbp_spar = gbp_sparsity(model, graph, data, gbp)\n",
    "cam_spar = cam_sparsity(model, graph, data, gbp)\n",
    "print(f\"GBP Sparsity: {gbp_spar}\\nCAM Sparsity: {cam_spar}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2708/2708 [10:33<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Spar: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ig_spar = ig_sparsity(model, graph, data)\n",
    "\n",
    "print(f\"IG Spar: {ig_spar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
